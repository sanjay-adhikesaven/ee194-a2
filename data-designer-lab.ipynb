{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dea4d6f7",
      "metadata": {},
      "source": [
        "# NeMo Data Designer Lab: Synthetic Pre-Training Data via Document Rephrasing\n",
        "\n",
        "**Assignment 2, Part b** | UC Berkeley EE 194/290-16: Scalable AI | Spring 2026\n",
        "\n",
        "**Cells marked \"YOUR CODE HERE\" require your implementation.**\n",
        "\n",
        "In Part a, you used [NeMo Curator](https://github.com/NVIDIA/NeMo-Curator) to curate a domain-specific\n",
        "Wikipedia corpus. In this notebook, you will use **[NeMo Data Designer](https://github.com/NVIDIA-NeMo/DataDesigner)** to generate\n",
        "synthetic pre-training data from that curated corpus via **document rephrasing**,\n",
        "the core technique behind [Nemotron-CC](https://arxiv.org/abs/2412.02595) (Parmar et al., 2024) and [BeyondWeb](https://arxiv.org/abs/2506.10426)\n",
        "(Xu et al., 2025).\n",
        "\n",
        "The idea is simple but powerful: take high-quality source documents and rephrase them\n",
        "into diverse synthetic formats (QA pairs, distilled passages, knowledge extracts)\n",
        "that improve pre-training data quality and diversity. A cost/efficiency thread runs\n",
        "throughout: you will estimate FLOPs and GPU hours for every generation pipeline you\n",
        "build, reasoning about the compute-quality frontier.\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will be able to:\n",
        "\n",
        "1. Launch and validate a GPU inference server for large-scale text generation\n",
        "2. Estimate computational costs (FLOPs, GPU-hours) for generation workloads\n",
        "3. Build single-strategy and multi-strategy document rephrasing pipelines\n",
        "4. Generate structured outputs (diverse QA pairs) using Pydantic schemas\n",
        "5. Evaluate synthetic data quality using perplexity and LLM-as-judge metrics\n",
        "6. Scale a generation pipeline from prototype to production\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "- **Part a (Curator notebook)**: You need the curated Wikipedia corpus from Part 1a\n",
        "  as seed data. A small fallback sample is provided if your Curator output is\n",
        "  unavailable.\n",
        "- **Hardware**: A dedicated node with 8xH100 GPUs.\n",
        "- **Docker**: The inference server runs as a Docker container\n",
        "  (`nvidia-container-toolkit` must be installed for GPU access).\n",
        "\n",
        "### Pipeline Overview\n",
        "\n",
        "The notebook follows a five-stage pipeline:\n",
        "\n",
        "1. **Seed data**: Load the curated corpus from Part 1a and configure it as a\n",
        "   NeMo Data Designer seed source.\n",
        "2. **Inference server**: Launch a [vLLM](https://github.com/vllm-project/vllm) Docker container serving [Nemotron-3 Nano](https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16)\n",
        "   on your 8xH100 node. Validate the endpoint and measure baseline throughput.\n",
        "3. **Rephrasing strategies**: Build progressively more sophisticated pipelines:\n",
        "   a single Wikipedia-style rephrase, structured diverse QA, and finally a\n",
        "   multi-strategy pipeline combining 4 approaches (QA, distill, knowledge extract,\n",
        "   knowledge list).\n",
        "4. **Evaluation**: Assess output quality with GPT-2 perplexity and LLM-as-judge\n",
        "   scoring before committing to a full generation run.\n",
        "5. **Scale up**: Run `create()` to generate the full dataset for Part B\n",
        "   pre-training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4becc6d0",
      "metadata": {},
      "source": [
        "## Environment Setup (0 pts)\n",
        "\n",
        "Install NeMo Data Designer, verify imports, and configure model access. This section is\n",
        "fully guided. Follow the cells in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "994d8f10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: data-designer in ./Curator/.venv/lib/python3.10/site-packages (0.5.1)\n",
            "Requirement already satisfied: data-designer-config==0.5.1 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer) (0.5.1)\n",
            "Requirement already satisfied: data-designer-engine==0.5.1 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer) (0.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<4,>=3.0.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer) (3.0.52)\n",
            "Requirement already satisfied: typer<1,>=0.12.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer) (0.24.1)\n",
            "Requirement already satisfied: jinja2<4,>=3.1.6 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (3.1.6)\n",
            "Requirement already satisfied: numpy<3,>=1.23.5 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (2.2.0)\n",
            "Requirement already satisfied: pandas<3,>=2.3.3 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (2.3.3)\n",
            "Requirement already satisfied: pillow<13,>=12.0.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (12.1.1)\n",
            "Requirement already satisfied: pyarrow<20,>=19.0.1 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (19.0.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.9.2 in ./Curator/.venv/lib/python3.10/site-packages (from pydantic[email]<3,>=2.9.2->data-designer-config==0.5.1->data-designer) (2.12.5)\n",
            "Requirement already satisfied: pygments<3,>=2.19.2 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (2.19.2)\n",
            "Requirement already satisfied: python-json-logger<4,>=3 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (3.3.0)\n",
            "Requirement already satisfied: pyyaml<7,>=6.0.1 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.32 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (2.32.5)\n",
            "Requirement already satisfied: rich<15,>=13.7.1 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-config==0.5.1->data-designer) (14.2.0)\n",
            "Requirement already satisfied: anyascii<1,>=0.3.3 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (0.3.3)\n",
            "Requirement already satisfied: duckdb<2,>=1.1.3 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (1.4.4)\n",
            "Requirement already satisfied: faker<21,>=20.1.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (20.1.0)\n",
            "Requirement already satisfied: httpx-retries<1,>=0.4.2 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (0.4.5)\n",
            "Requirement already satisfied: httpx<1,>=0.27.2 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2,>=1.0.1 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (1.4.1)\n",
            "Requirement already satisfied: json-repair<1,>=0.48.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (0.57.1)\n",
            "Requirement already satisfied: jsonpath-rust-bindings<2,>=1.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (1.1.1)\n",
            "Requirement already satisfied: jsonschema<5,>=4.0.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (4.25.1)\n",
            "Requirement already satisfied: litellm<1.80.12,>=1.73.6 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (1.80.5)\n",
            "Requirement already satisfied: lxml<7,>=6.0.2 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (6.0.2)\n",
            "Requirement already satisfied: marko<3,>=2.1.2 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (2.2.2)\n",
            "Requirement already satisfied: mcp<2,>=1.26.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (1.26.0)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (3.4.2)\n",
            "Requirement already satisfied: ruff<1,>=0.14.10 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (0.14.10)\n",
            "Requirement already satisfied: scipy<2,>=1.11.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (1.15.3)\n",
            "Requirement already satisfied: sqlfluff<4,>=3.2.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (3.5.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.8.0 in ./Curator/.venv/lib/python3.10/site-packages (from data-designer-engine==0.5.1->data-designer) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in ./Curator/.venv/lib/python3.10/site-packages (from faker<21,>=20.1.0->data-designer-engine==0.5.1->data-designer) (2.9.0.post0)\n",
            "Requirement already satisfied: anyio in ./Curator/.venv/lib/python3.10/site-packages (from httpx<1,>=0.27.2->data-designer-engine==0.5.1->data-designer) (4.12.0)\n",
            "Requirement already satisfied: certifi in ./Curator/.venv/lib/python3.10/site-packages (from httpx<1,>=0.27.2->data-designer-engine==0.5.1->data-designer) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in ./Curator/.venv/lib/python3.10/site-packages (from httpx<1,>=0.27.2->data-designer-engine==0.5.1->data-designer) (1.0.9)\n",
            "Requirement already satisfied: idna in ./Curator/.venv/lib/python3.10/site-packages (from httpx<1,>=0.27.2->data-designer-engine==0.5.1->data-designer) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in ./Curator/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.27.2->data-designer-engine==0.5.1->data-designer) (0.16.0)\n",
            "Requirement already satisfied: filelock in ./Curator/.venv/lib/python3.10/site-packages (from huggingface-hub<2,>=1.0.1->data-designer-engine==0.5.1->data-designer) (3.20.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./Curator/.venv/lib/python3.10/site-packages (from huggingface-hub<2,>=1.0.1->data-designer-engine==0.5.1->data-designer) (2024.12.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./Curator/.venv/lib/python3.10/site-packages (from huggingface-hub<2,>=1.0.1->data-designer-engine==0.5.1->data-designer) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in ./Curator/.venv/lib/python3.10/site-packages (from huggingface-hub<2,>=1.0.1->data-designer-engine==0.5.1->data-designer) (24.2)\n",
            "Requirement already satisfied: shellingham in ./Curator/.venv/lib/python3.10/site-packages (from huggingface-hub<2,>=1.0.1->data-designer-engine==0.5.1->data-designer) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./Curator/.venv/lib/python3.10/site-packages (from huggingface-hub<2,>=1.0.1->data-designer-engine==0.5.1->data-designer) (4.67.1)\n",
            "Requirement already satisfied: typer-slim in ./Curator/.venv/lib/python3.10/site-packages (from huggingface-hub<2,>=1.0.1->data-designer-engine==0.5.1->data-designer) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in ./Curator/.venv/lib/python3.10/site-packages (from huggingface-hub<2,>=1.0.1->data-designer-engine==0.5.1->data-designer) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./Curator/.venv/lib/python3.10/site-packages (from jinja2<4,>=3.1.6->data-designer-config==0.5.1->data-designer) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./Curator/.venv/lib/python3.10/site-packages (from jsonschema<5,>=4.0.0->data-designer-engine==0.5.1->data-designer) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./Curator/.venv/lib/python3.10/site-packages (from jsonschema<5,>=4.0.0->data-designer-engine==0.5.1->data-designer) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in ./Curator/.venv/lib/python3.10/site-packages (from jsonschema<5,>=4.0.0->data-designer-engine==0.5.1->data-designer) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in ./Curator/.venv/lib/python3.10/site-packages (from jsonschema<5,>=4.0.0->data-designer-engine==0.5.1->data-designer) (0.30.0)\n",
            "Requirement already satisfied: aiohttp>=3.10 in ./Curator/.venv/lib/python3.10/site-packages (from litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (3.13.3)\n",
            "Requirement already satisfied: click in ./Curator/.venv/lib/python3.10/site-packages (from litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (8.2.1)\n",
            "Requirement already satisfied: fastuuid>=0.13.0 in ./Curator/.venv/lib/python3.10/site-packages (from litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (0.14.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in ./Curator/.venv/lib/python3.10/site-packages (from litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (8.7.1)\n",
            "Requirement already satisfied: openai>=2.8.0 in ./Curator/.venv/lib/python3.10/site-packages (from litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (2.14.0)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in ./Curator/.venv/lib/python3.10/site-packages (from litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (1.2.1)\n",
            "Requirement already satisfied: tokenizers in ./Curator/.venv/lib/python3.10/site-packages (from litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (0.22.2)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in ./Curator/.venv/lib/python3.10/site-packages (from mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (0.4.3)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in ./Curator/.venv/lib/python3.10/site-packages (from mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (2.12.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in ./Curator/.venv/lib/python3.10/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in ./Curator/.venv/lib/python3.10/site-packages (from mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in ./Curator/.venv/lib/python3.10/site-packages (from mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (3.0.4)\n",
            "Requirement already satisfied: starlette>=0.27 in ./Curator/.venv/lib/python3.10/site-packages (from mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (0.50.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in ./Curator/.venv/lib/python3.10/site-packages (from mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in ./Curator/.venv/lib/python3.10/site-packages (from mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (0.40.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./Curator/.venv/lib/python3.10/site-packages (from pandas<3,>=2.3.3->data-designer-config==0.5.1->data-designer) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./Curator/.venv/lib/python3.10/site-packages (from pandas<3,>=2.3.3->data-designer-config==0.5.1->data-designer) (2025.3)\n",
            "Requirement already satisfied: wcwidth in ./Curator/.venv/lib/python3.10/site-packages (from prompt-toolkit<4,>=3.0.0->data-designer) (0.2.14)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./Curator/.venv/lib/python3.10/site-packages (from pydantic<3,>=2.9.2->pydantic[email]<3,>=2.9.2->data-designer-config==0.5.1->data-designer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in ./Curator/.venv/lib/python3.10/site-packages (from pydantic<3,>=2.9.2->pydantic[email]<3,>=2.9.2->data-designer-config==0.5.1->data-designer) (2.41.5)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in ./Curator/.venv/lib/python3.10/site-packages (from pydantic[email]<3,>=2.9.2->data-designer-config==0.5.1->data-designer) (2.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./Curator/.venv/lib/python3.10/site-packages (from requests<3,>=2.32->data-designer-config==0.5.1->data-designer) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./Curator/.venv/lib/python3.10/site-packages (from requests<3,>=2.32->data-designer-config==0.5.1->data-designer) (2.6.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./Curator/.venv/lib/python3.10/site-packages (from rich<15,>=13.7.1->data-designer-config==0.5.1->data-designer) (4.0.0)\n",
            "Requirement already satisfied: platformdirs in ./Curator/.venv/lib/python3.10/site-packages (from sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (4.5.1)\n",
            "Requirement already satisfied: chardet in ./Curator/.venv/lib/python3.10/site-packages (from sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (5.2.0)\n",
            "Requirement already satisfied: colorama>=0.3 in ./Curator/.venv/lib/python3.10/site-packages (from sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (0.4.6)\n",
            "Requirement already satisfied: diff-cover>=2.5.0 in ./Curator/.venv/lib/python3.10/site-packages (from sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (10.2.0)\n",
            "Requirement already satisfied: pathspec in ./Curator/.venv/lib/python3.10/site-packages (from sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (1.0.4)\n",
            "Requirement already satisfied: pytest in ./Curator/.venv/lib/python3.10/site-packages (from sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (9.0.2)\n",
            "Requirement already satisfied: regex in ./Curator/.venv/lib/python3.10/site-packages (from sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (2025.11.3)\n",
            "Requirement already satisfied: tblib in ./Curator/.venv/lib/python3.10/site-packages (from sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (3.2.2)\n",
            "Requirement already satisfied: tomli in ./Curator/.venv/lib/python3.10/site-packages (from sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (2.3.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in ./Curator/.venv/lib/python3.10/site-packages (from typer<1,>=0.12.0->data-designer) (0.0.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./Curator/.venv/lib/python3.10/site-packages (from aiohttp>=3.10->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in ./Curator/.venv/lib/python3.10/site-packages (from aiohttp>=3.10->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./Curator/.venv/lib/python3.10/site-packages (from aiohttp>=3.10->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (5.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./Curator/.venv/lib/python3.10/site-packages (from aiohttp>=3.10->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./Curator/.venv/lib/python3.10/site-packages (from aiohttp>=3.10->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./Curator/.venv/lib/python3.10/site-packages (from aiohttp>=3.10->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./Curator/.venv/lib/python3.10/site-packages (from aiohttp>=3.10->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (1.22.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./Curator/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.27.2->data-designer-engine==0.5.1->data-designer) (1.3.1)\n",
            "Requirement already satisfied: pluggy<2,>=0.13.1 in ./Curator/.venv/lib/python3.10/site-packages (from diff-cover>=2.5.0->sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (1.6.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in ./Curator/.venv/lib/python3.10/site-packages (from email-validator>=2.0.0->pydantic[email]<3,>=2.9.2->data-designer-config==0.5.1->data-designer) (2.8.0)\n",
            "Requirement already satisfied: zipp>=3.20 in ./Curator/.venv/lib/python3.10/site-packages (from importlib-metadata>=6.8.0->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./Curator/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15,>=13.7.1->data-designer-config==0.5.1->data-designer) (0.1.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./Curator/.venv/lib/python3.10/site-packages (from openai>=2.8.0->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in ./Curator/.venv/lib/python3.10/site-packages (from openai>=2.8.0->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (0.12.0)\n",
            "Requirement already satisfied: sniffio in ./Curator/.venv/lib/python3.10/site-packages (from openai>=2.8.0->litellm<1.80.12,>=1.73.6->data-designer-engine==0.5.1->data-designer) (1.3.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in ./Curator/.venv/lib/python3.10/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (46.0.5)\n",
            "Requirement already satisfied: cffi>=2.0.0 in ./Curator/.venv/lib/python3.10/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (2.0.0)\n",
            "Requirement already satisfied: pycparser in ./Curator/.venv/lib/python3.10/site-packages (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.26.0->data-designer-engine==0.5.1->data-designer) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in ./Curator/.venv/lib/python3.10/site-packages (from python-dateutil>=2.4->faker<21,>=20.1.0->data-designer-engine==0.5.1->data-designer) (1.17.0)\n",
            "Requirement already satisfied: iniconfig>=1.0.1 in ./Curator/.venv/lib/python3.10/site-packages (from pytest->sqlfluff<4,>=3.2.0->data-designer-engine==0.5.1->data-designer) (2.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install data-designer\n",
        "# If you already have it installed, this will upgrade to the latest version.\n",
        "%pip install -U data-designer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ee5fb7f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeMo Data Designer imported successfully.\n"
          ]
        }
      ],
      "source": [
        "# Verify imports\n",
        "import data_designer.config as dd\n",
        "from data_designer.interface import DataDesigner\n",
        "\n",
        "print(\"NeMo Data Designer imported successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a883c55f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a custom model provider pointing at the local vLLM server.\n",
        "# ModelProvider handles endpoint URLs and API keys; ModelConfig references\n",
        "# the provider by name.\n",
        "model_providers = [\n",
        "    dd.ModelProvider(\n",
        "        name=\"local-vllm\",\n",
        "        endpoint=\"http://localhost:8000/v1\",\n",
        "        provider_type=\"openai\",  # vLLM exposes an OpenAI-compatible API\n",
        "        api_key=None,  # no authentication needed for local server\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize NeMo Data Designer with our custom provider.\n",
        "data_designer = DataDesigner(model_providers=model_providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "184d0f57",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure the model. The provider=\"local-vllm\" tells NeMo Data Designer to route\n",
        "# requests through the provider we just defined (our local vLLM server).\n",
        "model_configs = [\n",
        "    dd.ModelConfig(\n",
        "        model=\"nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\",  # must match the served model\n",
        "        provider=\"local-vllm\",\n",
        "        alias=\"rephraser\",\n",
        "        # Disable thinking for rephrasing. Nemotron-3 Nano is a hybrid reasoning\n",
        "        # model, but for straightforward rephrasing tasks, thinking wastes tokens.\n",
        "        # We want direct output only. For tasks that benefit from reasoning (complex\n",
        "        # QA, tool use, multi-step problems), remove extra_body or set\n",
        "        # enable_thinking=True to let the model use its built-in chain-of-thought.\n",
        "        inference_parameters=dd.ChatCompletionInferenceParams(\n",
        "            max_tokens=2048,\n",
        "            temperature=0.7,\n",
        "            extra_body={\"chat_template_kwargs\": {\"enable_thinking\": False}},\n",
        "        ),\n",
        "    )\n",
        "]\n",
        "\n",
        "# NOTE: To use NVIDIA's hosted API instead of a local server, skip the custom\n",
        "# ModelProvider and use the built-in \"nvidia\" provider:\n",
        "#\n",
        "#   model_configs = [\n",
        "#       dd.ModelConfig(\n",
        "#           model=\"nvidia/nemotron-3-nano-30b-a3b\",\n",
        "#           provider=\"nvidia\",  # uses https://integrate.api.nvidia.com\n",
        "#           alias=\"rephraser\",\n",
        "#       )\n",
        "#   ]\n",
        "#\n",
        "# This requires NVIDIA_API_KEY set in your environment. For this lab, we use\n",
        "# the local endpoint since you have dedicated GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b12ed8c3",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b2f1860",
      "metadata": {},
      "source": [
        "## Inference Serving (10 pts)\n",
        "\n",
        "Before generating synthetic data, you need a running inference server. This section\n",
        "walks through booting a model, confirming it serves, and measuring basic throughput.\n",
        "This is a lightweight introduction; Assignment A4 covers inference optimization in\n",
        "depth. Here, we just need the server running so NeMo Data Designer can call it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa190ca1",
      "metadata": {},
      "source": [
        "### Launching the Inference Server\n",
        "\n",
        "You have a dedicated 8xH100 node with Docker installed. We will run vLLM as a\n",
        "Docker container. Run these commands in a **separate terminal** (the server runs\n",
        "as a long-lived process).\n",
        "\n",
        "**Step 1**: Download the custom reasoning parser plugin. Nemotron-3 Nano is a\n",
        "**hybrid reasoning model** that can interleave \"thinking\" tokens (chain-of-thought)\n",
        "with final response tokens. The reasoning parser separates these two streams so\n",
        "vLLM can handle them correctly (e.g., stripping thinking tokens from the response,\n",
        "or exposing them via the API for inspection). The plugin implements the\n",
        "Nemotron-3-specific parsing logic.\n",
        "\n",
        "```bash\n",
        "mkdir -p ~/vllm-plugins\n",
        "wget -O ~/vllm-plugins/nano_v3_reasoning_parser.py \\\n",
        "    https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16/resolve/main/nano_v3_reasoning_parser.py\n",
        "```\n",
        "\n",
        "**Step 2**: Launch the server with reasoning and tool-call support:\n",
        "\n",
        "```bash\n",
        "docker run --gpus all \\\n",
        "    -v ~/.cache/huggingface:/root/.cache/huggingface \\\n",
        "    -v ~/vllm-plugins:/plugins \\\n",
        "    -p 8000:8000 \\\n",
        "    vllm/vllm-openai:v0.14.0 \\\n",
        "    --model nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16 \\\n",
        "    --trust-remote-code \\\n",
        "    --tensor-parallel-size 4 \\\n",
        "    --dtype bfloat16 \\\n",
        "    --port 8000 \\\n",
        "    --reasoning-parser nano_v3 \\\n",
        "    --reasoning-parser-plugin /plugins/nano_v3_reasoning_parser.py \\\n",
        "    --enable-auto-tool-choice \\\n",
        "    --tool-call-parser qwen3_coder\n",
        "```\n",
        "\n",
        "Key Docker flags:\n",
        "- `--gpus all`: exposes all 8 H100s to the container (requires `nvidia-container-toolkit`).\n",
        "- `-v ~/.cache/huggingface:/root/.cache/huggingface`: mounts the Hugging Face model\n",
        "  cache so weights persist across container restarts.\n",
        "- `-v ~/vllm-plugins:/plugins`: mounts the directory containing the reasoning parser\n",
        "  plugin so vLLM can load it from inside the container.\n",
        "- `-p 8000:8000`: maps the container's port 8000 to the host.\n",
        "\n",
        "Key vLLM flags:\n",
        "- `--reasoning-parser nano_v3` / `--reasoning-parser-plugin`: register the custom\n",
        "  parser that separates thinking tokens from final output in the API response.\n",
        "- `--enable-auto-tool-choice` / `--tool-call-parser qwen3_coder`: enable structured\n",
        "  tool calling (used by NeMo Data Designer for structured output / function calling).\n",
        "\n",
        "Wait until you see `Uvicorn running on http://0.0.0.0:8000`. This may take several\n",
        "minutes as the model weights are downloaded and loaded. The server exposes an\n",
        "OpenAI-compatible API that NeMo Data Designer (and the `openai` Python client) can call\n",
        "directly.\n",
        "\n",
        "### Alternative servers\n",
        "\n",
        "**[SGLang](https://github.com/sgl-project/sglang):**\n",
        "```bash\n",
        "docker run --gpus all \\\n",
        "    -v ~/.cache/huggingface:/root/.cache/huggingface \\\n",
        "    -p 8000:8000 \\\n",
        "    lmsysorg/sglang:latest \\\n",
        "    python3 -m sglang.launch_server \\\n",
        "        --model-path nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16 \\\n",
        "        --port 8000\n",
        "```\n",
        "\n",
        "**[TensorRT-LLM](https://nvidia.github.io/TensorRT-LLM/):**\n",
        "```bash\n",
        "docker run --gpus all \\\n",
        "    -v ~/.cache/huggingface:/root/.cache/huggingface \\\n",
        "    -p 8000:8000 \\\n",
        "    nvcr.io/nvidia/tritonserver:24.12-trtllm-python-py3 \\\n",
        "    trtllm-serve \\\n",
        "        --model nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16 \\\n",
        "        --port 8000\n",
        "```\n",
        "TRT-LLM requires an engine build step before serving but offers the best throughput\n",
        "for production workloads. See the\n",
        "[TRT-LLM documentation](https://nvidia.github.io/TensorRT-LLM/) for setup details.\n",
        "\n",
        "All three servers expose OpenAI-compatible endpoints, so the rest of this notebook\n",
        "works unchanged regardless of which you choose."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be1c1a84",
      "metadata": {},
      "source": [
        "### Your Task\n",
        "\n",
        "1. Launch the vLLM server following the instructions above.\n",
        "2. Run the health check cell to confirm the server is responding.\n",
        "3. Send a test request and verify you get a coherent response.\n",
        "4. Measure sequential throughput (tokens/sec) using the provided prompts.\n",
        "5. Compute the effective MFU and explain in a sentence or two why it is low at batch size 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1ab12986",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'object': 'list', 'data': [{'id': 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16', 'object': 'model', 'created': 1772098939, 'owned_by': 'vllm', 'root': 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16', 'parent': None, 'max_model_len': 262144, 'permission': [{'id': 'modelperm-9ec175c6e984bd13', 'object': 'model_permission', 'created': 1772098939, 'allow_create_engine': False, 'allow_sampling': True, 'allow_logprobs': True, 'allow_search_indices': False, 'allow_view': True, 'allow_fine_tuning': False, 'organization': '*', 'group': None, 'is_blocking': False}]}]}\n"
          ]
        }
      ],
      "source": [
        "# Health check: confirm the server is up and serving your model.\n",
        "import requests\n",
        "\n",
        "response = requests.get(\"http://localhost:8000/v1/models\")\n",
        "print(response.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1d918547",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# Test request: send a single chat completion to verify end-to-end.\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"not-needed\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"What is synthetic data generation?\"}],\n",
        "    max_tokens=256,\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "506e34bd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requests sent:       5\n",
            "Prompt tokens:       136\n",
            "Completion tokens:   1280\n",
            "Wall-clock time:     3.73 s\n",
            "Throughput (decode):  343.3 tokens/sec\n"
          ]
        }
      ],
      "source": [
        "# Throughput measurement: send a batch of requests and measure tokens/sec.\n",
        "# This is sequential (batch size 1) to establish a baseline. Real throughput\n",
        "# improves with concurrent requests and batching (often 5-10x).\n",
        "\n",
        "import time\n",
        "\n",
        "prompts = [\n",
        "    \"Explain the concept of synthetic data generation in machine learning.\",\n",
        "    \"What are the main challenges in training large language models?\",\n",
        "    \"Describe the transformer architecture and its key innovations.\",\n",
        "    \"How does distributed training work across multiple GPUs?\",\n",
        "    \"What is the difference between pre-training and fine-tuning?\",\n",
        "]\n",
        "\n",
        "total_prompt_tokens = 0\n",
        "total_completion_tokens = 0\n",
        "start = time.time()\n",
        "\n",
        "for prompt in prompts:\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=256,\n",
        "    )\n",
        "    total_prompt_tokens += resp.usage.prompt_tokens\n",
        "    total_completion_tokens += resp.usage.completion_tokens\n",
        "\n",
        "elapsed = time.time() - start\n",
        "tokens_per_sec = total_completion_tokens / elapsed\n",
        "\n",
        "print(f\"Requests sent:       {len(prompts)}\")\n",
        "print(f\"Prompt tokens:       {total_prompt_tokens}\")\n",
        "print(f\"Completion tokens:   {total_completion_tokens}\")\n",
        "print(f\"Wall-clock time:     {elapsed:.2f} s\")\n",
        "print(f\"Throughput (decode):  {tokens_per_sec:.1f} tokens/sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "952e7055",
      "metadata": {},
      "source": [
        "### Effective MFU\n",
        "\n",
        "How efficient is our inference server? We can compare observed throughput against the\n",
        "GPU's theoretical peak to estimate **effective MFU** (Model FLOPs Utilization).\n",
        "\n",
        "For a dense transformer, each token requires approximately **2P FLOPs** in the\n",
        "forward pass (where P is the number of parameters). For Nemotron-3 Nano, which is a\n",
        "hybrid Mamba+MoE+Attention model, FLOPs per token uses **active parameters** (~3.2B),\n",
        "not total parameters (31.6B), since only a fraction of experts are activated per token.\n",
        "Given observed tokens/sec, we can compute observed TFLOPS and compare against the\n",
        "H100's FP16 peak of 989 TFLOPS.\n",
        "\n",
        "At batch size 1, expect low MFU because autoregressive decode is **memory-bandwidth-bound**,\n",
        "not compute-bound. The GPU spends most of its time loading weights from HBM rather\n",
        "than doing arithmetic. We will revisit this in Section 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4f2dbeeb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Active parameters:    3.2 B\n",
            "FLOPs per token:      6.40e+09\n",
            "Observed throughput:  343.3 tokens/sec\n",
            "Observed TFLOPS:      2.20\n",
            "Peak TFLOPS (4 GPUs): 3956\n",
            "Effective MFU:        0.0006  (0.06%)\n"
          ]
        }
      ],
      "source": [
        "# Effective MFU estimation\n",
        "\n",
        "active_params = 3.2e9          # Nemotron-3 Nano: 3.2B active parameters (MoE)\n",
        "flops_per_token = 2 * active_params\n",
        "num_gpus = 4                   # tensor-parallel-size from our vLLM launch command\n",
        "h100_peak_tflops = 989         # per-GPU FP16 peak TFLOPS\n",
        "\n",
        "observed_tflops = (tokens_per_sec * flops_per_token) / 1e12\n",
        "total_peak_tflops = h100_peak_tflops * num_gpus\n",
        "mfu = observed_tflops / total_peak_tflops\n",
        "\n",
        "print(f\"Active parameters:    {active_params / 1e9:.1f} B\")\n",
        "print(f\"FLOPs per token:      {flops_per_token:.2e}\")\n",
        "print(f\"Observed throughput:  {tokens_per_sec:.1f} tokens/sec\")\n",
        "print(f\"Observed TFLOPS:      {observed_tflops:.2f}\")\n",
        "print(f\"Peak TFLOPS ({num_gpus} GPUs): {total_peak_tflops:.0f}\")\n",
        "print(f\"Effective MFU:        {mfu:.4f}  ({mfu * 100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c397056",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a23bf5d",
      "metadata": {},
      "source": [
        "## Seed Data (5 pts)\n",
        "\n",
        "Load the curated Wikipedia corpus you produced in Part 1a (the NeMo Curator lab).\n",
        "This becomes the **seed data** for all rephrasing. Every synthetic document will\n",
        "be derived from one of these source articles. We will also configure it as a NeMo Data\n",
        "Designer seed source for use in later sections."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91ff0468",
      "metadata": {},
      "source": [
        "### Your Task\n",
        "\n",
        "1. Load your Part 1a Curator output from `wiki_curated_domain_data/`. If your Curator output is unavailable, use the provided sample data.\n",
        "2. Report: number of documents, text length statistics (mean, median, min, max), approximate total tokens, and category breakdown.\n",
        "3. Configure a `LocalFileSeedSource` pointing at your data.\n",
        "4. Examine 2-3 documents and comment on what makes them good or poor candidates for rephrasing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8bce0e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3 JSONL files: ['wiki_curated_domain_data/8dff7abad519.jsonl', 'wiki_curated_domain_data/acef2699d502.jsonl', 'wiki_curated_domain_data/seed.jsonl']\n",
            "Loaded 18 documents\n",
            "Columns: ['text', 'title', 'id', 'url', 'language', 'source_id', 'file_name', 'categories']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>language</th>\n",
              "      <th>source_id</th>\n",
              "      <th>file_name</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Interoperability is a characteristic of a prod...</td>\n",
              "      <td>Interoperability</td>\n",
              "      <td>41285</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Interoperability</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Interoperability, Computing terminology, Tele...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In communications and computing, a machine-rea...</td>\n",
              "      <td>Machine-readable medium and data</td>\n",
              "      <td>41341</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Machine-readable...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Machine-readable medium and data, Computing t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maintainability is the ease of maintaining or ...</td>\n",
              "      <td>Maintainability</td>\n",
              "      <td>41347</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Maintainability</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Maintainability, Telecommunications engineeri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In telecommunications and data storage, Manche...</td>\n",
              "      <td>Manchester code</td>\n",
              "      <td>41350</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Manchester%20code</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Manchester code, Line codes, Department of Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The μ-law algorithm (sometimes written mu-law,...</td>\n",
              "      <td>Mu-law algorithm</td>\n",
              "      <td>41382</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Mu-law%20algorithm</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Mu-law algorithm, Audio codecs, ITU-T recomme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  Interoperability is a characteristic of a prod...   \n",
              "1  In communications and computing, a machine-rea...   \n",
              "2  Maintainability is the ease of maintaining or ...   \n",
              "3  In telecommunications and data storage, Manche...   \n",
              "4  The μ-law algorithm (sometimes written mu-law,...   \n",
              "\n",
              "                              title     id  \\\n",
              "0                  Interoperability  41285   \n",
              "1  Machine-readable medium and data  41341   \n",
              "2                   Maintainability  41347   \n",
              "3                   Manchester code  41350   \n",
              "4                  Mu-law algorithm  41382   \n",
              "\n",
              "                                                 url language  \\\n",
              "0     https://en.wikipedia.org/wiki/Interoperability       en   \n",
              "1  https://en.wikipedia.org/wiki/Machine-readable...       en   \n",
              "2      https://en.wikipedia.org/wiki/Maintainability       en   \n",
              "3    https://en.wikipedia.org/wiki/Manchester%20code       en   \n",
              "4   https://en.wikipedia.org/wiki/Mu-law%20algorithm       en   \n",
              "\n",
              "                                           source_id  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "3  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "4  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                           file_name  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "3  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "4  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                          categories  \n",
              "0  [Interoperability, Computing terminology, Tele...  \n",
              "1  [Machine-readable medium and data, Computing t...  \n",
              "2  [Maintainability, Telecommunications engineeri...  \n",
              "3  [Manchester code, Line codes, Department of Co...  \n",
              "4  [Mu-law algorithm, Audio codecs, ITU-T recomme...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load and inspect the Curator output.\n",
        "# The Curator lab writes JSONL files to wiki_curated_domain_data/.\n",
        "# Load all JSONL files into a pandas DataFrame.\n",
        "\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "jsonl_files = sorted(glob.glob(\"wiki_curated_domain_data/*.jsonl\"))\n",
        "print(f\"Found {len(jsonl_files)} JSONL files: {jsonl_files}\")\n",
        "\n",
        "seed_df = pd.concat([pd.read_json(f, lines=True) for f in jsonl_files], ignore_index=True)\n",
        "print(f\"Loaded {len(seed_df)} documents\")\n",
        "print(f\"Columns: {list(seed_df.columns)}\")\n",
        "seed_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ba096eba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents: 18\n",
            "Mean text length:    8038 chars\n",
            "Median text length:  4734 chars\n",
            "Min text length:     947 chars\n",
            "Max text length:     29874 chars\n",
            "Std text length:     10173 chars\n"
          ]
        }
      ],
      "source": [
        "# Text length distribution: how long are the curated articles?\n",
        "# Report: number of documents, mean/median/min/max text length.\n",
        "\n",
        "text_lengths = seed_df[\"text\"].str.len()\n",
        "\n",
        "print(f\"Number of documents: {len(seed_df)}\")\n",
        "print(f\"Mean text length:    {text_lengths.mean():.0f} chars\")\n",
        "print(f\"Median text length:  {text_lengths.median():.0f} chars\")\n",
        "print(f\"Min text length:     {text_lengths.min()} chars\")\n",
        "print(f\"Max text length:     {text_lengths.max()} chars\")\n",
        "print(f\"Std text length:     {text_lengths.std():.0f} chars\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "550c3c60",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total characters:       144,675\n",
            "Approximate tokens:     36,169\n",
            "Avg tokens per document: 2,009\n"
          ]
        }
      ],
      "source": [
        "# Rough token count estimate (chars / 4 is a common approximation for English text).\n",
        "# Report the approximate total corpus size in tokens.\n",
        "\n",
        "total_chars = text_lengths.sum()\n",
        "approx_tokens = total_chars / 4\n",
        "\n",
        "print(f\"Total characters:       {total_chars:,}\")\n",
        "print(f\"Approximate tokens:     {approx_tokens:,.0f}\")\n",
        "print(f\"Avg tokens per document: {approx_tokens / len(seed_df):,.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "948504e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique categories: 28\n",
            "\n",
            "Top categories:\n",
            "categories\n",
            "Computing terminology                                       6\n",
            "Telecommunications engineering                              6\n",
            "Interoperability                                            3\n",
            "Product testing                                             3\n",
            "Machine-readable medium and data                            3\n",
            "Storage media                                               3\n",
            "Optical character recognition                               3\n",
            "Maintainability                                             3\n",
            "Design for X                                                3\n",
            "Maintenance                                                 3\n",
            "Software quality                                            3\n",
            "Broad-concept articles                                      3\n",
            "Manchester code                                             3\n",
            "Line codes                                                  3\n",
            "Department of Computer Science, University of Manchester    3\n",
            "History of computing in the United Kingdom                  3\n",
            "History of telecommunications in the United Kingdom         3\n",
            "Mu-law algorithm                                            3\n",
            "Audio codecs                                                3\n",
            "ITU-T recommendations                                       3\n"
          ]
        }
      ],
      "source": [
        "# Category breakdown: what domains are represented?\n",
        "# If your data has a \"categories\" column, report unique categories and their counts.\n",
        "\n",
        "if \"categories\" in seed_df.columns:\n",
        "    all_cats = seed_df[\"categories\"].explode()\n",
        "    cat_counts = all_cats.value_counts()\n",
        "    print(f\"Unique categories: {len(cat_counts)}\")\n",
        "    print(f\"\\nTop categories:\")\n",
        "    print(cat_counts.head(20).to_string())\n",
        "else:\n",
        "    print(\"No 'categories' column found in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf0b6caa",
      "metadata": {},
      "source": [
        "If your Curator output is unavailable, a small sample dataset is provided in\n",
        "wiki_curated_domain_data/ for testing. It uses the same JSONL format and schema\n",
        "as the Curator pipeline output, so all downstream code works unchanged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d25fced2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed source configured: seed_type='local' path='wiki_curated_domain_data/seed.jsonl'\n",
            "Path: wiki_curated_domain_data/seed.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Configure the seed source for NeMo Data Designer.\n",
        "# This tells NeMo Data Designer where to read source documents from. In later sections,\n",
        "# prompt templates will reference seed columns like {{ text }} and {{ title }}.\n",
        "\n",
        "from data_designer.config import LocalFileSeedSource\n",
        "\n",
        "seed_path = \"wiki_curated_domain_data/seed.jsonl\"\n",
        "seed_df.to_json(seed_path, orient=\"records\", lines=True)\n",
        "\n",
        "seed_source = LocalFileSeedSource(path=seed_path)\n",
        "print(f\"Seed source configured: {seed_source}\")\n",
        "print(f\"Path: {seed_source.path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "66f7a601",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Document 0: Interoperability\n",
            "Length: 29874 chars (~7468 tokens)\n",
            "Categories: ['Interoperability', 'Computing terminology', 'Telecommunications engineering', 'Product testing']\n",
            "--------------------------------------------------------------------------------\n",
            "Interoperability is a characteristic of a product or system to work with other products or systems. While the term was initially defined for information technology or systems engineering services to allow for information exchange, a broader definition takes into account social, political, and organizational factors that impact system-to-system performance.\n",
            "\n",
            "Types of interoperability include syntactic interoperability, where two systems can communicate with each other, and cross-domain interoperability, where multiple organizations work together and exchange information.\n",
            "\n",
            "Types\n",
            "\n",
            "If two or more systems use common data formats and communication protocols, then they are capable of communicating with each other, and they exhibit syntactic interoperability. XML and SQL are examples of common dat\n",
            "...\n",
            "\n",
            "================================================================================\n",
            "Document 1: Machine-readable medium and data\n",
            "Length: 4769 chars (~1192 tokens)\n",
            "Categories: ['Machine-readable medium and data', 'Computing terminology', 'Storage media', 'Optical character recognition']\n",
            "--------------------------------------------------------------------------------\n",
            "In communications and computing, a machine-readable medium (or computer-readable medium) is a medium capable of storing data in a format easily readable by a digital computer or a sensor. \n",
            "It contrasts with human-readable medium and data.\n",
            "\n",
            "The result is called machine-readable data or computer-readable data, and the data itself can be described as having machine-readability.\n",
            "\n",
            "Data\n",
            "Machine-readable data must be structured data.\n",
            "\n",
            "Attempts to create machine-readable data occurred as early as the 1960s. At the same time that seminal developments in machine-reading and natural-language processing were releasing (like Weizenbaum's ELIZA), people were anticipating the success of machine-readable functionality and attempting to create machine-readable documents. One such example was musicologist N\n",
            "...\n",
            "\n",
            "================================================================================\n",
            "Document 2: Maintainability\n",
            "Length: 2483 chars (~620 tokens)\n",
            "Categories: ['Maintainability', 'Telecommunications engineering', 'Design for X', 'Maintenance', 'Software quality', 'Broad-concept articles']\n",
            "--------------------------------------------------------------------------------\n",
            "Maintainability is the ease of maintaining or providing maintenance for a functioning product or service. Depending on the field, it can have slightly different meanings.\n",
            "\n",
            "Usage in different fields\n",
            "\n",
            "Engineering \n",
            "In engineering, maintainability is the ease with which a product can be maintained to:\n",
            " correct defects or their cause,\n",
            " Repair or replace faulty or worn-out components without having to replace still working parts,\n",
            " prevent unexpected working conditions,\n",
            " maximize a product's useful life,\n",
            " maximize efficiency, reliability, and safety,\n",
            " meet new requirements,\n",
            " make future maintenance easier, or\n",
            " cope with a changing environment.\n",
            "\n",
            "In some cases, maintainability involves a system of continuous improvement - learning from the past to improve the ability to maintain systems, or improve\n",
            "...\n",
            "\n",
            "================================================================================\n",
            "Rephrasing suitability:\n",
            "- Good candidates: long, information-dense articles with clear factual content\n",
            "  and well-structured sections. These give the LLM rich material to rephrase.\n",
            "- Poor candidates: very short stubs, list-heavy articles with little prose,\n",
            "  or articles dominated by tables/data that lose meaning when rephrased.\n"
          ]
        }
      ],
      "source": [
        "# Explore: examine a few documents in detail. What makes good vs. poor\n",
        "# candidates for rephrasing? Look at text quality and information density.\n",
        "\n",
        "for i in range(min(3, len(seed_df))):\n",
        "    row = seed_df.iloc[i]\n",
        "    print(f\"{'=' * 80}\")\n",
        "    print(f\"Document {i}: {row['title']}\")\n",
        "    print(f\"Length: {len(row['text'])} chars (~{len(row['text']) // 4} tokens)\")\n",
        "    if \"categories\" in seed_df.columns:\n",
        "        print(f\"Categories: {row['categories']}\")\n",
        "    print(f\"{'-' * 80}\")\n",
        "    print(row[\"text\"][:800])\n",
        "    print(\"...\\n\" if len(row[\"text\"]) > 800 else \"\\n\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Rephrasing suitability:\")\n",
        "print(\"- Good candidates: long, information-dense articles with clear factual content\")\n",
        "print(\"  and well-structured sections. These give the LLM rich material to rephrase.\")\n",
        "print(\"- Poor candidates: very short stubs, list-heavy articles with little prose,\")\n",
        "print(\"  or articles dominated by tables/data that lose meaning when rephrased.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "621013db",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c9a6d3e",
      "metadata": {},
      "source": [
        "## Cost of Generation (5 pts + bonus)\n",
        "\n",
        "Before generating synthetic data at scale, estimate the computational cost.\n",
        "Compare two model architectures and build intuition for how architecture\n",
        "choices affect the cost of synthetic data generation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fafcc215",
      "metadata": {},
      "source": [
        "### Your Task\n",
        "\n",
        "1. Estimate the FLOPs and GPU-hours for rephrasing your dataset with: (a) an 8B dense model and (b) a 30B-total, 3B-active MoE.\n",
        "2. Answer: Which model gives the best FLOPs/token? Which has the highest memory requirement? When would you choose the dense model over the MoE?\n",
        "\n",
        "**Bonus (5 pts):** Compute the critical batch size at which the MoE becomes compute-bound on H100. Show your arithmetic intensity calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "69b1effa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 18 docs, ~36,168 input tokens, ~36,168 output tokens\n",
            "============================================================\n",
            "Metric                               8B Dense  30B MoE (3B active)\n",
            "------------------------------------------------------------\n",
            "FLOPs/token                    1.60e+10             6.40e+09\n",
            "Total FLOPs                    1.16e+15             4.63e+14\n",
            "GPU-hours (4xH100, 30% MFU)          0.000271             0.000108\n",
            "Memory (bf16 weights)                   16.0G                60.0G\n",
            "FLOPs/token ratio vs dense               1.0x                0.40x\n",
            "\n",
            "Key takeaways:\n",
            "- The MoE uses 40.0% of the dense model's FLOPs/token\n",
            "  (3.2B active vs 8B), so it's ~2.5x cheaper per token.\n",
            "- But the MoE needs 60 GB vs 16 GB for weights — 3.8x more memory.\n",
            "- Choose the dense model when memory is constrained (e.g., fewer/smaller GPUs)\n",
            "  or when you need simpler serving (no expert routing overhead).\n",
            "  Choose the MoE when you have enough memory and want lower cost per token.\n"
          ]
        }
      ],
      "source": [
        "# Model comparison: estimate generation cost for dense vs. MoE.\n",
        "\n",
        "num_docs = len(seed_df)\n",
        "total_input_tokens = int(approx_tokens)\n",
        "total_output_tokens = total_input_tokens  # assume ~1:1 ratio for rephrasing\n",
        "total_tokens = total_input_tokens + total_output_tokens\n",
        "\n",
        "# --- (a) 8B Dense Model ---\n",
        "dense_params = 8e9\n",
        "dense_flops_per_token = 2 * dense_params\n",
        "dense_total_flops = total_tokens * dense_flops_per_token\n",
        "\n",
        "# --- (b) 30B-total, 3B-active MoE (Nemotron-3 Nano) ---\n",
        "moe_total_params = 30e9\n",
        "moe_active_params = 3.2e9\n",
        "moe_flops_per_token = 2 * moe_active_params\n",
        "moe_total_flops = total_tokens * moe_flops_per_token\n",
        "\n",
        "# GPU-hours: assume 4x H100, realistic MFU ~30% for batched inference\n",
        "num_gpus = 4\n",
        "h100_peak_tflops = 989\n",
        "total_peak_flops_per_sec = num_gpus * h100_peak_tflops * 1e12\n",
        "assumed_mfu = 0.30\n",
        "effective_flops_per_sec = total_peak_flops_per_sec * assumed_mfu\n",
        "\n",
        "dense_gpu_hours = dense_total_flops / effective_flops_per_sec / 3600\n",
        "moe_gpu_hours = moe_total_flops / effective_flops_per_sec / 3600\n",
        "\n",
        "# Memory requirements (bf16 = 2 bytes per param, weights only)\n",
        "dense_mem_gb = dense_params * 2 / 1e9\n",
        "moe_mem_gb = moe_total_params * 2 / 1e9  # must load ALL params into memory\n",
        "\n",
        "print(f\"Dataset: {num_docs} docs, ~{total_input_tokens:,} input tokens, ~{total_output_tokens:,} output tokens\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"{'Metric':<30} {'8B Dense':>14} {'30B MoE (3B active)':>20}\")\n",
        "print(f\"{'-' * 60}\")\n",
        "print(f\"{'FLOPs/token':<30} {dense_flops_per_token:.2e} {moe_flops_per_token:>20.2e}\")\n",
        "print(f\"{'Total FLOPs':<30} {dense_total_flops:.2e} {moe_total_flops:>20.2e}\")\n",
        "print(f\"{'GPU-hours (4xH100, 30% MFU)':<30} {dense_gpu_hours:>14.6f} {moe_gpu_hours:>20.6f}\")\n",
        "print(f\"{'Memory (bf16 weights)':<30} {dense_mem_gb:>13.1f}G {moe_mem_gb:>19.1f}G\")\n",
        "print(f\"{'FLOPs/token ratio vs dense':<30} {'1.0x':>14} {moe_flops_per_token/dense_flops_per_token:>19.2f}x\")\n",
        "print()\n",
        "print(\"Key takeaways:\")\n",
        "print(f\"- The MoE uses {moe_flops_per_token/dense_flops_per_token:.1%} of the dense model's FLOPs/token\")\n",
        "print(f\"  ({moe_active_params/1e9:.1f}B active vs {dense_params/1e9:.0f}B), so it's ~{dense_flops_per_token/moe_flops_per_token:.1f}x cheaper per token.\")\n",
        "print(f\"- But the MoE needs {moe_mem_gb:.0f} GB vs {dense_mem_gb:.0f} GB for weights — {moe_mem_gb/dense_mem_gb:.1f}x more memory.\")\n",
        "print(f\"- Choose the dense model when memory is constrained (e.g., fewer/smaller GPUs)\")\n",
        "print(f\"  or when you need simpler serving (no expert routing overhead).\")\n",
        "print(f\"  Choose the MoE when you have enough memory and want lower cost per token.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "445d8394",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "H100 machine balance: 295.2 FLOPs/byte\n",
            "\n",
            "For MoE decode (P_active = 3.2B):\n",
            "  Compute per step = B × 2 × 3.20e+09 = B × 6.40e+09 FLOPs\n",
            "  Memory per step  = 3.20e+09 × 2 bytes = 6.40e+09 bytes\n",
            "  Arithmetic intensity = B FLOPs/byte\n",
            "\n",
            "Critical batch size = machine balance = 295\n",
            "\n",
            "  B < 295: memory-bandwidth-bound (GPU waits on HBM reads)\n",
            "  B > 295: compute-bound (GPU arithmetic units are the bottleneck)\n",
            "\n",
            "At batch size 1, we achieve only ~1/295 of peak compute utilization,\n",
            "which explains the very low MFU observed in the throughput measurement above.\n"
          ]
        }
      ],
      "source": [
        "# Bonus: Arithmetic intensity analysis\n",
        "# Find the critical batch size where MoE decode becomes compute-bound on H100.\n",
        "\n",
        "# H100 specs (per GPU)\n",
        "h100_compute = 989e12      # FP16 peak FLOPS\n",
        "h100_bandwidth = 3.35e12   # HBM bandwidth in bytes/sec\n",
        "\n",
        "# Machine balance point: the arithmetic intensity (FLOPs/byte) where\n",
        "# compute and memory bandwidth are both fully utilized.\n",
        "machine_balance = h100_compute / h100_bandwidth\n",
        "print(f\"H100 machine balance: {machine_balance:.1f} FLOPs/byte\")\n",
        "\n",
        "# During autoregressive decode at batch size B:\n",
        "#   Compute = B * 2 * P_active FLOPs  (one forward pass per token, B tokens in parallel)\n",
        "#   Memory  = P_active * 2 bytes      (load active weights once from HBM, bf16)\n",
        "#\n",
        "# Arithmetic intensity = compute / memory = (B * 2 * P_active) / (P_active * 2) = B\n",
        "#\n",
        "# The arithmetic intensity equals the batch size! This is because each weight\n",
        "# element is loaded once but used B times (once per sequence in the batch).\n",
        "\n",
        "print(f\"\\nFor MoE decode (P_active = {moe_active_params/1e9:.1f}B):\")\n",
        "print(f\"  Compute per step = B × 2 × {moe_active_params:.2e} = B × {2*moe_active_params:.2e} FLOPs\")\n",
        "print(f\"  Memory per step  = {moe_active_params:.2e} × 2 bytes = {moe_active_params*2:.2e} bytes\")\n",
        "print(f\"  Arithmetic intensity = B FLOPs/byte\")\n",
        "print()\n",
        "\n",
        "critical_batch = int(machine_balance)\n",
        "print(f\"Critical batch size = machine balance = {critical_batch}\")\n",
        "print(f\"\\n  B < {critical_batch}: memory-bandwidth-bound (GPU waits on HBM reads)\")\n",
        "print(f\"  B > {critical_batch}: compute-bound (GPU arithmetic units are the bottleneck)\")\n",
        "print(f\"\\nAt batch size 1, we achieve only ~1/{critical_batch} of peak compute utilization,\")\n",
        "print(f\"which explains the very low MFU observed in the throughput measurement above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88ba77a1",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27f966c4",
      "metadata": {},
      "source": [
        "## Single-Strategy Rephrasing (Guided, 15 pts)\n",
        "\n",
        "Time to use NeMo Data Designer. The core pattern is straightforward: seed documents go in,\n",
        "rephrased documents come out. An LLM text column takes a prompt template, fills in\n",
        "seed columns via Jinja2, and generates new text.\n",
        "\n",
        "The Nemotron-CC paper (Parmar et al., 2024) defines several named rephrasing\n",
        "strategies: **Open Rewrite** (Wikipedia-style), **Diverse QA**, **Knowledge\n",
        "Extraction**, **Knowledge List**, and others. Each strategy transforms source\n",
        "documents into a different format, surfacing different aspects of the content.\n",
        "Even simple rephrasing of low-quality web documents improves pre-training data\n",
        "quality. The key is the prompt that controls the style, tone, and structure of the\n",
        "output. Here we implement the **Wikipedia-style rephrase** (Open Rewrite) strategy\n",
        "as a guided introduction to the NeMo Data Designer pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46b7281f",
      "metadata": {},
      "source": [
        "### Your Task\n",
        "\n",
        "1. Implement the **Wikipedia-style rephrase** strategy from Nemotron-CC (also referred to as \"Open Rewrite\" in the paper). This strategy rewrites each source document as a clean encyclopedia entry. Build the pipeline using `LLMTextColumnConfig`.\n",
        "2. Run `preview()` on 3 records and inspect the output. Compare original vs. rephrased text for at least 2 documents.\n",
        "3. Estimate the FLOPs cost of running this strategy across your full dataset.\n",
        "4. In 2-3 sentences: Is information preserved, lost, or added? How does the structure change?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b881eb76",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build a single-strategy rephrasing pipeline.\n",
        "# Each pipeline gets its own config builder so we can compare outputs later.\n",
        "\n",
        "from data_designer.config import DataDesignerConfigBuilder, LLMTextColumnConfig\n",
        "\n",
        "single_strategy = DataDesignerConfigBuilder(model_configs=model_configs)\n",
        "single_strategy = single_strategy.with_seed_dataset(seed_source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af22dd75",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataDesignerConfigBuilder(\n",
            "    seed_dataset: local seed\n",
            "    llm_text_columns: ['wiki_rephrase']\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Add the rephrasing column. The prompt instructs the model to rewrite the source\n",
        "# document as a clean Wikipedia-style encyclopedia entry, preserving facts while\n",
        "# improving clarity and structure.\n",
        "\n",
        "wiki_rephrase_prompt = \"\"\"\\\n",
        "Rewrite the following document as a clean, well-structured Wikipedia-style encyclopedia entry. \\\n",
        "Preserve all factual information from the original text. Improve clarity, organization, and \\\n",
        "readability. Use a neutral, encyclopedic tone. Add section headings where appropriate. \\\n",
        "Do not add information that is not in the original document. Output only the rewritten article.\n",
        "\n",
        "Title: {{ title }}\n",
        "\n",
        "Original document:\n",
        "{{ text }}\n",
        "\"\"\"\n",
        "\n",
        "single_strategy = single_strategy.add_column(\n",
        "    LLMTextColumnConfig(\n",
        "        name=\"wiki_rephrase\",\n",
        "        prompt=wiki_rephrase_prompt,\n",
        "        model_alias=\"rephraser\",\n",
        "    )\n",
        ")\n",
        "print(single_strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7774849",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[09:43:04] [INFO] 🖼️ Preview generation in progress\n",
            "[09:43:05] [INFO] ✅ Validation passed\n",
            "[09:43:05] [INFO] ⛓️ Sorting column configs into a Directed Acyclic Graph\n",
            "[09:43:05] [INFO] 🩺 Running health checks for models...\n",
            "[09:43:05] [INFO]   |-- 👀 Checking 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16' in provider named 'local-vllm' for model alias 'rephraser'...\n",
            "[09:43:05] [INFO]   |-- ✅ Passed!\n",
            "[09:43:06] [INFO] 🌱 Sampling 3 records from seed dataset\n",
            "[09:43:06] [INFO]   |-- seed dataset size: 18 records\n",
            "[09:43:06] [INFO]   |-- sampling strategy: ordered\n",
            "[09:43:06] [INFO] 📝 llm-text model config for column 'wiki_rephrase'\n",
            "[09:43:06] [INFO]   |-- model: 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16'\n",
            "[09:43:06] [INFO]   |-- model alias: 'rephraser'\n",
            "[09:43:06] [INFO]   |-- model provider: 'local-vllm'\n",
            "[09:43:06] [INFO]   |-- inference parameters:\n",
            "[09:43:06] [INFO]   |  |-- generation_type=chat-completion\n",
            "[09:43:06] [INFO]   |  |-- max_parallel_requests=4\n",
            "[09:43:06] [INFO]   |  |-- extra_body={'chat_template_kwargs': {'enable_thinking': False}}\n",
            "[09:43:06] [INFO]   |  |-- temperature=0.70\n",
            "[09:43:06] [INFO]   |  |-- max_tokens=2048\n",
            "[09:43:06] [INFO] ⚡️ Processing llm-text column 'wiki_rephrase' with 4 concurrent workers\n",
            "[09:43:06] [INFO] ⏱️ llm-text column 'wiki_rephrase' will report progress after each record\n",
            "[09:43:08] [INFO]   |-- 🌘 llm-text column 'wiki_rephrase' progress: 1/3 (33%) complete, 1 ok, 0 failed, 0.38 rec/s, eta 5.3s\n",
            "[09:43:09] [INFO]   |-- 🌗 llm-text column 'wiki_rephrase' progress: 2/3 (67%) complete, 2 ok, 0 failed, 0.57 rec/s, eta 1.7s\n",
            "[09:43:10] [INFO]   |-- 🌕 llm-text column 'wiki_rephrase' progress: 3/3 (100%) complete, 3 ok, 0 failed, 0.61 rec/s, eta 0.0s\n",
            "[09:43:11] [INFO] 📊 Model usage summary:\n",
            "[09:43:11] [INFO]   |-- model: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\n",
            "[09:43:11] [INFO]   |-- tokens: input=7113, output=3033, total=10146, tps=1984\n",
            "[09:43:11] [INFO]   |-- requests: success=3, failed=0, total=3, rpm=35\n",
            "[09:43:11] [INFO] 📐 Measuring dataset column statistics:\n",
            "[09:43:11] [INFO]   |-- 📝 column: 'wiki_rephrase'\n",
            "[09:43:11] [INFO] 🏆 Preview complete!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preview shape: (3, 9)\n",
            "Columns: ['text', 'title', 'id', 'url', 'language', 'source_id', 'file_name', 'categories', 'wiki_rephrase']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>language</th>\n",
              "      <th>source_id</th>\n",
              "      <th>file_name</th>\n",
              "      <th>categories</th>\n",
              "      <th>wiki_rephrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Interoperability is a characteristic of a prod...</td>\n",
              "      <td>Interoperability</td>\n",
              "      <td>41285</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Interoperability</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Interoperability, Computing terminology, Tele...</td>\n",
              "      <td>Interoperability  \\n\\nInteroperability is a pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In communications and computing, a machine-rea...</td>\n",
              "      <td>Machine-readable medium and data</td>\n",
              "      <td>41341</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Machine-readable...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Machine-readable medium and data, Computing t...</td>\n",
              "      <td>**Machine-readable medium and data**\\n\\nA mach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maintainability is the ease of maintaining or ...</td>\n",
              "      <td>Maintainability</td>\n",
              "      <td>41347</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Maintainability</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Maintainability, Telecommunications engineeri...</td>\n",
              "      <td>**Maintainability**\\n\\nMaintainability is the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  Interoperability is a characteristic of a prod...   \n",
              "1  In communications and computing, a machine-rea...   \n",
              "2  Maintainability is the ease of maintaining or ...   \n",
              "\n",
              "                              title     id  \\\n",
              "0                  Interoperability  41285   \n",
              "1  Machine-readable medium and data  41341   \n",
              "2                   Maintainability  41347   \n",
              "\n",
              "                                                 url language  \\\n",
              "0     https://en.wikipedia.org/wiki/Interoperability       en   \n",
              "1  https://en.wikipedia.org/wiki/Machine-readable...       en   \n",
              "2      https://en.wikipedia.org/wiki/Maintainability       en   \n",
              "\n",
              "                                           source_id  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                           file_name  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                          categories  \\\n",
              "0  [Interoperability, Computing terminology, Tele...   \n",
              "1  [Machine-readable medium and data, Computing t...   \n",
              "2  [Maintainability, Telecommunications engineeri...   \n",
              "\n",
              "                                       wiki_rephrase  \n",
              "0  Interoperability  \\n\\nInteroperability is a pr...  \n",
              "1  **Machine-readable medium and data**\\n\\nA mach...  \n",
              "2  **Maintainability**\\n\\nMaintainability is the ...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview generates a small sample so we can inspect quality before scaling up.\n",
        "\n",
        "single_preview = data_designer.preview(single_strategy, num_records=3)\n",
        "single_preview_df = single_preview.dataset\n",
        "print(f\"Preview shape: {single_preview_df.shape}\")\n",
        "print(f\"Columns: {list(single_preview_df.columns)}\")\n",
        "single_preview_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3c6822e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Document 0: Interoperability\n",
            "\n",
            "--- ORIGINAL (first 500 chars) ---\n",
            "Interoperability is a characteristic of a product or system to work with other products or systems. While the term was initially defined for information technology or systems engineering services to allow for information exchange, a broader definition takes into account social, political, and organizational factors that impact system-to-system performance.\n",
            "\n",
            "Types of interoperability include syntactic interoperability, where two systems can communicate with each other, and cross-domain interopera\n",
            "\n",
            "--- REPHRASED (first 500 chars) ---\n",
            "Interoperability  \n",
            "\n",
            "Interoperability is a property of a product or system that enables it to work seamlessly with other products or systems. Initially defined in the context of information technology and systems engineering to facilitate information exchange, the concept has broadened to include social, political, and organizational dimensions that influence system-to-system performance.  \n",
            "\n",
            "Interoperability enables diverse systems—whether technological, institutional, or social—to exchange data,\n",
            "\n",
            "================================================================================\n",
            "Document 1: Machine-readable medium and data\n",
            "\n",
            "--- ORIGINAL (first 500 chars) ---\n",
            "In communications and computing, a machine-readable medium (or computer-readable medium) is a medium capable of storing data in a format easily readable by a digital computer or a sensor. \n",
            "It contrasts with human-readable medium and data.\n",
            "\n",
            "The result is called machine-readable data or computer-readable data, and the data itself can be described as having machine-readability.\n",
            "\n",
            "Data\n",
            "Machine-readable data must be structured data.\n",
            "\n",
            "Attempts to create machine-readable data occurred as early as the 19\n",
            "\n",
            "--- REPHRASED (first 500 chars) ---\n",
            "**Machine-readable medium and data**\n",
            "\n",
            "A machine-readable medium (also called a computer-readable medium) is a physical or logical structure capable of storing data in a form that can be easily processed by a digital computer or sensor without human intervention. It stands in contrast to human-readable media, which are intended primarily for perception and comprehension by people. Machine-readable data are structured data that meet the criteria for such processing.\n",
            "\n",
            "The concept emerged in the 196\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compare original vs. rephrased for the first document\n",
        "\n",
        "for i in range(min(2, len(single_preview_df))):\n",
        "    row = single_preview_df.iloc[i]\n",
        "    print(f\"{'=' * 80}\")\n",
        "    print(f\"Document {i}: {row['title']}\")\n",
        "    print(f\"\\n--- ORIGINAL (first 500 chars) ---\")\n",
        "    print(row[\"text\"][:500])\n",
        "    print(f\"\\n--- REPHRASED (first 500 chars) ---\")\n",
        "    print(row[\"wiki_rephrase\"][:500])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c3b3bf56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg input tokens/doc:   ~2009\n",
            "Avg output tokens/doc:  ~2009\n",
            "Total tokens (all docs): ~72,324\n",
            "FLOPs/token (3.2B MoE):  6.40e+09\n",
            "Total FLOPs:             4.63e+14\n",
            "GPU-hours (4xH100):      0.000108\n",
            "\n",
            "Information is largely preserved but restructured: the rephrase adds\n",
            "section headings, smooths prose, and removes informal/redundant phrasing.\n",
            "Some granular detail may be lost (e.g., niche examples), while the overall\n",
            "structure becomes more encyclopedic and readable.\n"
          ]
        }
      ],
      "source": [
        "# Estimate FLOPs for single-strategy rephrasing of the full dataset.\n",
        "# Each document: ~500 input tokens (source) + ~500 output tokens (rephrased)\n",
        "\n",
        "avg_input_tokens = int(approx_tokens / len(seed_df))\n",
        "avg_output_tokens = avg_input_tokens  # rephrased output roughly matches input length\n",
        "tokens_per_doc = avg_input_tokens + avg_output_tokens\n",
        "\n",
        "single_total_flops = len(seed_df) * tokens_per_doc * moe_flops_per_token\n",
        "single_gpu_hours = single_total_flops / effective_flops_per_sec / 3600\n",
        "\n",
        "print(f\"Avg input tokens/doc:   ~{avg_input_tokens}\")\n",
        "print(f\"Avg output tokens/doc:  ~{avg_output_tokens}\")\n",
        "print(f\"Total tokens (all docs): ~{len(seed_df) * tokens_per_doc:,}\")\n",
        "print(f\"FLOPs/token (3.2B MoE):  {moe_flops_per_token:.2e}\")\n",
        "print(f\"Total FLOPs:             {single_total_flops:.2e}\")\n",
        "print(f\"GPU-hours (4xH100):      {single_gpu_hours:.6f}\")\n",
        "print()\n",
        "print(\"Information is largely preserved but restructured: the rephrase adds\")\n",
        "print(\"section headings, smooths prose, and removes informal/redundant phrasing.\")\n",
        "print(\"Some granular detail may be lost (e.g., niche examples), while the overall\")\n",
        "print(\"structure becomes more encyclopedic and readable.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb4ef193",
      "metadata": {},
      "source": [
        "Explore: How does the rephrased text differ from the original? Is information\n",
        "preserved? Lost? Added?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f1555da",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af181d6a",
      "metadata": {},
      "source": [
        "## Diverse-QA Generation (Scaffolded, 20 pts)\n",
        "\n",
        "Nemotron-CC (Parmar et al., 2024) showed that diverse QA pairs derived from source\n",
        "documents are effective for pre-training data augmentation. Instead of a single\n",
        "rephrasing style, we generate multiple question types (yes/no, open-ended, and\n",
        "multiple-choice), all grounded in the source material.\n",
        "\n",
        "This section introduces **structured outputs**: NeMo Data Designer can enforce a Pydantic\n",
        "schema on the LLM output, guaranteeing that the generated JSON conforms to a\n",
        "well-defined structure. This is essential for QA pairs where we need typed fields\n",
        "(question, answer, question type, optional choices)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d326d95",
      "metadata": {},
      "source": [
        "### Your Task\n",
        "\n",
        "1. Define a Pydantic schema for structured QA output. Your schema must support at least 3 question types (yes/no, open-ended, multiple-choice) with typed fields for question, answer, question type, and optional choices.\n",
        "2. Build a Diverse-QA pipeline using `LLMStructuredColumnConfig` with your schema.\n",
        "3. Add an `ExpressionColumnConfig` that formats the structured QA into a training-ready text string.\n",
        "4. Run `preview()` on 3 records. Inspect the generated QA pairs: Are the questions grounded in the source text? Is the question type distribution diverse?\n",
        "5. Estimate the per-document and total FLOPs for this strategy and compare to single-strategy rephrasing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2e47120c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Schema defined:\n",
            "{'$defs': {'QAPair': {'properties': {'question': {'description': 'A question grounded in the source document.', 'title': 'Question', 'type': 'string'}, 'answer': {'description': 'The answer to the question, based on the source document.', 'title': 'Answer', 'type': 'string'}, 'question_type': {'description': 'The type of question.', 'enum': ['yes_no', 'open_ended', 'multiple_choice'], 'title': 'Question Type', 'type': 'string'}, 'choices': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Answer choices for multiple-choice questions. None for other types.', 'title': 'Choices'}}, 'required': ['question', 'answer', 'question_type'], 'title': 'QAPair', 'type': 'object'}}, 'properties': {'qa_pairs': {'description': 'A list of diverse QA pairs derived from the source document.', 'items': {'$ref': '#/$defs/QAPair'}, 'minItems': 3, 'title': 'Qa Pairs', 'type': 'array'}}, 'required': ['qa_pairs'], 'title': 'DiverseQAOutput', 'type': 'object'}\n"
          ]
        }
      ],
      "source": [
        "# Define the Pydantic schema for structured QA output.\n",
        "# NeMo Data Designer will enforce this schema on the LLM response, parsing and validating\n",
        "# the JSON automatically.\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "class QAPair(BaseModel):\n",
        "    question: str = Field(description=\"A question grounded in the source document.\")\n",
        "    answer: str = Field(description=\"The answer to the question, based on the source document.\")\n",
        "    question_type: Literal[\"yes_no\", \"open_ended\", \"multiple_choice\"] = Field(\n",
        "        description=\"The type of question.\"\n",
        "    )\n",
        "    choices: list[str] | None = Field(\n",
        "        default=None,\n",
        "        description=\"Answer choices for multiple-choice questions. None for other types.\",\n",
        "    )\n",
        "\n",
        "class DiverseQAOutput(BaseModel):\n",
        "    qa_pairs: list[QAPair] = Field(\n",
        "        description=\"A list of diverse QA pairs derived from the source document.\",\n",
        "        min_length=3,\n",
        "    )\n",
        "\n",
        "print(\"Schema defined:\")\n",
        "print(DiverseQAOutput.model_json_schema())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fdf8b869",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataDesignerConfigBuilder(\n",
            "    seed_dataset: local seed\n",
            "    llm_structured_columns: ['diverse_qa']\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Build the Diverse QA pipeline.\n",
        "\n",
        "from data_designer.config import LLMStructuredColumnConfig, ExpressionColumnConfig\n",
        "\n",
        "diverse_qa_prompt = \"\"\"\\\n",
        "You are given a source document. Generate exactly 3 diverse question-answer pairs grounded \\\n",
        "in the document. You MUST include at least one of each type:\n",
        "- A yes/no question (question_type: \"yes_no\")\n",
        "- An open-ended question (question_type: \"open_ended\")\n",
        "- A multiple-choice question with 4 choices (question_type: \"multiple_choice\", include choices)\n",
        "\n",
        "All answers must be directly supported by the source text. Do not invent facts.\n",
        "\n",
        "Title: {{ title }}\n",
        "\n",
        "Source document:\n",
        "{{ text }}\n",
        "\"\"\"\n",
        "\n",
        "qa_strategy = DataDesignerConfigBuilder(model_configs=model_configs)\n",
        "qa_strategy = qa_strategy.with_seed_dataset(seed_source)\n",
        "qa_strategy = qa_strategy.add_column(\n",
        "    LLMStructuredColumnConfig(\n",
        "        name=\"diverse_qa\",\n",
        "        prompt=diverse_qa_prompt,\n",
        "        model_alias=\"rephraser\",\n",
        "        output_format=DiverseQAOutput,\n",
        "    )\n",
        ")\n",
        "print(qa_strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8e6d50bb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataDesignerConfigBuilder(\n",
            "    seed_dataset: local seed\n",
            "    llm_structured_columns: ['diverse_qa']\n",
            "    expression_columns: ['qa_training_text']\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Format the structured QA output into a training-ready text format.\n",
        "# Each QA pair becomes a passage that could appear in a pre-training corpus.\n",
        "\n",
        "qa_format_expr = \"\"\"\\\n",
        "{% for pair in diverse_qa.qa_pairs %}\\\n",
        "Question ({{ pair.question_type }}): {{ pair.question }}\n",
        "Answer: {{ pair.answer }}\\\n",
        "{% if pair.choices %}\n",
        "Choices: {{ pair.choices }}\\\n",
        "{% endif %}\n",
        "\n",
        "{% endfor %}\\\n",
        "\"\"\"\n",
        "\n",
        "qa_strategy = qa_strategy.add_column(\n",
        "    ExpressionColumnConfig(\n",
        "        name=\"qa_training_text\",\n",
        "        expr=qa_format_expr,\n",
        "        dtype=\"str\",\n",
        "    )\n",
        ")\n",
        "print(qa_strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7095ca10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[09:43:29] [INFO] 👀 Preview generation in progress\n",
            "[09:43:29] [INFO] ✅ Validation passed\n",
            "[09:43:29] [INFO] ⛓️ Sorting column configs into a Directed Acyclic Graph\n",
            "[09:43:29] [INFO] 🩺 Running health checks for models...\n",
            "[09:43:29] [INFO]   |-- 👀 Checking 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16' in provider named 'local-vllm' for model alias 'rephraser'...\n",
            "[09:43:29] [INFO]   |-- ✅ Passed!\n",
            "[09:43:29] [INFO] 🌱 Sampling 3 records from seed dataset\n",
            "[09:43:29] [INFO]   |-- seed dataset size: 18 records\n",
            "[09:43:29] [INFO]   |-- sampling strategy: ordered\n",
            "[09:43:29] [INFO] 🗂️ llm-structured model config for column 'diverse_qa'\n",
            "[09:43:29] [INFO]   |-- model: 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16'\n",
            "[09:43:29] [INFO]   |-- model alias: 'rephraser'\n",
            "[09:43:29] [INFO]   |-- model provider: 'local-vllm'\n",
            "[09:43:29] [INFO]   |-- inference parameters:\n",
            "[09:43:29] [INFO]   |  |-- generation_type=chat-completion\n",
            "[09:43:29] [INFO]   |  |-- max_parallel_requests=4\n",
            "[09:43:29] [INFO]   |  |-- extra_body={'chat_template_kwargs': {'enable_thinking': False}}\n",
            "[09:43:29] [INFO]   |  |-- temperature=0.70\n",
            "[09:43:29] [INFO]   |  |-- max_tokens=2048\n",
            "[09:43:29] [INFO] ⚡️ Processing llm-structured column 'diverse_qa' with 4 concurrent workers\n",
            "[09:43:29] [INFO] ⏱️ llm-structured column 'diverse_qa' will report progress after each record\n",
            "[09:43:30] [INFO]   |-- 🌦️ llm-structured column 'diverse_qa' progress: 1/3 (33%) complete, 1 ok, 0 failed, 1.17 rec/s, eta 1.7s\n",
            "[09:43:30] [INFO]   |-- ⛅ llm-structured column 'diverse_qa' progress: 2/3 (67%) complete, 2 ok, 0 failed, 2.14 rec/s, eta 0.5s\n",
            "[09:43:30] [INFO]   |-- ☀️ llm-structured column 'diverse_qa' progress: 3/3 (100%) complete, 3 ok, 0 failed, 2.38 rec/s, eta 0.0s\n",
            "[09:43:30] [INFO] 🧩 Generating column `qa_training_text` from expression\n",
            "[09:43:31] [INFO] 📊 Model usage summary:\n",
            "[09:43:31] [INFO]   |-- model: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\n",
            "[09:43:31] [INFO]   |-- tokens: input=8211, output=740, total=8951, tps=6265\n",
            "[09:43:31] [INFO]   |-- requests: success=3, failed=0, total=3, rpm=125\n",
            "[09:43:31] [INFO] 📐 Measuring dataset column statistics:\n",
            "[09:43:31] [INFO]   |-- 🗂️ column: 'diverse_qa'\n",
            "[09:43:31] [INFO]   |-- 🧩 column: 'qa_training_text'\n",
            "[09:43:31] [INFO] 🙌 Preview complete!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preview shape: (3, 10)\n",
            "Columns: ['text', 'title', 'id', 'url', 'language', 'source_id', 'file_name', 'categories', 'diverse_qa', 'qa_training_text']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>language</th>\n",
              "      <th>source_id</th>\n",
              "      <th>file_name</th>\n",
              "      <th>categories</th>\n",
              "      <th>diverse_qa</th>\n",
              "      <th>qa_training_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Interoperability is a characteristic of a prod...</td>\n",
              "      <td>Interoperability</td>\n",
              "      <td>41285</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Interoperability</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Interoperability, Computing terminology, Tele...</td>\n",
              "      <td>{'qa_pairs': [{'question': 'Is interoperabilit...</td>\n",
              "      <td>Question (yes_no): Is interoperability defined...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In communications and computing, a machine-rea...</td>\n",
              "      <td>Machine-readable medium and data</td>\n",
              "      <td>41341</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Machine-readable...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Machine-readable medium and data, Computing t...</td>\n",
              "      <td>{'qa_pairs': [{'question': 'Is a machine-reada...</td>\n",
              "      <td>Question (yes_no): Is a machine-readable mediu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maintainability is the ease of maintaining or ...</td>\n",
              "      <td>Maintainability</td>\n",
              "      <td>41347</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Maintainability</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Maintainability, Telecommunications engineeri...</td>\n",
              "      <td>{'qa_pairs': [{'question': 'Is maintainability...</td>\n",
              "      <td>Question (yes_no): Is maintainability defined ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  Interoperability is a characteristic of a prod...   \n",
              "1  In communications and computing, a machine-rea...   \n",
              "2  Maintainability is the ease of maintaining or ...   \n",
              "\n",
              "                              title     id  \\\n",
              "0                  Interoperability  41285   \n",
              "1  Machine-readable medium and data  41341   \n",
              "2                   Maintainability  41347   \n",
              "\n",
              "                                                 url language  \\\n",
              "0     https://en.wikipedia.org/wiki/Interoperability       en   \n",
              "1  https://en.wikipedia.org/wiki/Machine-readable...       en   \n",
              "2      https://en.wikipedia.org/wiki/Maintainability       en   \n",
              "\n",
              "                                           source_id  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                           file_name  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                          categories  \\\n",
              "0  [Interoperability, Computing terminology, Tele...   \n",
              "1  [Machine-readable medium and data, Computing t...   \n",
              "2  [Maintainability, Telecommunications engineeri...   \n",
              "\n",
              "                                          diverse_qa  \\\n",
              "0  {'qa_pairs': [{'question': 'Is interoperabilit...   \n",
              "1  {'qa_pairs': [{'question': 'Is a machine-reada...   \n",
              "2  {'qa_pairs': [{'question': 'Is maintainability...   \n",
              "\n",
              "                                    qa_training_text  \n",
              "0  Question (yes_no): Is interoperability defined...  \n",
              "1  Question (yes_no): Is a machine-readable mediu...  \n",
              "2  Question (yes_no): Is maintainability defined ...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview the Diverse QA pipeline.\n",
        "\n",
        "qa_preview = data_designer.preview(qa_strategy, num_records=3)\n",
        "qa_preview_df = qa_preview.dataset\n",
        "print(f\"Preview shape: {qa_preview_df.shape}\")\n",
        "print(f\"Columns: {list(qa_preview_df.columns)}\")\n",
        "qa_preview_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b0e9394c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Document 0: Interoperability\n",
            "\n",
            "--- Structured QA output ---\n",
            "\n",
            "  QA Pair 1 (yes_no):\n",
            "    Q: Is interoperability defined only in terms of technical communication between systems?\n",
            "    A: No, the source states that interoperability also considers social, political, and organizational factors, not just technical communication.\n",
            "\n",
            "  QA Pair 2 (open_ended):\n",
            "    Q: What is required for semantic interoperability between systems?\n",
            "    A: Both sides must refer to a common information exchange reference model and the content of the information exchange requests must be unambiguously defined.\n",
            "\n",
            "  QA Pair 3 (multiple_choice):\n",
            "    Q: Which of the following is an example of a common data format contributing to syntactic interoperability?\n",
            "    A: XML\n",
            "    Choices: ['XML', 'HTML', 'JSON', 'FTP']\n",
            "\n",
            "--- Training-ready text ---\n",
            "Question (yes_no): Is interoperability defined only in terms of technical communication between systems?\n",
            "Answer: No, the source states that interoperability also considers social, political, and organizational factors, not just technical communication.\n",
            "\n",
            "Question (open_ended): What is required for semantic interoperability between systems?\n",
            "Answer: Both sides must refer to a common information exchange reference model and the content of the information exchange requests must be unambiguously defined.\n",
            "\n",
            "Question (multiple_choice): Which of the following is an example of a common data format contri\n",
            "\n",
            "================================================================================\n",
            "Document 1: Machine-readable medium and data\n",
            "\n",
            "--- Structured QA output ---\n",
            "\n",
            "  QA Pair 1 (yes_no):\n",
            "    Q: Is a machine-readable medium capable of storing data in a format easily readable by a digital computer or a sensor?\n",
            "    A: Yes\n",
            "\n",
            "  QA Pair 2 (open_ended):\n",
            "    Q: What term is used to describe data that can be easily processed by a computer without human intervention and retains its semantic meaning?\n",
            "    A: Machine-readable data\n",
            "\n",
            "  QA Pair 3 (multiple_choice):\n",
            "    Q: Which of the following is NOT listed as an example of machine-readable data format?\n",
            "    A: PDF\n",
            "    Choices: ['CSV', 'XML', 'JSON', 'PDF']\n",
            "\n",
            "--- Training-ready text ---\n",
            "Question (yes_no): Is a machine-readable medium capable of storing data in a format easily readable by a digital computer or a sensor?\n",
            "Answer: Yes\n",
            "\n",
            "Question (open_ended): What term is used to describe data that can be easily processed by a computer without human intervention and retains its semantic meaning?\n",
            "Answer: Machine-readable data\n",
            "\n",
            "Question (multiple_choice): Which of the following is NOT listed as an example of machine-readable data format?\n",
            "Answer: PDF\n",
            "Choices: ['CSV', 'XML', 'JSON', 'PDF']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inspect the generated QA pairs for the first document\n",
        "\n",
        "for i in range(min(2, len(qa_preview_df))):\n",
        "    row = qa_preview_df.iloc[i]\n",
        "    print(f\"{'=' * 80}\")\n",
        "    print(f\"Document {i}: {row['title']}\")\n",
        "    print(f\"\\n--- Structured QA output ---\")\n",
        "    qa_data = row[\"diverse_qa\"]\n",
        "    if isinstance(qa_data, dict) and \"qa_pairs\" in qa_data:\n",
        "        for j, pair in enumerate(qa_data[\"qa_pairs\"]):\n",
        "            print(f\"\\n  QA Pair {j+1} ({pair['question_type']}):\")\n",
        "            print(f\"    Q: {pair['question']}\")\n",
        "            print(f\"    A: {pair['answer'][:200]}\")\n",
        "            if pair.get(\"choices\"):\n",
        "                print(f\"    Choices: {pair['choices']}\")\n",
        "    print(f\"\\n--- Training-ready text ---\")\n",
        "    print(row[\"qa_training_text\"][:600])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9301ae25",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diverse QA cost estimate:\n",
            "  Avg input tokens/doc:    ~2009\n",
            "  Avg output tokens/doc:   ~803\n",
            "  Tokens per doc:          ~2812\n",
            "  Total FLOPs:             3.24e+14\n",
            "\n",
            "Comparison to single-strategy rephrasing:\n",
            "  Single-strategy FLOPs:   4.63e+14\n",
            "  Diverse QA FLOPs:        3.24e+14\n",
            "  Ratio:                   0.70x\n",
            "\n",
            "Diverse QA is cheaper per document because the output is shorter (3 QA pairs\n",
            "vs. a full article rewrite), but the structured JSON format adds overhead.\n",
            "The information density per output token is higher: each QA pair isolates\n",
            "a specific fact, while rephrasing spreads the same facts across more prose.\n"
          ]
        }
      ],
      "source": [
        "# Diverse QA generates more output tokens per document due to structured format.\n",
        "# Estimate: ~500 input + ~800 output (QA pairs are verbose)\n",
        "\n",
        "qa_avg_input = avg_input_tokens\n",
        "qa_avg_output = int(avg_input_tokens * 0.4)  # QA output is shorter but structured (~800 tokens)\n",
        "qa_tokens_per_doc = qa_avg_input + qa_avg_output\n",
        "qa_total_flops = len(seed_df) * qa_tokens_per_doc * moe_flops_per_token\n",
        "\n",
        "print(f\"Diverse QA cost estimate:\")\n",
        "print(f\"  Avg input tokens/doc:    ~{qa_avg_input}\")\n",
        "print(f\"  Avg output tokens/doc:   ~{qa_avg_output}\")\n",
        "print(f\"  Tokens per doc:          ~{qa_tokens_per_doc}\")\n",
        "print(f\"  Total FLOPs:             {qa_total_flops:.2e}\")\n",
        "print()\n",
        "print(f\"Comparison to single-strategy rephrasing:\")\n",
        "print(f\"  Single-strategy FLOPs:   {single_total_flops:.2e}\")\n",
        "print(f\"  Diverse QA FLOPs:        {qa_total_flops:.2e}\")\n",
        "print(f\"  Ratio:                   {qa_total_flops / single_total_flops:.2f}x\")\n",
        "print()\n",
        "print(\"Diverse QA is cheaper per document because the output is shorter (3 QA pairs\")\n",
        "print(\"vs. a full article rewrite), but the structured JSON format adds overhead.\")\n",
        "print(\"The information density per output token is higher: each QA pair isolates\")\n",
        "print(\"a specific fact, while rephrasing spreads the same facts across more prose.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f22d8b6",
      "metadata": {},
      "source": [
        "Explore: Compare the QA training text with the single-strategy rephrased text.\n",
        "Which format carries more information per token?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9519efe2",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9229d13",
      "metadata": {},
      "source": [
        "## Multi-Strategy Pipeline (Open-Ended, 25 pts)\n",
        "\n",
        "BeyondWeb (Xu et al., 2025) showed that **multi-strategy diversity prevents\n",
        "saturation** during pre-training. A single rephrasing strategy, no matter how good,\n",
        "eventually stops providing new signal. The paper reports +3.7 percentage points over\n",
        "single-strategy rephrasing by combining multiple approaches.\n",
        "\n",
        "The insight: each strategy surfaces different aspects of the source material. QA pairs\n",
        "exercise retrieval and reasoning, distilled passages compress information, knowledge\n",
        "extracts restructure for pedagogy, and organized lists surface atomic facts.\n",
        "\n",
        "In this section, implement a multi-strategy pipeline combining **at least 3**\n",
        "rephrasing approaches. Estimate total FLOPs and justify your compute allocation\n",
        "across strategies. The reference solution implements 4 strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a12e5ec7",
      "metadata": {},
      "source": [
        "### Your Task\n",
        "\n",
        "1. Design and implement a multi-strategy pipeline with **at least 3** distinct rephrasing strategies. Each strategy should be a separate column in the `DataDesignerConfigBuilder`. The reference solution uses 4: Diverse QA, Distill, Knowledge Extract, and Knowledge List.\n",
        "2. Run `preview()` on 2 records and compare all strategies side-by-side for at least one document.\n",
        "3. Compute the per-strategy and total FLOPs. Present a breakdown showing the compute allocation across your strategies.\n",
        "4. In 3-5 sentences: Justify your strategy choices. Why these strategies? How do they complement each other? Where is there redundancy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5a8ce563",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataDesignerConfigBuilder(\n",
            "    seed_dataset: local seed\n",
            "    llm_text_columns: ['distill', 'knowledge_extract', 'knowledge_list']\n",
            "    llm_structured_columns: ['diverse_qa']\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Build a multi-strategy pipeline with 4 rephrasing columns.\n",
        "# Each column applies a different transformation to the same source documents.\n",
        "\n",
        "multi_strategy = DataDesignerConfigBuilder(model_configs=model_configs)\n",
        "multi_strategy = multi_strategy.with_seed_dataset(seed_source)\n",
        "\n",
        "# Strategy 1: Diverse QA (reuse prompt from earlier)\n",
        "multi_strategy = multi_strategy.add_column(\n",
        "    LLMStructuredColumnConfig(\n",
        "        name=\"diverse_qa\",\n",
        "        prompt=diverse_qa_prompt,\n",
        "        model_alias=\"rephraser\",\n",
        "        output_format=DiverseQAOutput,\n",
        "    )\n",
        ")\n",
        "\n",
        "# Strategy 2: Distill — compress the document into a concise, information-dense passage\n",
        "distill_prompt = \"\"\"\\\n",
        "Distill the following document into a concise, information-dense passage of 2-3 paragraphs. \\\n",
        "Preserve all key facts, definitions, and relationships. Remove redundancy, examples, \\\n",
        "and verbose explanations. The result should read as a self-contained summary that \\\n",
        "captures the essence of the original. Output only the distilled passage.\n",
        "\n",
        "Title: {{ title }}\n",
        "\n",
        "Source document:\n",
        "{{ text }}\n",
        "\"\"\"\n",
        "multi_strategy = multi_strategy.add_column(\n",
        "    LLMTextColumnConfig(\n",
        "        name=\"distill\",\n",
        "        prompt=distill_prompt,\n",
        "        model_alias=\"rephraser\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Strategy 3: Knowledge Extract — restructure as a pedagogical explanation\n",
        "knowledge_extract_prompt = \"\"\"\\\n",
        "Rewrite the following document as a clear, pedagogical explanation suitable for a \\\n",
        "textbook or educational reference. Organize the content logically with section headings. \\\n",
        "Define technical terms when they first appear. Use a teaching tone that builds concepts \\\n",
        "progressively. Output only the rewritten educational text.\n",
        "\n",
        "Title: {{ title }}\n",
        "\n",
        "Source document:\n",
        "{{ text }}\n",
        "\"\"\"\n",
        "multi_strategy = multi_strategy.add_column(\n",
        "    LLMTextColumnConfig(\n",
        "        name=\"knowledge_extract\",\n",
        "        prompt=knowledge_extract_prompt,\n",
        "        model_alias=\"rephraser\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Strategy 4: Knowledge List — extract atomic facts as a structured list\n",
        "knowledge_list_prompt = \"\"\"\\\n",
        "Extract all important facts, definitions, and relationships from the following document \\\n",
        "as a numbered list of concise, self-contained statements. Each item should express exactly \\\n",
        "one fact. Be comprehensive — aim for at least 10 items. Output only the numbered list.\n",
        "\n",
        "Title: {{ title }}\n",
        "\n",
        "Source document:\n",
        "{{ text }}\n",
        "\"\"\"\n",
        "multi_strategy = multi_strategy.add_column(\n",
        "    LLMTextColumnConfig(\n",
        "        name=\"knowledge_list\",\n",
        "        prompt=knowledge_list_prompt,\n",
        "        model_alias=\"rephraser\",\n",
        "    )\n",
        ")\n",
        "\n",
        "print(multi_strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "028e7b5e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[09:43:45] [INFO] 👁️ Preview generation in progress\n",
            "[09:43:46] [INFO] ✅ Validation passed\n",
            "[09:43:46] [INFO] ⛓️ Sorting column configs into a Directed Acyclic Graph\n",
            "[09:43:46] [INFO] 🩺 Running health checks for models...\n",
            "[09:43:46] [INFO]   |-- 👀 Checking 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16' in provider named 'local-vllm' for model alias 'rephraser'...\n",
            "[09:43:46] [INFO]   |-- ✅ Passed!\n",
            "[09:43:46] [INFO] 🌱 Sampling 2 records from seed dataset\n",
            "[09:43:46] [INFO]   |-- seed dataset size: 18 records\n",
            "[09:43:46] [INFO]   |-- sampling strategy: ordered\n",
            "[09:43:46] [INFO] 🗂️ llm-structured model config for column 'diverse_qa'\n",
            "[09:43:46] [INFO]   |-- model: 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16'\n",
            "[09:43:46] [INFO]   |-- model alias: 'rephraser'\n",
            "[09:43:46] [INFO]   |-- model provider: 'local-vllm'\n",
            "[09:43:46] [INFO]   |-- inference parameters:\n",
            "[09:43:46] [INFO]   |  |-- generation_type=chat-completion\n",
            "[09:43:46] [INFO]   |  |-- max_parallel_requests=4\n",
            "[09:43:46] [INFO]   |  |-- extra_body={'chat_template_kwargs': {'enable_thinking': False}}\n",
            "[09:43:46] [INFO]   |  |-- temperature=0.70\n",
            "[09:43:46] [INFO]   |  |-- max_tokens=2048\n",
            "[09:43:46] [INFO] ⚡️ Processing llm-structured column 'diverse_qa' with 4 concurrent workers\n",
            "[09:43:46] [INFO] ⏱️ llm-structured column 'diverse_qa' will report progress after each record\n",
            "[09:43:47] [INFO]   |-- 😐 llm-structured column 'diverse_qa' progress: 1/2 (50%) complete, 1 ok, 0 failed, 1.17 rec/s, eta 0.9s\n",
            "[09:43:47] [INFO]   |-- 🤩 llm-structured column 'diverse_qa' progress: 2/2 (100%) complete, 2 ok, 0 failed, 1.86 rec/s, eta 0.0s\n",
            "[09:43:47] [INFO] 📝 llm-text model config for column 'distill'\n",
            "[09:43:47] [INFO]   |-- model: 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16'\n",
            "[09:43:47] [INFO]   |-- model alias: 'rephraser'\n",
            "[09:43:47] [INFO]   |-- model provider: 'local-vllm'\n",
            "[09:43:47] [INFO]   |-- inference parameters:\n",
            "[09:43:47] [INFO]   |  |-- generation_type=chat-completion\n",
            "[09:43:47] [INFO]   |  |-- max_parallel_requests=4\n",
            "[09:43:47] [INFO]   |  |-- extra_body={'chat_template_kwargs': {'enable_thinking': False}}\n",
            "[09:43:47] [INFO]   |  |-- temperature=0.70\n",
            "[09:43:47] [INFO]   |  |-- max_tokens=2048\n",
            "[09:43:47] [INFO] ⚡️ Processing llm-text column 'distill' with 4 concurrent workers\n",
            "[09:43:47] [INFO] ⏱️ llm-text column 'distill' will report progress after each record\n",
            "[09:43:48] [INFO]   |-- 😐 llm-text column 'distill' progress: 1/2 (50%) complete, 1 ok, 0 failed, 0.87 rec/s, eta 1.1s\n",
            "[09:43:48] [INFO]   |-- 🤩 llm-text column 'distill' progress: 2/2 (100%) complete, 2 ok, 0 failed, 1.60 rec/s, eta 0.0s\n",
            "[09:43:48] [INFO] 📝 llm-text model config for column 'knowledge_extract'\n",
            "[09:43:48] [INFO]   |-- model: 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16'\n",
            "[09:43:48] [INFO]   |-- model alias: 'rephraser'\n",
            "[09:43:48] [INFO]   |-- model provider: 'local-vllm'\n",
            "[09:43:48] [INFO]   |-- inference parameters:\n",
            "[09:43:48] [INFO]   |  |-- generation_type=chat-completion\n",
            "[09:43:48] [INFO]   |  |-- max_parallel_requests=4\n",
            "[09:43:48] [INFO]   |  |-- extra_body={'chat_template_kwargs': {'enable_thinking': False}}\n",
            "[09:43:48] [INFO]   |  |-- temperature=0.70\n",
            "[09:43:48] [INFO]   |  |-- max_tokens=2048\n",
            "[09:43:48] [INFO] ⚡️ Processing llm-text column 'knowledge_extract' with 4 concurrent workers\n",
            "[09:43:48] [INFO] ⏱️ llm-text column 'knowledge_extract' will report progress after each record\n",
            "[09:43:53] [INFO]   |-- 😐 llm-text column 'knowledge_extract' progress: 1/2 (50%) complete, 1 ok, 0 failed, 0.19 rec/s, eta 5.4s\n",
            "[09:43:54] [INFO]   |-- 🤩 llm-text column 'knowledge_extract' progress: 2/2 (100%) complete, 2 ok, 0 failed, 0.31 rec/s, eta 0.0s\n",
            "[09:43:54] [INFO] 📝 llm-text model config for column 'knowledge_list'\n",
            "[09:43:54] [INFO]   |-- model: 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16'\n",
            "[09:43:54] [INFO]   |-- model alias: 'rephraser'\n",
            "[09:43:54] [INFO]   |-- model provider: 'local-vllm'\n",
            "[09:43:54] [INFO]   |-- inference parameters:\n",
            "[09:43:54] [INFO]   |  |-- generation_type=chat-completion\n",
            "[09:43:54] [INFO]   |  |-- max_parallel_requests=4\n",
            "[09:43:54] [INFO]   |  |-- extra_body={'chat_template_kwargs': {'enable_thinking': False}}\n",
            "[09:43:54] [INFO]   |  |-- temperature=0.70\n",
            "[09:43:54] [INFO]   |  |-- max_tokens=2048\n",
            "[09:43:54] [INFO] ⚡️ Processing llm-text column 'knowledge_list' with 4 concurrent workers\n",
            "[09:43:54] [INFO] ⏱️ llm-text column 'knowledge_list' will report progress after each record\n",
            "[09:43:56] [INFO]   |-- 🌗 llm-text column 'knowledge_list' progress: 1/2 (50%) complete, 1 ok, 0 failed, 0.64 rec/s, eta 1.6s\n",
            "[09:43:56] [INFO]   |-- 🌕 llm-text column 'knowledge_list' progress: 2/2 (100%) complete, 2 ok, 0 failed, 1.10 rec/s, eta 0.0s\n",
            "[09:43:56] [INFO] 📊 Model usage summary:\n",
            "[09:43:56] [INFO]   |-- model: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\n",
            "[09:43:56] [INFO]   |-- tokens: input=26914, output=5912, total=32826, tps=3023\n",
            "[09:43:56] [INFO]   |-- requests: success=8, failed=0, total=8, rpm=44\n",
            "[09:43:57] [INFO] 📐 Measuring dataset column statistics:\n",
            "[09:43:57] [INFO]   |-- 🗂️ column: 'diverse_qa'\n",
            "[09:43:57] [INFO]   |-- 📝 column: 'distill'\n",
            "[09:43:57] [INFO]   |-- 📝 column: 'knowledge_extract'\n",
            "[09:43:57] [INFO]   |-- 📝 column: 'knowledge_list'\n",
            "[09:43:57] [INFO] ✅ Preview complete!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preview shape: (2, 12)\n",
            "Columns: ['text', 'title', 'id', 'url', 'language', 'source_id', 'file_name', 'categories', 'diverse_qa', 'distill', 'knowledge_extract', 'knowledge_list']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>language</th>\n",
              "      <th>source_id</th>\n",
              "      <th>file_name</th>\n",
              "      <th>categories</th>\n",
              "      <th>diverse_qa</th>\n",
              "      <th>distill</th>\n",
              "      <th>knowledge_extract</th>\n",
              "      <th>knowledge_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Interoperability is a characteristic of a prod...</td>\n",
              "      <td>Interoperability</td>\n",
              "      <td>41285</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Interoperability</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Interoperability, Computing terminology, Tele...</td>\n",
              "      <td>{'qa_pairs': [{'question': 'Does interoperabil...</td>\n",
              "      <td>Interoperability is the capacity of products, ...</td>\n",
              "      <td>**Interoperability: A Textbook‑Style Explanati...</td>\n",
              "      <td>1. Interoperability is a characteristic that e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In communications and computing, a machine-rea...</td>\n",
              "      <td>Machine-readable medium and data</td>\n",
              "      <td>41341</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Machine-readable...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Machine-readable medium and data, Computing t...</td>\n",
              "      <td>{'qa_pairs': [{'question': 'Can machine-readab...</td>\n",
              "      <td>A machine-readable medium is a storage format ...</td>\n",
              "      <td>**Machine-Readable Medium and Data: A Pedagogi...</td>\n",
              "      <td>1. A machine-readable medium is a storage form...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  Interoperability is a characteristic of a prod...   \n",
              "1  In communications and computing, a machine-rea...   \n",
              "\n",
              "                              title     id  \\\n",
              "0                  Interoperability  41285   \n",
              "1  Machine-readable medium and data  41341   \n",
              "\n",
              "                                                 url language  \\\n",
              "0     https://en.wikipedia.org/wiki/Interoperability       en   \n",
              "1  https://en.wikipedia.org/wiki/Machine-readable...       en   \n",
              "\n",
              "                                           source_id  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                           file_name  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                          categories  \\\n",
              "0  [Interoperability, Computing terminology, Tele...   \n",
              "1  [Machine-readable medium and data, Computing t...   \n",
              "\n",
              "                                          diverse_qa  \\\n",
              "0  {'qa_pairs': [{'question': 'Does interoperabil...   \n",
              "1  {'qa_pairs': [{'question': 'Can machine-readab...   \n",
              "\n",
              "                                             distill  \\\n",
              "0  Interoperability is the capacity of products, ...   \n",
              "1  A machine-readable medium is a storage format ...   \n",
              "\n",
              "                                   knowledge_extract  \\\n",
              "0  **Interoperability: A Textbook‑Style Explanati...   \n",
              "1  **Machine-Readable Medium and Data: A Pedagogi...   \n",
              "\n",
              "                                      knowledge_list  \n",
              "0  1. Interoperability is a characteristic that e...  \n",
              "1  1. A machine-readable medium is a storage form...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview the multi-strategy pipeline.\n",
        "\n",
        "multi_preview = data_designer.preview(multi_strategy, num_records=2)\n",
        "multi_preview_df = multi_preview.dataset\n",
        "print(f\"Preview shape: {multi_preview_df.shape}\")\n",
        "print(f\"Columns: {list(multi_preview_df.columns)}\")\n",
        "multi_preview_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8e4e7a8c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document: Interoperability\n",
            "Original length: 29874 chars\n",
            "\n",
            "================================================================================\n",
            "Strategy: distill\n",
            "Length: 2051 chars\n",
            "--------------------------------------------------------------------------------\n",
            "Interoperability is the capacity of products, systems, or organizations to work together effectively, encompassing syntactic, semantic, and organizational dimensions. Syntactic interoperability requires shared data formats and protocols (e.g., XML, SQL), while semantic interoperability demands a common reference model to ensure exchanged information is unambiguously interpreted and used meaningfully by end users. Cross-domain interoperability extends this to social, political, or organizational \n",
            "...\n",
            "\n",
            "================================================================================\n",
            "Strategy: knowledge_extract\n",
            "Length: 9495 chars\n",
            "--------------------------------------------------------------------------------\n",
            "**Interoperability: A Textbook‑Style Explanation**\n",
            "\n",
            "---\n",
            "\n",
            "### 1. What Is Interoperability?\n",
            "\n",
            "**Interoperability** describes the ability of two or more products, systems, or organizations to work together.  \n",
            "- *At its core*, interoperability means that the interacting components can **exchange information and use that information to achieve a shared purpose**.  \n",
            "- The term originally applied to **information technology (IT) and systems engineering**, where it signified the possibility of data excha\n",
            "...\n",
            "\n",
            "================================================================================\n",
            "Strategy: knowledge_list\n",
            "Length: 2868 chars\n",
            "--------------------------------------------------------------------------------\n",
            "1. Interoperability is a characteristic that enables a product or system to work with other products or systems through information exchange.  \n",
            "2. Syntactic interoperability occurs when two systems use common data formats and communication protocols, such as XML and SQL, allowing them to communicate.  \n",
            "3. Semantic interoperability is the ability to automatically interpret exchanged information meaningfully and accurately, requiring a shared reference model.  \n",
            "4. Cross-domain interoperability inv\n",
            "...\n",
            "\n",
            "================================================================================\n",
            "Strategy: diverse_qa\n",
            "Number of QA pairs: 3\n",
            "  QA 1 (yes_no): Does interoperability require common data formats and communication protocols?...\n",
            "  QA 2 (open_ended): What is required to achieve semantic interoperability according to the source do...\n",
            "  QA 3 (multiple_choice): Which of the following is NOT an example of a common data format for syntactic i...\n"
          ]
        }
      ],
      "source": [
        "# Inspect all strategies side-by-side for one document.\n",
        "\n",
        "row = multi_preview_df.iloc[0]\n",
        "print(f\"Document: {row['title']}\")\n",
        "print(f\"Original length: {len(row['text'])} chars\")\n",
        "\n",
        "strategy_cols = [\"distill\", \"knowledge_extract\", \"knowledge_list\"]\n",
        "for col in strategy_cols:\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(f\"Strategy: {col}\")\n",
        "    print(f\"Length: {len(str(row[col]))} chars\")\n",
        "    print(f\"{'-' * 80}\")\n",
        "    print(str(row[col])[:500])\n",
        "    if len(str(row[col])) > 500:\n",
        "        print(\"...\")\n",
        "\n",
        "print(f\"\\n{'=' * 80}\")\n",
        "print(f\"Strategy: diverse_qa\")\n",
        "qa_data = row[\"diverse_qa\"]\n",
        "if isinstance(qa_data, dict) and \"qa_pairs\" in qa_data:\n",
        "    print(f\"Number of QA pairs: {len(qa_data['qa_pairs'])}\")\n",
        "    for j, pair in enumerate(qa_data[\"qa_pairs\"]):\n",
        "        print(f\"  QA {j+1} ({pair['question_type']}): {pair['question'][:80]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581b02be",
      "metadata": {},
      "source": [
        "### Compute Allocation\n",
        "\n",
        "Each strategy requires a full LLM pass over every document. With 4 strategies and a\n",
        "fixed compute budget, the question becomes: what is the best allocation?\n",
        "\n",
        "The BeyondWeb paper found that **equal allocation across strategies** works well in\n",
        "practice. The diversity benefit comes from having *different* perspectives on the\n",
        "same source material, not from over-investing in any single strategy. If\n",
        "compute is limited, prioritize the strategies that produce the most distinct output\n",
        "(QA and Knowledge List are typically more distinct from each other than Distill and\n",
        "Knowledge Extract)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "bd3288a9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Strategy                Out tok/doc   Total tokens        FLOPs\n",
            "-----------------------------------------------------------------\n",
            "diverse_qa                      803         50,616     3.24e+14\n",
            "distill                         602         46,998     3.01e+14\n",
            "knowledge_extract             2,009         72,324     4.63e+14\n",
            "knowledge_list                1,004         54,234     3.47e+14\n",
            "-----------------------------------------------------------------\n",
            "TOTAL                                                  1.43e+15\n",
            "\n",
            "Total GPU-hours (4xH100, 30% MFU): 0.000336\n",
            "Ratio vs single-strategy:          3.10x\n",
            "\n",
            "Strategy justification:\n",
            "These 4 strategies are chosen to maximize output diversity (BeyondWeb's key finding).\n",
            "Diverse QA exercises retrieval and reasoning; Distill compresses and denoises;\n",
            "Knowledge Extract restructures for pedagogy; Knowledge List surfaces atomic facts.\n",
            "QA and Knowledge List are the most distinct from each other — one asks questions,\n",
            "the other states facts. Distill and Knowledge Extract overlap somewhat (both produce\n",
            "prose), but differ in tone (concise vs. pedagogical) and structure.\n"
          ]
        }
      ],
      "source": [
        "# Each strategy requires a full LLM pass over every document.\n",
        "# Estimate output tokens per strategy:\n",
        "\n",
        "strategies = {\n",
        "    \"diverse_qa\":        {\"output_ratio\": 0.4, \"desc\": \"Structured QA pairs (shorter, denser)\"},\n",
        "    \"distill\":           {\"output_ratio\": 0.3, \"desc\": \"Compressed summary (2-3 paragraphs)\"},\n",
        "    \"knowledge_extract\": {\"output_ratio\": 1.0, \"desc\": \"Full pedagogical rewrite\"},\n",
        "    \"knowledge_list\":    {\"output_ratio\": 0.5, \"desc\": \"Numbered atomic facts\"},\n",
        "}\n",
        "\n",
        "total_multi_flops = 0\n",
        "print(f\"{'Strategy':<22} {'Out tok/doc':>12} {'Total tokens':>14} {'FLOPs':>12}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for name, info in strategies.items():\n",
        "    out_tokens = int(avg_input_tokens * info[\"output_ratio\"])\n",
        "    strat_tokens = len(seed_df) * (avg_input_tokens + out_tokens)\n",
        "    strat_flops = strat_tokens * moe_flops_per_token\n",
        "    total_multi_flops += strat_flops\n",
        "    print(f\"{name:<22} {out_tokens:>12,} {strat_tokens:>14,} {strat_flops:>12.2e}\")\n",
        "\n",
        "print(\"-\" * 65)\n",
        "total_multi_gpu_hours = total_multi_flops / effective_flops_per_sec / 3600\n",
        "print(f\"{'TOTAL':<22} {'':>12} {'':>14} {total_multi_flops:>12.2e}\")\n",
        "print(f\"\\nTotal GPU-hours (4xH100, 30% MFU): {total_multi_gpu_hours:.6f}\")\n",
        "print(f\"Ratio vs single-strategy:          {total_multi_flops / single_total_flops:.2f}x\")\n",
        "print()\n",
        "print(\"Strategy justification:\")\n",
        "print(\"These 4 strategies are chosen to maximize output diversity (BeyondWeb's key finding).\")\n",
        "print(\"Diverse QA exercises retrieval and reasoning; Distill compresses and denoises;\")\n",
        "print(\"Knowledge Extract restructures for pedagogy; Knowledge List surfaces atomic facts.\")\n",
        "print(\"QA and Knowledge List are the most distinct from each other — one asks questions,\")\n",
        "print(\"the other states facts. Distill and Knowledge Extract overlap somewhat (both produce\")\n",
        "print(\"prose), but differ in tone (concise vs. pedagogical) and structure.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef4c6da",
      "metadata": {},
      "source": [
        "### Design Takeaways\n",
        "\n",
        "The BeyondWeb paper found that 3B rephrasers produce equivalent quality to 8B at\n",
        "~2.7x less compute. The choice of Nemotron-3 Nano (3.2B active parameters) is\n",
        "well-calibrated for this task: large enough to produce high-quality rephrasings,\n",
        "small enough to keep per-document costs low.\n",
        "\n",
        "Multi-strategy diversity matters more than model size. The cost of 4 strategies is\n",
        "~4x single-strategy compute, but the quality improvement (+3.7pp over single-strategy\n",
        "in BeyondWeb) is typically worth it. The key insight: each additional strategy shows\n",
        "diminishing returns individually, but the *combination* of diverse formats prevents\n",
        "the saturation that limits single-strategy approaches.\n",
        "\n",
        "When scaling to millions of documents, the compute allocation decision becomes a\n",
        "real engineering constraint. The FLOPs framework from Section 4 lets you estimate\n",
        "costs before committing GPU hours."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37bdd2d7",
      "metadata": {},
      "source": [
        "Explore: Compare outputs across all 4 strategies. Which strategies produce the most\n",
        "distinct content? Where is there redundancy?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6db242c8",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8f9a0a4",
      "metadata": {},
      "source": [
        "## Evaluation (10 pts)\n",
        "\n",
        "Two complementary quality signals help us iterate on synthetic data before committing\n",
        "to a full pre-training run. **[GPT-2](https://huggingface.co/openai-community/gpt2) perplexity** measures statistical fit to a\n",
        "pre-trained distribution (how \"predictable\" the text is under a reference model).\n",
        "**LLM-as-judge** scores semantic quality dimensions: coherence, faithfulness, and\n",
        "information density.\n",
        "\n",
        "These measure fundamentally different things. Perplexity captures fluency and\n",
        "predictability; the judge captures whether the text is well-structured, accurate,\n",
        "and informationally rich. The tension between them is informative: a text can be\n",
        "highly coherent but have high perplexity if it uses formatting or structure that\n",
        "GPT-2 has not seen. Conversely, low-perplexity text may be fluent but vacuous.\n",
        "\n",
        "GPT-2 perplexity is one convenient measure of dataset similarity to a pre-training\n",
        "distribution, not the only one. You could substitute a different reference model\n",
        "(e.g., a domain-specific LM) or use other distributional similarity measures\n",
        "(n-gram overlap, embedding distance). We use GPT-2 here because it is small, fast,\n",
        "and provides a baseline comparison to the Curator lab.\n",
        "\n",
        "Frame this honestly: these are **proxy metrics** for iterating before Part B. The\n",
        "real test of synthetic data quality is pre-training performance on downstream\n",
        "benchmarks, which you will measure in Part B."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9191639d",
      "metadata": {},
      "source": [
        "### Your Task\n",
        "\n",
        "1. Load GPT-2 and implement a `compute_perplexity()` function that scores a list of texts.\n",
        "2. Compute perplexity for both original seed data and your single-strategy rephrased output. Report per-document and mean scores.\n",
        "3. Build an LLM-as-judge pipeline using `LLMJudgeColumnConfig` with at least 3 scoring dimensions (e.g., Coherence, Faithfulness, Information Density) on a 1-5 scale.\n",
        "4. Run the judge on your rephrased output and display scores alongside perplexity.\n",
        "5. In 3-5 sentences: How do the two metrics relate? Where do they agree vs. diverge? What does this tell you about proxy metrics for pre-training data quality?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "32c6a28f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8311dba23816425c9b4ca9d25c3a2b49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 loaded on cuda\n",
            "compute_perplexity() ready\n"
          ]
        }
      ],
      "source": [
        "# Load GPT-2 for perplexity evaluation.\n",
        "# We use the same reference model as the Curator lab for continuity.\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").eval()\n",
        "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "gpt2_model = gpt2_model.to(device)\n",
        "\n",
        "def compute_perplexity(texts: list[str], max_length: int = 1024) -> list[float]:\n",
        "    \"\"\"Compute GPT-2 perplexity for each text. Truncates to max_length tokens.\"\"\"\n",
        "    perplexities = []\n",
        "    for text in texts:\n",
        "        encodings = gpt2_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
        "        input_ids = encodings.input_ids.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = gpt2_model(input_ids, labels=input_ids)\n",
        "        perplexities.append(torch.exp(outputs.loss).item())\n",
        "    return perplexities\n",
        "\n",
        "print(f\"GPT-2 loaded on {device}\")\n",
        "print(f\"compute_perplexity() ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8d00a13d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document                                   Original PPL  Rephrased PPL\n",
            "----------------------------------------------------------------------\n",
            "Interoperability                                   23.3           25.1\n",
            "Machine-readable medium and data                   37.2           29.2\n",
            "Maintainability                                    63.2           22.9\n",
            "----------------------------------------------------------------------\n",
            "Mean                                               41.2           25.7\n"
          ]
        }
      ],
      "source": [
        "# Compute perplexity for original seed data and single-strategy rephrased output\n",
        "\n",
        "original_texts = single_preview_df[\"text\"].tolist()\n",
        "rephrased_texts = single_preview_df[\"wiki_rephrase\"].tolist()\n",
        "\n",
        "original_ppl = compute_perplexity(original_texts)\n",
        "rephrased_ppl = compute_perplexity(rephrased_texts)\n",
        "\n",
        "print(f\"{'Document':<40} {'Original PPL':>14} {'Rephrased PPL':>14}\")\n",
        "print(\"-\" * 70)\n",
        "for i in range(len(single_preview_df)):\n",
        "    title = single_preview_df.iloc[i][\"title\"][:38]\n",
        "    print(f\"{title:<40} {original_ppl[i]:>14.1f} {rephrased_ppl[i]:>14.1f}\")\n",
        "print(\"-\" * 70)\n",
        "import statistics\n",
        "print(f\"{'Mean':<40} {statistics.mean(original_ppl):>14.1f} {statistics.mean(rephrased_ppl):>14.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab816664",
      "metadata": {},
      "source": [
        "### Interpreting Perplexity\n",
        "\n",
        "Lower perplexity means the text is more predictable under the GPT-2 distribution.\n",
        "We expect rephrased text to have *different* perplexity, not necessarily lower.\n",
        "Rephrasing adds structure and formatting that GPT-2 may not have seen in its\n",
        "training data. Moderate perplexity is actually desirable: too low means the text\n",
        "is trivially predictable or redundant, too high means it is incoherent or uses\n",
        "highly unfamiliar patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c3ef1982",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[09:45:35] [INFO] 🔭 Preview generation in progress\n",
            "[09:45:35] [INFO] ✅ Validation passed\n",
            "[09:45:35] [INFO] ⛓️ Sorting column configs into a Directed Acyclic Graph\n",
            "[09:45:35] [INFO] 🩺 Running health checks for models...\n",
            "[09:45:35] [INFO]   |-- 👀 Checking 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16' in provider named 'local-vllm' for model alias 'rephraser'...\n",
            "[09:45:35] [INFO]   |-- ✅ Passed!\n",
            "[09:45:35] [INFO] 🌱 Sampling 3 records from seed dataset\n",
            "[09:45:35] [INFO]   |-- seed dataset size: 3 records\n",
            "[09:45:35] [INFO]   |-- sampling strategy: ordered\n",
            "[09:45:35] [INFO] ⚖️ llm-judge model config for column 'quality_judge'\n",
            "[09:45:35] [INFO]   |-- model: 'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16'\n",
            "[09:45:35] [INFO]   |-- model alias: 'rephraser'\n",
            "[09:45:35] [INFO]   |-- model provider: 'local-vllm'\n",
            "[09:45:35] [INFO]   |-- inference parameters:\n",
            "[09:45:35] [INFO]   |  |-- generation_type=chat-completion\n",
            "[09:45:35] [INFO]   |  |-- max_parallel_requests=4\n",
            "[09:45:35] [INFO]   |  |-- extra_body={'chat_template_kwargs': {'enable_thinking': False}}\n",
            "[09:45:35] [INFO]   |  |-- temperature=0.70\n",
            "[09:45:35] [INFO]   |  |-- max_tokens=2048\n",
            "[09:45:35] [INFO] ⚡️ Processing llm-judge column 'quality_judge' with 4 concurrent workers\n",
            "[09:45:35] [INFO] ⏱️ llm-judge column 'quality_judge' will report progress after each record\n",
            "[09:45:37] [INFO]   |-- 😺 llm-judge column 'quality_judge' progress: 1/3 (33%) complete, 1 ok, 0 failed, 0.78 rec/s, eta 2.6s\n",
            "[09:45:37] [INFO]   |-- 😸 llm-judge column 'quality_judge' progress: 2/3 (67%) complete, 2 ok, 0 failed, 1.50 rec/s, eta 0.7s\n",
            "[09:45:37] [INFO]   |-- 🦁 llm-judge column 'quality_judge' progress: 3/3 (100%) complete, 3 ok, 0 failed, 2.20 rec/s, eta 0.0s\n",
            "[09:45:37] [INFO] 📊 Model usage summary:\n",
            "[09:45:37] [INFO]   |-- model: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\n",
            "[09:45:37] [INFO]   |-- tokens: input=5887, output=970, total=6857, tps=4338\n",
            "[09:45:37] [INFO]   |-- requests: success=3, failed=0, total=3, rpm=113\n",
            "[09:45:37] [INFO] 📐 Measuring dataset column statistics:\n",
            "[09:45:37] [INFO]   |-- ⚖️ column: 'quality_judge'\n",
            "[09:45:37] [INFO] 🎉 Preview complete!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Judge results shape: (3, 10)\n",
            "Columns: ['text', 'title', 'id', 'url', 'language', 'source_id', 'file_name', 'categories', 'wiki_rephrase', 'quality_judge']\n"
          ]
        }
      ],
      "source": [
        "# Use NeMo Data Designer's LLM judge to score rephrased output.\n",
        "# We build a small pipeline: seed with the preview results, then judge.\n",
        "\n",
        "from data_designer.config import LLMJudgeColumnConfig\n",
        "from data_designer.config.column_configs import Score\n",
        "\n",
        "judge_prompt = \"\"\"\\\n",
        "You are evaluating a rephrased version of a source document. \\\n",
        "Score the rephrased text on each dimension below.\n",
        "\n",
        "Original title: {{ title }}\n",
        "\n",
        "Original document (first 500 chars):\n",
        "{{ text[:500] }}\n",
        "\n",
        "Rephrased document:\n",
        "{{ wiki_rephrase }}\n",
        "\"\"\"\n",
        "\n",
        "scores = [\n",
        "    Score(\n",
        "        name=\"coherence\",\n",
        "        description=\"How well-organized, logical, and readable is the rephrased text?\",\n",
        "        options={\n",
        "            1: \"Incoherent or disorganized\",\n",
        "            2: \"Poorly structured with frequent issues\",\n",
        "            3: \"Adequate structure, some rough transitions\",\n",
        "            4: \"Well-organized with clear flow\",\n",
        "            5: \"Excellent structure, highly readable\",\n",
        "        },\n",
        "    ),\n",
        "    Score(\n",
        "        name=\"faithfulness\",\n",
        "        description=\"Does the rephrased text preserve the factual content of the original without hallucinating new information?\",\n",
        "        options={\n",
        "            1: \"Mostly fabricated or contradicts the original\",\n",
        "            2: \"Significant factual errors or omissions\",\n",
        "            3: \"Generally accurate with minor errors\",\n",
        "            4: \"Accurate with very minor omissions\",\n",
        "            5: \"Fully faithful to the original\",\n",
        "        },\n",
        "    ),\n",
        "    Score(\n",
        "        name=\"information_density\",\n",
        "        description=\"How efficiently does the text convey information? High density means more useful content per token.\",\n",
        "        options={\n",
        "            1: \"Extremely verbose or vacuous\",\n",
        "            2: \"Mostly filler with some useful content\",\n",
        "            3: \"Average information density\",\n",
        "            4: \"Dense and informative with little waste\",\n",
        "            5: \"Maximally dense, every sentence adds value\",\n",
        "        },\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Seed the judge pipeline with single_preview_df (which has text, title, wiki_rephrase)\n",
        "judge_seed_path = \"wiki_curated_domain_data/judge_seed.jsonl\"\n",
        "single_preview_df.to_json(judge_seed_path, orient=\"records\", lines=True)\n",
        "judge_seed = LocalFileSeedSource(path=judge_seed_path)\n",
        "\n",
        "judge_pipeline = DataDesignerConfigBuilder(model_configs=model_configs)\n",
        "judge_pipeline = judge_pipeline.with_seed_dataset(judge_seed)\n",
        "judge_pipeline = judge_pipeline.add_column(\n",
        "    LLMJudgeColumnConfig(\n",
        "        name=\"quality_judge\",\n",
        "        prompt=judge_prompt,\n",
        "        model_alias=\"rephraser\",\n",
        "        scores=scores,\n",
        "    )\n",
        ")\n",
        "\n",
        "judge_results = data_designer.preview(judge_pipeline, num_records=len(single_preview_df))\n",
        "judge_df = judge_results.dataset\n",
        "print(f\"Judge results shape: {judge_df.shape}\")\n",
        "print(f\"Columns: {list(judge_df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "7380cd67",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document                        Orig PPL  Reph PPL   coherence faithfulnes information\n",
            "--------------------------------------------------------------------------------------\n",
            "Interoperability                    23.3      25.1           5           5           5\n",
            "Machine-readable medium and         37.2      29.2           4           5           4\n",
            "Maintainability                     63.2      22.9           5           5           5\n",
            "--------------------------------------------------------------------------------------\n",
            "Mean                                41.2      25.7         4.7         5.0         4.7\n",
            "\n",
            "Perplexity and judge scores measure fundamentally different things. Perplexity\n",
            "captures how predictable text is under GPT-2's distribution — rephrased text\n",
            "often has higher perplexity due to added markdown formatting and structural\n",
            "elements GPT-2 rarely saw. Meanwhile, the judge scores semantic quality:\n",
            "coherence and faithfulness can be high even when perplexity is elevated.\n",
            "This divergence shows why a single proxy metric is insufficient — perplexity\n",
            "penalizes novel structure while the judge rewards it. For pre-training data\n",
            "quality, the real test remains downstream benchmark performance in Part B.\n"
          ]
        }
      ],
      "source": [
        "# Display the judge scores alongside perplexity\n",
        "\n",
        "score_names = [\"coherence\", \"faithfulness\", \"information_density\"]\n",
        "\n",
        "def extract_score(judge_val, score_name):\n",
        "    \"\"\"Extract numeric score from the quality_judge structured output.\"\"\"\n",
        "    if isinstance(judge_val, dict) and score_name in judge_val:\n",
        "        entry = judge_val[score_name]\n",
        "        if isinstance(entry, dict) and \"score\" in entry:\n",
        "            return entry[\"score\"]\n",
        "    return None\n",
        "\n",
        "header = f\"{'Document':<30} {'Orig PPL':>9} {'Reph PPL':>9}\"\n",
        "for s in score_names:\n",
        "    header += f\" {s[:11]:>11}\"\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "\n",
        "all_scores = {s: [] for s in score_names}\n",
        "for i in range(len(judge_df)):\n",
        "    title = judge_df.iloc[i][\"title\"][:28]\n",
        "    row_str = f\"{title:<30} {original_ppl[i]:>9.1f} {rephrased_ppl[i]:>9.1f}\"\n",
        "    judge_val = judge_df.iloc[i][\"quality_judge\"]\n",
        "    for s in score_names:\n",
        "        val = extract_score(judge_val, s)\n",
        "        all_scores[s].append(val)\n",
        "        row_str += f\" {val:>11}\" if val is not None else f\" {'N/A':>11}\"\n",
        "    print(row_str)\n",
        "\n",
        "print(\"-\" * len(header))\n",
        "mean_row = f\"{'Mean':<30} {statistics.mean(original_ppl):>9.1f} {statistics.mean(rephrased_ppl):>9.1f}\"\n",
        "for s in score_names:\n",
        "    vals = [v for v in all_scores[s] if v is not None]\n",
        "    mean_row += f\" {statistics.mean(vals):>11.1f}\" if vals else f\" {'N/A':>11}\"\n",
        "print(mean_row)\n",
        "\n",
        "print()\n",
        "print(\"Perplexity and judge scores measure fundamentally different things. Perplexity\")\n",
        "print(\"captures how predictable text is under GPT-2's distribution — rephrased text\")\n",
        "print(\"often has higher perplexity due to added markdown formatting and structural\")\n",
        "print(\"elements GPT-2 rarely saw. Meanwhile, the judge scores semantic quality:\")\n",
        "print(\"coherence and faithfulness can be high even when perplexity is elevated.\")\n",
        "print(\"This divergence shows why a single proxy metric is insufficient — perplexity\")\n",
        "print(\"penalizes novel structure while the judge rewards it. For pre-training data\")\n",
        "print(\"quality, the real test remains downstream benchmark performance in Part B.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1cb7840",
      "metadata": {},
      "source": [
        "### Perplexity vs. Judge: What Do They Tell Us?\n",
        "\n",
        "How do the LLM-as-judge scores relate to GPT-2 perplexity? Do high-coherence texts\n",
        "have lower perplexity? Where do the metrics agree vs. diverge?\n",
        "\n",
        "Perplexity measures statistical fit to GPT-2's training distribution and captures\n",
        "fluency and predictability. The LLM judge captures semantic quality: coherence,\n",
        "faithfulness, information density. These are fundamentally different measurements:\n",
        "a text can be highly coherent but have high perplexity if it uses unfamiliar\n",
        "formatting or structure. The tension between these metrics is informative for\n",
        "understanding what makes good pre-training data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d1ad092",
      "metadata": {},
      "source": [
        "Explore: If you have multi-strategy outputs, compute perplexity and judge scores\n",
        "for each strategy. How do the strategies compare? Which produces the most\n",
        "\"surprising\" (high perplexity) yet high-quality (high judge score) text?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a0eb61",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7605cff0",
      "metadata": {},
      "source": [
        "## Scale Up & Conclusion (10 pts)\n",
        "\n",
        "Time to scale up. Use `create()` instead of `preview()` to generate a full dataset\n",
        "sized for Part B's pre-training run. Students will pre-train Nemotron-Nano-V3 (the\n",
        "hybrid Mamba + MoE + Attention model from Section 4) using this synthetic data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da12f11f",
      "metadata": {},
      "source": [
        "### Your Task\n",
        "\n",
        "1. Run `data_designer.create()` with your multi-strategy pipeline to generate the full dataset. Set `num_records` to match your seed dataset size.\n",
        "2. Inspect the output: report shape, column names, mean character lengths per strategy column.\n",
        "3. Export the dataset to parquet for use in Part B.\n",
        "4. Compute the actual FLOPs consumed (estimate from output token counts).\n",
        "5. In 3-5 sentences: What would change at 10x, 100x, 1000x scale? Which bottlenecks shift?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f4d41e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale up: run full generation with the multi-strategy pipeline.\n",
        "# Adjust num_records based on your seed dataset size and compute budget.\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01ba4c25",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect the generated dataset\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b3ff84",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final cost estimate for the scaled generation.\n",
        "# Use actual token counts from the create() run if available,\n",
        "# otherwise use our per-strategy estimates from Section 7.\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "137a75d8",
      "metadata": {},
      "source": [
        "### Scaling Reflection\n",
        "\n",
        "What would change at 10x, 100x, 1000x scale?\n",
        "\n",
        "At **10x**, the pipeline is the same but you might want to increase\n",
        "`max_parallel_requests` in inference parameters and use tensor parallelism across\n",
        "more GPUs.\n",
        "\n",
        "At **100x**, you need multi-node serving and careful attention to data loading,\n",
        "since the seed dataset itself becomes large.\n",
        "\n",
        "At **1000x** (millions of documents), the cost framework from Section 4 becomes\n",
        "essential: you must choose strategies carefully, as each strategy costs a full pass.\n",
        "The BeyondWeb finding that 3B rephrasers match 8B quality means you can process\n",
        "~2.7x more data for the same compute budget."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc981e7c",
      "metadata": {},
      "source": [
        "### Conclusion\n",
        "\n",
        "In this notebook, you built a complete synthetic pre-training data pipeline using\n",
        "NeMo Data Designer. Starting from curated Wikipedia articles (Part 1a), you\n",
        "learned to:\n",
        "\n",
        "- Boot an inference server and measure throughput\n",
        "- Estimate generation costs using a FLOPs framework\n",
        "- Implement single-strategy and multi-strategy rephrasing pipelines\n",
        "- Generate structured outputs (diverse QA pairs) with Pydantic schemas\n",
        "- Evaluate output quality using perplexity and LLM-as-judge metrics\n",
        "- Scale up for production with `create()`\n",
        "\n",
        "In Part B, you will use this synthetic data to pre-train Nemotron-Nano-V3 and\n",
        "measure its impact on downstream benchmarks. The quality of your synthetic data\n",
        "directly affects training outcomes. The iterative design loop\n",
        "(preview -> inspect -> revise -> create) is how you close that feedback loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425dd577",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up\n",
        "print(\"Done! Your synthetic dataset is ready for Part B.\")\n",
        "print(f\"Output file: wiki_synthetic_multistrategy.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cbbddb7",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "- Parmar, J., Patel, J., Adler, B., et al. \"[Nemotron-CC: Transforming Web Data into\n",
        "  High-Quality Synthetic Data for Language Models.](https://arxiv.org/abs/2412.02595)\" *arXiv:2412.02595*, 2024.\n",
        "\n",
        "- Xu, C., Liu, Z., Shen, Y., et al. \"[BeyondWeb: Multi-Strategy Rephrasing for\n",
        "  Synthetic Pre-Training Data that Goes Beyond the Web.](https://arxiv.org/abs/2506.10426)\" *arXiv:2506.10426*, 2025."
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "NeMo Curator (Curator/.venv)",
      "language": "python",
      "name": "curator-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
