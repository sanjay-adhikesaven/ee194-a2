{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "32f8a22a",
      "metadata": {},
      "source": [
        "# NeMo Curator Lab\n",
        "\n",
        "**Assignment 2, Part a** | UC Berkeley EE 194/290-16: Scalable AI | Spring 2026\n",
        "\n",
        "## Objective\n",
        "\n",
        "In this assignment, students will use NeMo Curator to download and curate Wikipedia data within a chosen domain. Then, they will compare the non-curated data with the curated data and reason about how data curation may impact downstream tasks.\n",
        "\n",
        "This assignment will be scored out of 70 points, with an opportunity to earn an additional 5 bonus points during the evaluation section. Refer to the headings for breakdowns of the scoring rubric.\n",
        "\n",
        "**Deliverable**: Submit this notebook with all cells implemented and run, including each output per cell.\n",
        "\n",
        "## Environment Setup [0 points]\n",
        "\n",
        "Refer to Curator's [Installation Guide](https://docs.nvidia.com/nemo/curator/latest/admin/installation.html) to install and run Curator via Docker or `uv`. If using `uv`, include the `text_cuda12` extra (or install `all` which includes `text_cuda12`). Verify the environment and library setups with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ee46dcae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1.0rc0.dev0\n"
          ]
        }
      ],
      "source": [
        "# verifies curator is installed\n",
        "import nemo_curator\n",
        "\n",
        "print(nemo_curator.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "974c800b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Feb 26 00:37:18 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA H100 80GB HBM3          Off |   00000000:04:00.0 Off |                    0 |\n",
            "| N/A   31C    P0             67W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   1  NVIDIA H100 80GB HBM3          Off |   00000000:05:00.0 Off |                    0 |\n",
            "| N/A   29C    P0             68W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   2  NVIDIA H100 80GB HBM3          Off |   00000000:0B:00.0 Off |                    0 |\n",
            "| N/A   31C    P0             68W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   3  NVIDIA H100 80GB HBM3          Off |   00000000:0C:00.0 Off |                    0 |\n",
            "| N/A   29C    P0             66W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   4  NVIDIA H100 80GB HBM3          Off |   00000000:84:00.0 Off |                    0 |\n",
            "| N/A   31C    P0             68W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   5  NVIDIA H100 80GB HBM3          Off |   00000000:85:00.0 Off |                    0 |\n",
            "| N/A   28C    P0             67W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   6  NVIDIA H100 80GB HBM3          Off |   00000000:8B:00.0 Off |                    0 |\n",
            "| N/A   30C    P0             68W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   7  NVIDIA H100 80GB HBM3          Off |   00000000:8C:00.0 Off |                    0 |\n",
            "| N/A   29C    P0             69W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2e1bf55a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.10.00\n"
          ]
        }
      ],
      "source": [
        "# verifies that gpu dependencies are installed\n",
        "import cudf\n",
        "\n",
        "print(cudf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08394be6",
      "metadata": {},
      "source": [
        "Initialize and start a Ray client:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "962701a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 00:37:32.739\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnemo_curator.core.client\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m115\u001b[0m - \u001b[33m\u001b[1mNo monitoring services are running. Please run the `start_prometheus_grafana.py` script from nemo_curator/metrics folder to setup monitoring services separately.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:32.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36minit_cluster\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mRay start command: ray start --head --node-ip-address 10.128.0.20 --port 6379 --metrics-export-port 8081 --dashboard-host 127.0.0.1 --dashboard-port 8265 --ray-client-server-port 10001 --temp-dir /tmp/ray --disable-usage-stats --num-cpus 32 --block\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:32.781\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36mcheck_ray_responsive\u001b[0m:\u001b[36m38\u001b[0m - \u001b[34m\u001b[1mVerifying Ray cluster is responsive, using RAY_ADDRESS=10.128.0.20:6379\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:32.782\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36mcheck_ray_responsive\u001b[0m:\u001b[36m45\u001b[0m - \u001b[34m\u001b[1mrunning 'ray status' command\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-26 00:37:34,639\tINFO usage_lib.py:447 -- Usage stats collection is disabled.\n",
            "2026-02-26 00:37:34,639\tINFO scripts.py:919 -- \u001b[37mLocal node IP\u001b[39m: \u001b[1m10.128.0.20\u001b[22m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 00:37:36.386\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36mcheck_ray_responsive\u001b[0m:\u001b[36m70\u001b[0m - \u001b[34m\u001b[1mRay cluster is not responsive ('ray status' command failed)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:36.888\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36mcheck_ray_responsive\u001b[0m:\u001b[36m45\u001b[0m - \u001b[34m\u001b[1mrunning 'ray status' command\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:39.347\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36mcheck_ray_responsive\u001b[0m:\u001b[36m58\u001b[0m - \u001b[34m\u001b[1mRay cluster is not responsive ('No cluster status' returned or Error in output)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:39.848\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36mcheck_ray_responsive\u001b[0m:\u001b[36m45\u001b[0m - \u001b[34m\u001b[1mrunning 'ray status' command\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-26 00:37:39,835\tSUCC scripts.py:963 -- \u001b[32m--------------------\u001b[39m\n",
            "2026-02-26 00:37:39,835\tSUCC scripts.py:964 -- \u001b[32mRay runtime started.\u001b[39m\n",
            "2026-02-26 00:37:39,835\tSUCC scripts.py:965 -- \u001b[32m--------------------\u001b[39m\n",
            "2026-02-26 00:37:39,835\tINFO scripts.py:967 -- \u001b[36mNext steps\u001b[39m\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:970 -- To add another node to this Ray cluster, run\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:973 -- \u001b[1m  ray start --address='10.128.0.20:6379'\u001b[22m\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:982 -- To connect to this Ray cluster:\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:984 -- \u001b[35mimport\u001b[39m\u001b[26m ray\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:985 -- ray\u001b[35m.\u001b[39m\u001b[26minit(_node_ip_address\u001b[35m=\u001b[39m\u001b[26m\u001b[33m'10.128.0.20'\u001b[39m\u001b[26m)\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:997 -- To submit a Ray job using the Ray Jobs CLI:\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:998 -- \u001b[1m  RAY_API_SERVER_ADDRESS='http://127.0.0.1:8265' ray job submit --working-dir . -- python my_script.py\u001b[22m\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1007 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html \n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1011 -- for more information on submitting Ray jobs to the Ray cluster.\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1016 -- To terminate the Ray runtime, run\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1017 -- \u001b[1m  ray stop\u001b[22m\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1020 -- To view the status of the cluster, use\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1021 --   \u001b[1mray status\u001b[22m\u001b[26m\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1025 -- To monitor and debug Ray, view the dashboard at \n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1026 --   \u001b[1m127.0.0.1:8265\u001b[22m\u001b[26m\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1033 -- \u001b[4mIf connection to the dashboard fails, check your firewall settings and network configuration.\u001b[24m\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1139 -- \u001b[36m\u001b[1m--block\u001b[22m\u001b[39m\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1140 -- This command will now block forever until terminated by a signal.\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1143 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n",
            "2026-02-26 00:37:39,836\tINFO scripts.py:1148 -- Process exit logs will be saved to: \u001b[1m/tmp/ray/session_2026-02-26_00-37-34_640238_3085280/logs/ray_process_exit.log\u001b[22m\u001b[26m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 00:37:42.150\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36mcheck_ray_responsive\u001b[0m:\u001b[36m58\u001b[0m - \u001b[34m\u001b[1mRay cluster is not responsive ('No cluster status' returned or Error in output)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:42.651\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36mcheck_ray_responsive\u001b[0m:\u001b[36m45\u001b[0m - \u001b[34m\u001b[1mrunning 'ray status' command\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:44.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnemo_curator.core.utils\u001b[0m:\u001b[36mcheck_ray_responsive\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mRay cluster IS responsive\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from nemo_curator.core.client import RayClient\n",
        "\n",
        "ray_client = RayClient(num_cpus=32)\n",
        "ray_client.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7d2ff0",
      "metadata": {},
      "source": [
        "Note: If you encounter out of memory errors while downloading the data, then you may need to stop the Ray client (with `ray_client.stop()`), reduce `num_cpus` above, and start a fresh Ray client.\n",
        "\n",
        "## Data Setup [5 points]\n",
        "\n",
        "Use the following code to download and extract data from the latest Wikipedia dump. Limit it to English text only.\n",
        "\n",
        "You are encouraged to experiment with the URL limit and record limit. Some helpful information:\n",
        "- There are ~70 URLs per dump\n",
        "- The number of JSONL files written == `url_limit`\n",
        "- There are ~20,000 records per URL\n",
        "- The number of rows per JSONL file == `record_limit`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "077ebf58",
      "metadata": {},
      "outputs": [],
      "source": [
        "from nemo_curator.stages.text.download.wikipedia.stage import WikipediaDownloadExtractStage\n",
        "\n",
        "language = \"en\"  # do not change this\n",
        "download_dir = \"./wiki_downloads\"\n",
        "url_limit = 2  # experiment with this\n",
        "record_limit = 100  # experiment with this\n",
        "# Initialize the Wikipedia download stage\n",
        "wiki_stage = WikipediaDownloadExtractStage(\n",
        "    language=language,\n",
        "    download_dir=download_dir,\n",
        "    url_limit=url_limit,\n",
        "    record_limit=record_limit,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2c1c1245",
      "metadata": {},
      "outputs": [],
      "source": [
        "from nemo_curator.stages.text.io.writer.jsonl import JsonlWriter\n",
        "\n",
        "wiki_data_dir = \"./wiki_data\"\n",
        "\n",
        "# Initialize the JSONL writer stage\n",
        "jsonl_writer = JsonlWriter(wiki_data_dir, write_kwargs={\"force_ascii\": False})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "889d74a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 00:37:53.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'wikipedia_en_pipeline' to pipeline 'download_wiki_pipeline'\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:53.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_writer' to pipeline 'download_wiki_pipeline'\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(name='download_wiki_pipeline', stages=[wikipedia_en_pipeline(WikipediaDownloadExtractStage), jsonl_writer(JsonlWriter)])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nemo_curator.pipeline import Pipeline\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipeline = Pipeline(\"download_wiki_pipeline\")\n",
        "\n",
        "# Add the stages to the pipeline\n",
        "pipeline.add_stage(wiki_stage)\n",
        "pipeline.add_stage(jsonl_writer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "27065889",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 00:37:56.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: download_wiki_pipeline\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:56.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mDecomposing composite stage: wikipedia_en_pipeline\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:56.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExpanded 'wikipedia_en_pipeline' into 3 execution stages\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:56.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mExecution mode: STREAMING\u001b[0m\n",
            "2026-02-26 00:37:56,333\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 00:37:56,342\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 00:37:56,356\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "/home/sanjay/ee194-a2/Curator/.venv/lib/python3.10/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
            "  warnings.warn(\n",
            "\u001b[32m2026-02-26 00:37:58.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mPipelineSpec:\n",
            "  config: PipelineConfig(execution_mode=<ExecutionMode.STREAMING: 0>, num_setup_attempts_python=1, num_run_attempts_python=1, max_setup_failure_percentage=None, ignore_failures=False, reset_workers_on_failure=False, slots_per_actor=2, worker_max_lifetime_m=0, worker_restart_interval_m=1, logging_interval_s=60, failures_return_nones=False, return_last_stage_outputs=True, actor_pool_verbosity_level=<VerbosityLevel.INFO: 1>, monitoring_verbosity_level=<VerbosityLevel.INFO: 1>, mode_specific=StreamingSpecificSpec(autoscale_interval_s=180, autoscaler_verbosity_level=<VerbosityLevel.INFO: 1>, executor_verbosity_level=<VerbosityLevel.INFO: 1>), log_worker_allocation_layout=True, cpu_allocation_percentage=0.95, clear_cuda_visible_devices_on_cpu_actors=True)\n",
            "  job_info: None\n",
            "  Stage 0:\n",
            "   class_name: URLGenerationStage\n",
            "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: 1\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 1:\n",
            "   class_name: DocumentDownloadStage\n",
            "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: 2\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 2:\n",
            "   class_name: DocumentIterateExtractStage\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 3:\n",
            "   class_name: JsonlWriter\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 00:37:58.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mInitialized Ray cluster.\u001b[0m\n",
            "2026-02-26 00:37:58,370\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 00:37:58,375\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 00:37:58,376\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
            "\u001b[32m2026-02-26 00:37:58.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.cluster\u001b[0m:\u001b[36minit_or_connect_to_cluster\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mRay dashboard url: 127.0.0.1:8265\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m759\u001b[0m - \u001b[1mDetermining number of nvdecs/nvencs per gpu in this cluster.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m775\u001b[0m - \u001b[1mGpu with name NVIDIA H100 80GB HBM3 found. Looking up nvdecs and nvencs...\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m777\u001b[0m - \u001b[1mFound the following gpu resources: GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mCreated/connected to cluster with resources: PoolOfResources(cpus=30.0, gpus=8.0, nvdecs=56.0, nvencs=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mSetting up fragmentation based autoscaler with problem: Problem(cluster_resources=ClusterResources(nodes={'ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71': NodeResources(cpus=30, gpus=[GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())], name='ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71')}), stages=[ProblemStage(name='Stage 00 - URLGenerationStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=1, over_provision_factor=None), ProblemStage(name='Stage 01 - DocumentDownloadStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=2, over_provision_factor=None), ProblemStage(name='Stage 02 - DocumentIterateExtractStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 03 - JsonlWriter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None)])\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mStarting main loop\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mAutoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mSolving the following naiive allocation problem:\n",
            "{ 'cluster_resources': { 'cpus': 30.0,\n",
            "                         'gpus': 8.0,\n",
            "                         'nvdecs': 56.0,\n",
            "                         'nvencs': 0.0},\n",
            "  'stages': [ { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 00 - URLGenerationStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': 1,\n",
            "                'resources_per_worker': { 'cpus': 0.5,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 01 - DocumentDownloadStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': 2,\n",
            "                'resources_per_worker': { 'cpus': 0.5,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 02 - DocumentIterateExtractStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 03 - JsonlWriter',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1}]}\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mGot the following naiive allocation result:\n",
            "{ 'allocation_result': { 'cluster_resources': { 'cpus': 30.0,\n",
            "                                                'gpus': 8.0,\n",
            "                                                'nvdecs': 56.0,\n",
            "                                                'nvencs': 0.0},\n",
            "                         'stages': [ { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 1,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 00 - '\n",
            "                                                            'URLGenerationStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': 1,\n",
            "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 2,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 01 - '\n",
            "                                                            'DocumentDownloadStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': 2,\n",
            "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 14,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 02 - '\n",
            "                                                            'DocumentIterateExtractStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 14,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 03 - '\n",
            "                                                            'JsonlWriter',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}}],\n",
            "                         'throughput': 1.0},\n",
            "  'num_slots_per_state': [2, 2, 2, 2]}\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36mrun_fragmentation_autoscaler\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mRunning phase 4...\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:01.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mDone calculating autoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:04.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 3.3627045154571533 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:04.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.017218828201293945 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:04.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.007489204406738281 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:04.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 3.3906469345092773 to get stats.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:04.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
            "Pipeline duration: 0.057842135429382324 minutes\n",
            "Number of initial input samples: 1\n",
            "Number of input samples remaining: 1\n",
            "Streaming pipeline main loop rate: 0\n",
            "\n",
            "Cluster Resources:\n",
            "\n",
            " Resource                    Total    Available \n",
            "\n",
            " CPUs                        32           31    \n",
            "\n",
            " GPUs                         8            8    \n",
            "\n",
            " Memory (GB)               1751.72      1751.72 \n",
            "\n",
            " Object Store Memory (GB)   200          200    \n",
            "\n",
            "\n",
            "Resource Usage by Stage:\n",
            "\n",
            " Stage                                     CPU %    Memory (GB)    Actor Count    CPU % per worker    Memory (GB) per worker \n",
            "\n",
            " Stage 00 - URLGenerationStage                 0              0              0                   0                         0 \n",
            "\n",
            " Stage 01 - DocumentDownloadStage              0              0              0                   0                         0 \n",
            "\n",
            " Stage 02 - DocumentIterateExtractStage        0              0              0                   0                         0 \n",
            "\n",
            " Stage 03 - JsonlWriter                        0              0              0                   0                         0 \n",
            "\n",
            "\n",
            "Stage state:\n",
            "\n",
            " Stage                                     Actors:    Actors:    Actors:    Actors:    Actors:       Tasks:           Tasks:        Queue:         Queue:      Slots:       Slots:  Speed:          \n",
            "                                            Target    Pending      Ready    Running       Idle    Completed    Returned None    Input Size    Output Size    Num Used    Num Empty  Tasks/actor/s   \n",
            "\n",
            " Stage 00 - URLGenerationStage                   0          1          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 01 - DocumentDownloadStage                0          2          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 02 - DocumentIterateExtractStage          0         14          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 03 - JsonlWriter                          0         14          0          0          0            0                0             0              0           0            0                  \n",
            "\u001b[0m\n",
            "\u001b[36m(Stage 00 - URLGenerationStage pid=3090419)\u001b[0m 2026-02-26 00:38:05.237 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 00 - URLGenerationStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - URLGenerationStage pid=3090419)\u001b[0m 2026-02-26 00:38:05.237 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 00 - URLGenerationStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - URLGenerationStage pid=3090419)\u001b[0m 2026-02-26 00:38:05.239 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 00 - URLGenerationStage\n",
            "\u001b[36m(Stage 00 - URLGenerationStage pid=3090419)\u001b[0m 2026-02-26 00:38:05.239 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 00 - URLGenerationStage\n",
            "\u001b[36m(Stage 00 - URLGenerationStage pid=3090419)\u001b[0m 2026-02-26 00:38:05.262 | INFO     | nemo_curator.stages.text.download.wikipedia.url_generation:_get_wikipedia_urls:70 - Fetching latest dump date from https://dumps.wikimedia.org/enwiki\n",
            "\u001b[36m(Stage 02 - DocumentIterateExtractStage pid=3090420)\u001b[0m 2026-02-26 00:38:05.265 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 02 - DocumentIterateExtractStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - DocumentIterateExtractStage pid=3090420)\u001b[0m 2026-02-26 00:38:05.265 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 02 - DocumentIterateExtractStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - DocumentIterateExtractStage pid=3090420)\u001b[0m 2026-02-26 00:38:05.269 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - DocumentIterateExtractStage\n",
            "\u001b[36m(Stage 02 - DocumentIterateExtractStage pid=3090420)\u001b[0m 2026-02-26 00:38:05.269 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - DocumentIterateExtractStage\n",
            "\u001b[36m(Stage 01 - DocumentDownloadStage pid=3090418)\u001b[0m 2026-02-26 00:38:05.256 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 01 - DocumentDownloadStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - DocumentDownloadStage pid=3090418)\u001b[0m 2026-02-26 00:38:05.257 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 01 - DocumentDownloadStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - DocumentDownloadStage pid=3090418)\u001b[0m 2026-02-26 00:38:05.259 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - DocumentDownloadStage\n",
            "\u001b[36m(Stage 01 - DocumentDownloadStage pid=3090418)\u001b[0m 2026-02-26 00:38:05.259 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - DocumentDownloadStage\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3090429)\u001b[0m 2026-02-26 00:38:05.595 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3090429)\u001b[0m 2026-02-26 00:38:05.595 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3090436)\u001b[0m 2026-02-26 00:38:05.586 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3090436)\u001b[0m 2026-02-26 00:38:05.587 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[32m2026-02-26 00:38:05.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 0\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:05.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 00 - URLGenerationStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:05.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 1 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:05.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 0.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:05.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 0 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:38:05.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 00 - URLGenerationStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 00 - URLGenerationStage pid=3090419)\u001b[0m 2026-02-26 00:38:05.671 | INFO     | nemo_curator.stages.text.download.wikipedia.url_generation:_get_wikipedia_urls:92 - Found latest dump date: 20260201\n",
            "\u001b[36m(Stage 00 - URLGenerationStage pid=3090419)\u001b[0m 2026-02-26 00:38:05.672 | INFO     | nemo_curator.stages.text.download.wikipedia.url_generation:_get_wikipedia_urls:113 - Found 70 Wikipedia dump files\n",
            "\u001b[32m2026-02-26 00:39:04.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.013749837875366211 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:04.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.011651277542114258 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:04.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.008636236190795898 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:04.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 0.03726530075073242 to get stats.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:04.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
            "Pipeline duration: 1.058565092086792 minutes\n",
            "Number of initial input samples: 1\n",
            "Number of input samples remaining: 0\n",
            "Streaming pipeline main loop rate: 93.99534832819779\n",
            "\n",
            "Cluster Resources:\n",
            "\n",
            " Resource                    Total    Available \n",
            "\n",
            " CPUs                        32           31    \n",
            "\n",
            " GPUs                         8            8    \n",
            "\n",
            " Memory (GB)               1751.72      1751.72 \n",
            "\n",
            " Object Store Memory (GB)   200          200    \n",
            "\n",
            "\n",
            "Resource Usage by Stage:\n",
            "\n",
            " Stage                                     CPU %    Memory (GB)    Actor Count    CPU % per worker    Memory (GB) per worker \n",
            "\n",
            " Stage 00 - URLGenerationStage               0             0                 0                0                         0    \n",
            "\n",
            " Stage 01 - DocumentDownloadStage            5.2           0.52              2                2.6                       0.26 \n",
            "\n",
            " Stage 02 - DocumentIterateExtractStage     13             3.53             14                0.93                      0.25 \n",
            "\n",
            " Stage 03 - JsonlWriter                     13.9           3.34             14                0.99                      0.24 \n",
            "\n",
            "\n",
            "Stage state:\n",
            "\n",
            " Stage                                     Actors:    Actors:    Actors:    Actors:    Actors:       Tasks:           Tasks:        Queue:         Queue:      Slots:       Slots:  Speed:          \n",
            "                                            Target    Pending      Ready    Running       Idle    Completed    Returned None    Input Size    Output Size    Num Used    Num Empty  Tasks/actor/s   \n",
            "\n",
            " Stage 00 - URLGenerationStage                   0          0          0          0          0            1                0             0              0           0            0                  \n",
            "\n",
            " Stage 01 - DocumentDownloadStage                0          0          2          2          0            0                0             0              0           2            2                  \n",
            "\n",
            " Stage 02 - DocumentIterateExtractStage          0          0         14          0         14            0                0             0              0           0           28                  \n",
            "\n",
            " Stage 03 - JsonlWriter                          0          0         14          0         14            0                0             0              0           0           28                  \n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:04.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m448\u001b[0m - \u001b[1mStreamingExecutor Timing Summary:\n",
            "  Auto Scaling  : 0.000001 seconds\n",
            "  Pool Update   : 0.000171 seconds\n",
            "  Monitor Update: 0.000007 seconds\n",
            "  Add Tasks     : 0.000033 seconds\n",
            "  Sleep         : 0.009878 seconds\n",
            "  Total         : 0.010090 seconds\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:04.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m450\u001b[0m - \u001b[1mWorker allocation:\n",
            "Component    Utilization                               NVDEC                                    NVENC\n",
            "Node 0       CPUs: [###################-] 29.00/30.00\n",
            "GPU 0        GPU: [--------------------] 0.00/1.00     NVDEC: [--------------------] 0.00/7.00  NVENC: [--------------------] 0.00/0.00\n",
            "GPU 1        GPU: [--------------------] 0.00/1.00     NVDEC: [--------------------] 0.00/7.00  NVENC: [--------------------] 0.00/0.00\n",
            "GPU 2        GPU: [--------------------] 0.00/1.00     NVDEC: [--------------------] 0.00/7.00  NVENC: [--------------------] 0.00/0.00\n",
            "GPU 3        GPU: [--------------------] 0.00/1.00     NVDEC: [--------------------] 0.00/7.00  NVENC: [--------------------] 0.00/0.00\n",
            "GPU 4        GPU: [--------------------] 0.00/1.00     NVDEC: [--------------------] 0.00/7.00  NVENC: [--------------------] 0.00/0.00\n",
            "GPU 5        GPU: [--------------------] 0.00/1.00     NVDEC: [--------------------] 0.00/7.00  NVENC: [--------------------] 0.00/0.00\n",
            "GPU 6        GPU: [--------------------] 0.00/1.00     NVDEC: [--------------------] 0.00/7.00  NVENC: [--------------------] 0.00/0.00\n",
            "GPU 7        GPU: [--------------------] 0.00/1.00     NVDEC: [--------------------] 0.00/7.00  NVENC: [--------------------] 0.00/0.00\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3090436)\u001b[0m 2026-02-26 00:39:24.608 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 100 records to /home/sanjay/ee194-a2/wiki_data/f1f915649bf3.jsonl\n",
            "\u001b[36m(Stage 02 - DocumentIterateExtractStage pid=3090428)\u001b[0m 2026-02-26 00:38:05.606 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - DocumentIterateExtractStage\u001b[32m [repeated 13x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(Stage 02 - DocumentIterateExtractStage pid=3090428)\u001b[0m 2026-02-26 00:38:05.606 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - DocumentIterateExtractStage\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 01 - DocumentDownloadStage pid=3090421)\u001b[0m 2026-02-26 00:38:05.343 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - DocumentDownloadStage\n",
            "\u001b[36m(Stage 01 - DocumentDownloadStage pid=3090421)\u001b[0m 2026-02-26 00:38:05.343 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - DocumentDownloadStage\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3090439)\u001b[0m 2026-02-26 00:38:05.807 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3090439)\u001b[0m 2026-02-26 00:38:05.807 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 1\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 01 - DocumentDownloadStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 2 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 2.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 2 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 1.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 1 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 01 - DocumentDownloadStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 2\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 02 - DocumentIterateExtractStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 14 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 21.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 21 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 29.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 29 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 5.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 5 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 19.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 19 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 7.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 7 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 11.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 11 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 25.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 25 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 23.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 23 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 27.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 27 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 13.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 13 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 17.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 17 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 3.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 3 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 15.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 15 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 9.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 9 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:41.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 02 - DocumentIterateExtractStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 3\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 03 - JsonlWriter. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 14 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 10.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 10 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 12.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 12 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 24.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 24 from allocator.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3090436)\u001b[0m 2026-02-26 00:39:42.034 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 100 records to /home/sanjay/ee194-a2/wiki_data/c01153922546.jsonl\n",
            "\u001b[32m2026-02-26 00:39:42.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 28.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 28 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 22.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 22 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 16.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 16 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 14.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 14 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 8.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 8 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 18.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 18 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 6.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 6 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 4.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 4 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 30.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 30 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 20.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 20 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 26.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 26 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 03 - JsonlWriter stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m543\u001b[0m - \u001b[1mAll stages are done. Finishing pipeline.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.013633012771606445 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.03794717788696289 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:42.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.005473613739013672 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:39:52.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mPipeline completed successfully with 2 output tasks\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Run the pipeline\n",
        "results = pipeline.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f277cc2",
      "metadata": {},
      "source": [
        "## Implement a Stage [10 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28d77e7",
      "metadata": {},
      "source": [
        "Use the code snippet below to read and inspect a portion of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b3dd5c19",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>language</th>\n",
              "      <th>source_id</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A hotline is a point-to-point communications l...</td>\n",
              "      <td>Hotline</td>\n",
              "      <td>41243</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hotline</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In biology, a hybrid is the offspring resultin...</td>\n",
              "      <td>Hybrid (biology)</td>\n",
              "      <td>41244</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hybrid%20%28biol...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In telecommunications, a hybrid balance is an ...</td>\n",
              "      <td>Hybrid balance</td>\n",
              "      <td>41245</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hybrid%20balance</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A hybrid transformer (also known as a bridge t...</td>\n",
              "      <td>Hybrid transformer</td>\n",
              "      <td>41246</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hybrid%20transfo...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hydroxyl ion absorption is the absorption in o...</td>\n",
              "      <td>Hydroxyl ion absorption</td>\n",
              "      <td>41248</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hydroxyl%20ion%2...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>An identifier is a name that identifies (that ...</td>\n",
              "      <td>Identifier</td>\n",
              "      <td>41250</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Identifier</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>In telecommunications and antenna design, an i...</td>\n",
              "      <td>Image antenna</td>\n",
              "      <td>41251</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Image%20antenna</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Improved-definition television (IDTV) or enhan...</td>\n",
              "      <td>Improved-definition television</td>\n",
              "      <td>41254</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Improved-definit...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>In optics, an index-matching material is a sub...</td>\n",
              "      <td>Index-matching material</td>\n",
              "      <td>41256</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Index-matching%2...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>In electrical engineering, two conductors are ...</td>\n",
              "      <td>Inductive coupling</td>\n",
              "      <td>41258</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Inductive%20coup...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  A hotline is a point-to-point communications l...   \n",
              "1  In biology, a hybrid is the offspring resultin...   \n",
              "2  In telecommunications, a hybrid balance is an ...   \n",
              "3  A hybrid transformer (also known as a bridge t...   \n",
              "4  Hydroxyl ion absorption is the absorption in o...   \n",
              "5  An identifier is a name that identifies (that ...   \n",
              "6  In telecommunications and antenna design, an i...   \n",
              "7  Improved-definition television (IDTV) or enhan...   \n",
              "8  In optics, an index-matching material is a sub...   \n",
              "9  In electrical engineering, two conductors are ...   \n",
              "\n",
              "                            title     id  \\\n",
              "0                         Hotline  41243   \n",
              "1                Hybrid (biology)  41244   \n",
              "2                  Hybrid balance  41245   \n",
              "3              Hybrid transformer  41246   \n",
              "4         Hydroxyl ion absorption  41248   \n",
              "5                      Identifier  41250   \n",
              "6                   Image antenna  41251   \n",
              "7  Improved-definition television  41254   \n",
              "8         Index-matching material  41256   \n",
              "9              Inductive coupling  41258   \n",
              "\n",
              "                                                 url language  \\\n",
              "0              https://en.wikipedia.org/wiki/Hotline       en   \n",
              "1  https://en.wikipedia.org/wiki/Hybrid%20%28biol...       en   \n",
              "2     https://en.wikipedia.org/wiki/Hybrid%20balance       en   \n",
              "3  https://en.wikipedia.org/wiki/Hybrid%20transfo...       en   \n",
              "4  https://en.wikipedia.org/wiki/Hydroxyl%20ion%2...       en   \n",
              "5           https://en.wikipedia.org/wiki/Identifier       en   \n",
              "6      https://en.wikipedia.org/wiki/Image%20antenna       en   \n",
              "7  https://en.wikipedia.org/wiki/Improved-definit...       en   \n",
              "8  https://en.wikipedia.org/wiki/Index-matching%2...       en   \n",
              "9  https://en.wikipedia.org/wiki/Inductive%20coup...       en   \n",
              "\n",
              "                                           source_id  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "3  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "4  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "5  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "6  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "7  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "8  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "9  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                           file_name  \n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...  \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...  \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...  \n",
              "3  enwiki-20260201-enwiki-20260201-pages-articles...  \n",
              "4  enwiki-20260201-enwiki-20260201-pages-articles...  \n",
              "5  enwiki-20260201-enwiki-20260201-pages-articles...  \n",
              "6  enwiki-20260201-enwiki-20260201-pages-articles...  \n",
              "7  enwiki-20260201-enwiki-20260201-pages-articles...  \n",
              "8  enwiki-20260201-enwiki-20260201-pages-articles...  \n",
              "9  enwiki-20260201-enwiki-20260201-pages-articles...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nemo_curator.utils.file_utils import get_all_file_paths_under\n",
        "\n",
        "# Read and inspect the first JSONL file from wiki_data_dir\n",
        "file_paths = get_all_file_paths_under(wiki_data_dir)\n",
        "df = pd.read_json(file_paths[0], lines=True)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d6f2c5",
      "metadata": {},
      "source": [
        "In the Wikipedia dataset, the last portion of the document's text typically corresponds \"Categories\" section of the Wikipedia page. For example, the text for the Wikipedia page on [Anarchism](https://en.wikipedia.org/wiki/Anarchism) looks like:\n",
        "\n",
        "```text\n",
        "Anarchism is a political philosophy and movement... \\n\\nExternal links \\n\\n Anarchy Archives  an online research center on the history and theory of anarchism.\\n\\n \\nAnti-capitalism\\nAnti-fascism\\nEconomic ideologies\\nFar-left politics\\nLeft-wing ideologies\\nLibertarian socialism\\nLibertarianism\\nPolitical culture\\nPolitical ideologies\\nPolitical movements\\nSocial theories\\nTypes of socialism\n",
        "```\n",
        "\n",
        "where `\\n\\n` denotes a new section on the page, and the last section of the page is a list of categories (in the above example, the categories are Anti-capitalism, Anti-fascism, ... Types of socialism).\n",
        "\n",
        "In Pandas, we can create a new column called \"categories\" by using the following operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "50e2eb13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# In the text column, grab everything after the final occurence of \"\\n\\n\"\n",
        "df[\"categories\"] = df[\"text\"].str.rsplit(\"\\n\\n\", n=1).str[-1].str.strip().str.split(\"\\n\")\n",
        "\n",
        "# Add the title of the page to the list of categories\n",
        "df[\"categories\"] = df.apply(\n",
        "    lambda row: [row[\"title\"]] + row[\"categories\"], axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "479c36f4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>language</th>\n",
              "      <th>source_id</th>\n",
              "      <th>file_name</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A hotline is a point-to-point communications l...</td>\n",
              "      <td>Hotline</td>\n",
              "      <td>41243</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hotline</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Hotline, de:Heier Draht]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In biology, a hybrid is the offspring resultin...</td>\n",
              "      <td>Hybrid (biology)</td>\n",
              "      <td>41244</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hybrid%20%28biol...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Hybrid (biology), Biology terminology, Botani...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In telecommunications, a hybrid balance is an ...</td>\n",
              "      <td>Hybrid balance</td>\n",
              "      <td>41245</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hybrid%20balance</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Hybrid balance, Telecommunications engineerin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A hybrid transformer (also known as a bridge t...</td>\n",
              "      <td>Hybrid transformer</td>\n",
              "      <td>41246</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hybrid%20transfo...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Hybrid transformer, Electric transformers, Te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hydroxyl ion absorption is the absorption in o...</td>\n",
              "      <td>Hydroxyl ion absorption</td>\n",
              "      <td>41248</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Hydroxyl%20ion%2...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Hydroxyl ion absorption, Fiber optics, Glass ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>An identifier is a name that identifies (that ...</td>\n",
              "      <td>Identifier</td>\n",
              "      <td>41250</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Identifier</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Identifier, Metadata]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>In telecommunications and antenna design, an i...</td>\n",
              "      <td>Image antenna</td>\n",
              "      <td>41251</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Image%20antenna</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Image antenna, Radio frequency antenna types,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Improved-definition television (IDTV) or enhan...</td>\n",
              "      <td>Improved-definition television</td>\n",
              "      <td>41254</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Improved-definit...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Improved-definition television, Television te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>In optics, an index-matching material is a sub...</td>\n",
              "      <td>Index-matching material</td>\n",
              "      <td>41256</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Index-matching%2...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Index-matching material, Fiber optics, Optica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>In electrical engineering, two conductors are ...</td>\n",
              "      <td>Inductive coupling</td>\n",
              "      <td>41258</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Inductive%20coup...</td>\n",
              "      <td>en</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>enwiki-20260201-enwiki-20260201-pages-articles...</td>\n",
              "      <td>[Inductive coupling, Electronic engineering, E...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  A hotline is a point-to-point communications l...   \n",
              "1  In biology, a hybrid is the offspring resultin...   \n",
              "2  In telecommunications, a hybrid balance is an ...   \n",
              "3  A hybrid transformer (also known as a bridge t...   \n",
              "4  Hydroxyl ion absorption is the absorption in o...   \n",
              "5  An identifier is a name that identifies (that ...   \n",
              "6  In telecommunications and antenna design, an i...   \n",
              "7  Improved-definition television (IDTV) or enhan...   \n",
              "8  In optics, an index-matching material is a sub...   \n",
              "9  In electrical engineering, two conductors are ...   \n",
              "\n",
              "                            title     id  \\\n",
              "0                         Hotline  41243   \n",
              "1                Hybrid (biology)  41244   \n",
              "2                  Hybrid balance  41245   \n",
              "3              Hybrid transformer  41246   \n",
              "4         Hydroxyl ion absorption  41248   \n",
              "5                      Identifier  41250   \n",
              "6                   Image antenna  41251   \n",
              "7  Improved-definition television  41254   \n",
              "8         Index-matching material  41256   \n",
              "9              Inductive coupling  41258   \n",
              "\n",
              "                                                 url language  \\\n",
              "0              https://en.wikipedia.org/wiki/Hotline       en   \n",
              "1  https://en.wikipedia.org/wiki/Hybrid%20%28biol...       en   \n",
              "2     https://en.wikipedia.org/wiki/Hybrid%20balance       en   \n",
              "3  https://en.wikipedia.org/wiki/Hybrid%20transfo...       en   \n",
              "4  https://en.wikipedia.org/wiki/Hydroxyl%20ion%2...       en   \n",
              "5           https://en.wikipedia.org/wiki/Identifier       en   \n",
              "6      https://en.wikipedia.org/wiki/Image%20antenna       en   \n",
              "7  https://en.wikipedia.org/wiki/Improved-definit...       en   \n",
              "8  https://en.wikipedia.org/wiki/Index-matching%2...       en   \n",
              "9  https://en.wikipedia.org/wiki/Inductive%20coup...       en   \n",
              "\n",
              "                                           source_id  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "3  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "4  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "5  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "6  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "7  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "8  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "9  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                           file_name  \\\n",
              "0  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "1  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "2  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "3  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "4  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "5  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "6  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "7  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "8  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "9  enwiki-20260201-enwiki-20260201-pages-articles...   \n",
              "\n",
              "                                          categories  \n",
              "0                         [Hotline, de:Heier Draht]  \n",
              "1  [Hybrid (biology), Biology terminology, Botani...  \n",
              "2  [Hybrid balance, Telecommunications engineerin...  \n",
              "3  [Hybrid transformer, Electric transformers, Te...  \n",
              "4  [Hydroxyl ion absorption, Fiber optics, Glass ...  \n",
              "5                             [Identifier, Metadata]  \n",
              "6  [Image antenna, Radio frequency antenna types,...  \n",
              "7  [Improved-definition television, Television te...  \n",
              "8  [Index-matching material, Fiber optics, Optica...  \n",
              "9  [Inductive coupling, Electronic engineering, E...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac76d20",
      "metadata": {},
      "source": [
        "With this in mind, implement a stage in Curator which adds a \"categories\" column to the entire dataset. Here is a skeleton to help:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c966a3ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from nemo_curator.stages.base import ProcessingStage\n",
        "from nemo_curator.tasks import DocumentBatch\n",
        "\n",
        "@dataclass\n",
        "class CategoriesAdder(ProcessingStage[DocumentBatch, DocumentBatch]):\n",
        "    \"\"\"\n",
        "    Adds a \"categories\" column to the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    text_field = \"text\"\n",
        "    title_field = \"title\"\n",
        "    categories_field = \"categories\"  # list[str]\n",
        "\n",
        "    def inputs(self):\n",
        "        return [[\"data\"], [self.text_field, self.title_field]]\n",
        "\n",
        "    def outputs(self):\n",
        "        return [[\"data\"], [self.categories_field]]\n",
        "\n",
        "    def process(self, batch: DocumentBatch) -> DocumentBatch:\n",
        "        df = batch.to_pandas()\n",
        "\n",
        "        df[self.categories_field] = (\n",
        "            df[self.text_field]\n",
        "            .str.rsplit(\"\\n\\n\", n=1)\n",
        "            .str[-1]\n",
        "            .str.strip()\n",
        "            .str.split(\"\\n\")\n",
        "        )\n",
        "\n",
        "        df[self.categories_field] = df.apply(\n",
        "            lambda row: [row[self.title_field]] + row[self.categories_field], axis=1\n",
        "        )\n",
        "\n",
        "        batch.data = df\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7c1f7772",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 00:53:34.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_reader' to pipeline 'wiki_categories_pipeline'\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:34.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'ProcessingStage' to pipeline 'wiki_categories_pipeline'\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:34.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_writer' to pipeline 'wiki_categories_pipeline'\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(name='wiki_categories_pipeline', stages=[jsonl_reader(JsonlReader), ProcessingStage(CategoriesAdder), jsonl_writer(JsonlWriter)])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nemo_curator.stages.text.io.reader import JsonlReader\n",
        "\n",
        "# Create a pipeline and add stages to it\n",
        "pipeline = Pipeline(\"wiki_categories_pipeline\")\n",
        "\n",
        "jsonl_reader = JsonlReader(wiki_data_dir)\n",
        "pipeline.add_stage(jsonl_reader)\n",
        "\n",
        "categories_adder = CategoriesAdder()\n",
        "pipeline.add_stage(categories_adder)\n",
        "\n",
        "wiki_categories_dir = \"./wiki_categories_data\"\n",
        "jsonl_writer = JsonlWriter(wiki_categories_dir)\n",
        "pipeline.add_stage(jsonl_writer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8671f20a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 00:53:36.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: wiki_categories_pipeline\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mDecomposing composite stage: jsonl_reader\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExpanded 'jsonl_reader' into 2 execution stages\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mExecution mode: STREAMING\u001b[0m\n",
            "2026-02-26 00:53:36,317\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 00:53:36,321\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 00:53:36,329\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\u001b[32m2026-02-26 00:53:36.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mPipelineSpec:\n",
            "  config: PipelineConfig(execution_mode=<ExecutionMode.STREAMING: 0>, num_setup_attempts_python=1, num_run_attempts_python=1, max_setup_failure_percentage=None, ignore_failures=False, reset_workers_on_failure=False, slots_per_actor=2, worker_max_lifetime_m=0, worker_restart_interval_m=1, logging_interval_s=60, failures_return_nones=False, return_last_stage_outputs=True, actor_pool_verbosity_level=<VerbosityLevel.INFO: 1>, monitoring_verbosity_level=<VerbosityLevel.INFO: 1>, mode_specific=StreamingSpecificSpec(autoscale_interval_s=180, autoscaler_verbosity_level=<VerbosityLevel.INFO: 1>, executor_verbosity_level=<VerbosityLevel.INFO: 1>), log_worker_allocation_layout=True, cpu_allocation_percentage=0.95, clear_cuda_visible_devices_on_cpu_actors=True)\n",
            "  job_info: None\n",
            "  Stage 0:\n",
            "   class_name: FilePartitioningStage\n",
            "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: 1\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 1:\n",
            "   class_name: JsonlReaderStage\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 2:\n",
            "   class_name: CategoriesAdder\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 3:\n",
            "   class_name: JsonlWriter\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:36.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mInitialized Ray cluster.\u001b[0m\n",
            "2026-02-26 00:53:36,356\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 00:53:36,362\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 00:53:36,362\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
            "\u001b[32m2026-02-26 00:53:36.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.cluster\u001b[0m:\u001b[36minit_or_connect_to_cluster\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mRay dashboard url: 127.0.0.1:8265\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m759\u001b[0m - \u001b[1mDetermining number of nvdecs/nvencs per gpu in this cluster.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m775\u001b[0m - \u001b[1mGpu with name NVIDIA H100 80GB HBM3 found. Looking up nvdecs and nvencs...\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m777\u001b[0m - \u001b[1mFound the following gpu resources: GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mCreated/connected to cluster with resources: PoolOfResources(cpus=30.0, gpus=8.0, nvdecs=56.0, nvencs=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mSetting up fragmentation based autoscaler with problem: Problem(cluster_resources=ClusterResources(nodes={'ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71': NodeResources(cpus=30, gpus=[GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())], name='ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71')}), stages=[ProblemStage(name='Stage 00 - FilePartitioningStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=1, over_provision_factor=None), ProblemStage(name='Stage 01 - JsonlReaderStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 02 - CategoriesAdder', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 03 - JsonlWriter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None)])\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mStarting main loop\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mAutoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mSolving the following naiive allocation problem:\n",
            "{ 'cluster_resources': { 'cpus': 30.0,\n",
            "                         'gpus': 8.0,\n",
            "                         'nvdecs': 56.0,\n",
            "                         'nvencs': 0.0},\n",
            "  'stages': [ { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 00 - FilePartitioningStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': 1,\n",
            "                'resources_per_worker': { 'cpus': 0.5,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 01 - JsonlReaderStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 02 - CategoriesAdder',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 03 - JsonlWriter',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1}]}\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mGot the following naiive allocation result:\n",
            "{ 'allocation_result': { 'cluster_resources': { 'cpus': 30.0,\n",
            "                                                'gpus': 8.0,\n",
            "                                                'nvdecs': 56.0,\n",
            "                                                'nvencs': 0.0},\n",
            "                         'stages': [ { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 1,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 00 - '\n",
            "                                                            'FilePartitioningStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': 1,\n",
            "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 9,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 01 - '\n",
            "                                                            'JsonlReaderStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 9,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 02 - '\n",
            "                                                            'CategoriesAdder',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 9,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 03 - '\n",
            "                                                            'JsonlWriter',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}}],\n",
            "                         'throughput': 1.0},\n",
            "  'num_slots_per_state': [2, 2, 2, 2]}\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36mrun_fragmentation_autoscaler\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mRunning phase 4...\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:39.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mDone calculating autoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 3.5243027210235596 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.009834527969360352 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.006054401397705078 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 3.5422959327697754 to get stats.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
            "Pipeline duration: 0.06057684024175008 minutes\n",
            "Number of initial input samples: 1\n",
            "Number of input samples remaining: 1\n",
            "Streaming pipeline main loop rate: 0\n",
            "\n",
            "Cluster Resources:\n",
            "\n",
            " Resource                    Total    Available \n",
            "\n",
            " CPUs                        32           31    \n",
            "\n",
            " GPUs                         8            8    \n",
            "\n",
            " Memory (GB)               1751.72      1751.72 \n",
            "\n",
            " Object Store Memory (GB)   200          200    \n",
            "\n",
            "\n",
            "Resource Usage by Stage:\n",
            "\n",
            " Stage                               CPU %    Memory (GB)    Actor Count    CPU % per worker    Memory (GB) per worker \n",
            "\n",
            " Stage 00 - FilePartitioningStage        0              0              0                   0                         0 \n",
            "\n",
            " Stage 01 - JsonlReaderStage             0              0              0                   0                         0 \n",
            "\n",
            " Stage 02 - CategoriesAdder              0              0              0                   0                         0 \n",
            "\n",
            " Stage 03 - JsonlWriter                  0              0              0                   0                         0 \n",
            "\n",
            "\n",
            "Stage state:\n",
            "\n",
            " Stage                               Actors:    Actors:    Actors:    Actors:    Actors:       Tasks:           Tasks:        Queue:         Queue:      Slots:       Slots:  Speed:          \n",
            "                                      Target    Pending      Ready    Running       Idle    Completed    Returned None    Input Size    Output Size    Num Used    Num Empty  Tasks/actor/s   \n",
            "\n",
            " Stage 00 - FilePartitioningStage          0          1          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 01 - JsonlReaderStage               0         10          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 02 - CategoriesAdder                0         10          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 03 - JsonlWriter                    0          9          0          0          0            0                0             0              0           0            0                  \n",
            "\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3159074)\u001b[0m 2026-02-26 00:53:43.262 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3159074)\u001b[0m 2026-02-26 00:53:43.263 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3159074)\u001b[0m 2026-02-26 00:53:43.267 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3159074)\u001b[0m 2026-02-26 00:53:43.267 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3159075)\u001b[0m 2026-02-26 00:53:43.277 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3159075)\u001b[0m 2026-02-26 00:53:43.278 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3159075)\u001b[0m 2026-02-26 00:53:43.287 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3159075)\u001b[0m 2026-02-26 00:53:43.287 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[32m2026-02-26 00:53:43.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 0\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 00 - FilePartitioningStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 1 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 0.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 0 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 00 - FilePartitioningStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 02 - CategoriesAdder pid=3159082)\u001b[0m 2026-02-26 00:53:43.397 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - CategoriesAdder\n",
            "\u001b[36m(Stage 02 - CategoriesAdder pid=3159082)\u001b[0m 2026-02-26 00:53:43.397 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - CategoriesAdder\n",
            "\u001b[36m(Stage 02 - CategoriesAdder pid=3159090)\u001b[0m 2026-02-26 00:53:43.373 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 02 - CategoriesAdder on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - CategoriesAdder pid=3159090)\u001b[0m 2026-02-26 00:53:43.374 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 02 - CategoriesAdder on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3159075)\u001b[0m 2026-02-26 00:53:43.311 | DEBUG    | nemo_curator.stages.file_partitioning:_get_file_list:179 - Getting file list for ./wiki_data\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3159075)\u001b[0m 2026-02-26 00:53:43.314 | INFO     | nemo_curator.stages.file_partitioning:process:106 - Found 2 files\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3159075)\u001b[0m 2026-02-26 00:53:43.314 | INFO     | nemo_curator.stages.file_partitioning:process:117 - No partitions specified, defaulting to one file per partition\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3159075)\u001b[0m 2026-02-26 00:53:43.314 | INFO     | nemo_curator.stages.file_partitioning:process:143 - Created 2 file groups from 2 files\n",
            "\u001b[32m2026-02-26 00:53:43.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 1\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 01 - JsonlReaderStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 10 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 10.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 10 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 28.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 28 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 7.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 7 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 19.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 19 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 22.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 22 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 16.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 16 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 25.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 25 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 13.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 13 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 4.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 4 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 1.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 1 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 01 - JsonlReaderStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159089)\u001b[0m 2026-02-26 00:53:43.510 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159089)\u001b[0m 2026-02-26 00:53:43.511 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[32m2026-02-26 00:53:43.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 2\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 02 - CategoriesAdder. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 10 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 2.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 2 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 29.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 29 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 5.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 5 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 14.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 14 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 11.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 11 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 8.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 8 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 23.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 23 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 17.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 17 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 20.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 20 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 26.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 26 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 02 - CategoriesAdder stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159097)\u001b[0m 2026-02-26 00:53:43.520 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159097)\u001b[0m 2026-02-26 00:53:43.521 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159097)\u001b[0m 2026-02-26 00:53:43.596 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:90 - File /home/sanjay/ee194-a2/wiki_categories_data/45c5139b309b.jsonl already exists, overwriting it\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159089)\u001b[0m 2026-02-26 00:53:43.570 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 100 records to /home/sanjay/ee194-a2/wiki_categories_data/55f4c77fa8b9.jsonl\n",
            "\u001b[32m2026-02-26 00:53:43.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 3\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 03 - JsonlWriter. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 9 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 12.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 12 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 21.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 21 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 24.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 24 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 18.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 18 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 27.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 27 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 6.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 6 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 3.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 3 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 15.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 15 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 9.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 9 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 03 - JsonlWriter stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m543\u001b[0m - \u001b[1mAll stages are done. Finishing pipeline.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.0014400482177734375 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.006749868392944336 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:43.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.004352569580078125 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 00:53:53.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mPipeline completed successfully with 2 output tasks\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3159087)\u001b[0m 2026-02-26 00:53:43.406 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3159087)\u001b[0m 2026-02-26 00:53:43.406 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - CategoriesAdder pid=3159096)\u001b[0m 2026-02-26 00:53:43.535 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - CategoriesAdder\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - CategoriesAdder pid=3159096)\u001b[0m 2026-02-26 00:53:43.536 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - CategoriesAdder\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159093)\u001b[0m 2026-02-26 00:53:43.540 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159093)\u001b[0m 2026-02-26 00:53:43.540 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159089)\u001b[0m 2026-02-26 00:53:43.562 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:90 - File /home/sanjay/ee194-a2/wiki_categories_data/55f4c77fa8b9.jsonl already exists, overwriting it\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3159097)\u001b[0m 2026-02-26 00:53:43.628 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 100 records to /home/sanjay/ee194-a2/wiki_categories_data/45c5139b309b.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Run the pipeline\n",
        "results = pipeline.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674495e9",
      "metadata": {},
      "source": [
        "Feel free to do some exploratory analyses of the categories of data available. Include your explorations below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c14a49",
      "metadata": {},
      "outputs": [],
      "source": [
        "# exploratory analysis here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29742246",
      "metadata": {},
      "source": [
        "## Implement a Filter [10 points]\n",
        "\n",
        "Next, choose a topic of interest and implement the following filter. Aim for 1,000 - 10,000 or more documents (rows) in your `wiki_domain_dir`.\n",
        "\n",
        "Note in the below code, we expect `domains` to be a list of strings. This is intended to help keep more documents matching your targeted area. For example, if your targeted domain is political theory, then an appropriate usage might be `domains=[\"politics\", \"political theory\", \"conservatism\", \"liberalism\", ...]` to catch as many relevant matches as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b6c451a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from nemo_curator.stages.text.filters.doc_filter import DocumentFilter\n",
        "\n",
        "class DomainFilter(DocumentFilter):\n",
        "    \"\"\"\n",
        "    Throw away documents whose categories column does not contain the given substring(s)\n",
        "\n",
        "    Advice:\n",
        "    - Check if any of the domains are in the categories, even as a substring\n",
        "    - This function should not be case-sensitive\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, domains: list[str]):\n",
        "        super().__init__()\n",
        "        self._domains = domains\n",
        "        self._name = \"domain_filter\"\n",
        "\n",
        "    def score_document(self, categories: list[str]) -> list[str]:\n",
        "        return categories  # do not modify this function\n",
        "\n",
        "    def keep_document(self, categories: list[str]) -> bool:\n",
        "        lower_categories = [c.lower() for c in categories]\n",
        "        return any(\n",
        "            domain.lower() in cat\n",
        "            for domain in self._domains\n",
        "            for cat in lower_categories\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d5066fe1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:05:39.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_reader' to pipeline 'wiki_domain_pipeline'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:39.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'domain_filter' to pipeline 'wiki_domain_pipeline'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:39.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_writer' to pipeline 'wiki_domain_pipeline'\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(name='wiki_domain_pipeline', stages=[jsonl_reader(JsonlReader), domain_filter(Filter), jsonl_writer(JsonlWriter)])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nemo_curator.stages.text.modules import Filter\n",
        "\n",
        "# Create a pipeline and add stages to it\n",
        "pipeline = Pipeline(\"wiki_domain_pipeline\")\n",
        "\n",
        "jsonl_reader = JsonlReader(wiki_categories_dir)\n",
        "pipeline.add_stage(jsonl_reader)\n",
        "\n",
        "domains = [\"computer science\", \"computing\", \"software\", \"programming\", \"algorithm\", \"artificial intelligence\", \"machine learning\"]\n",
        "domain_filter = DomainFilter(domains=domains)\n",
        "pipeline.add_stage(Filter(domain_filter, filter_field=\"categories\"))\n",
        "\n",
        "wiki_domain_dir = \"./wiki_domain_data\"\n",
        "jsonl_writer = JsonlWriter(wiki_domain_dir)\n",
        "pipeline.add_stage(jsonl_writer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c347e0cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:05:45.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: wiki_domain_pipeline\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mDecomposing composite stage: jsonl_reader\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExpanded 'jsonl_reader' into 2 execution stages\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mExecution mode: STREAMING\u001b[0m\n",
            "2026-02-26 01:05:45,326\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:05:45,331\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:05:45,339\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\u001b[32m2026-02-26 01:05:45.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mPipelineSpec:\n",
            "  config: PipelineConfig(execution_mode=<ExecutionMode.STREAMING: 0>, num_setup_attempts_python=1, num_run_attempts_python=1, max_setup_failure_percentage=None, ignore_failures=False, reset_workers_on_failure=False, slots_per_actor=2, worker_max_lifetime_m=0, worker_restart_interval_m=1, logging_interval_s=60, failures_return_nones=False, return_last_stage_outputs=True, actor_pool_verbosity_level=<VerbosityLevel.INFO: 1>, monitoring_verbosity_level=<VerbosityLevel.INFO: 1>, mode_specific=StreamingSpecificSpec(autoscale_interval_s=180, autoscaler_verbosity_level=<VerbosityLevel.INFO: 1>, executor_verbosity_level=<VerbosityLevel.INFO: 1>), log_worker_allocation_layout=True, cpu_allocation_percentage=0.95, clear_cuda_visible_devices_on_cpu_actors=True)\n",
            "  job_info: None\n",
            "  Stage 0:\n",
            "   class_name: FilePartitioningStage\n",
            "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: 1\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 1:\n",
            "   class_name: JsonlReaderStage\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 2:\n",
            "   class_name: Filter\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 3:\n",
            "   class_name: JsonlWriter\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:45.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mInitialized Ray cluster.\u001b[0m\n",
            "2026-02-26 01:05:45,369\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:05:45,374\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:05:45,374\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
            "\u001b[32m2026-02-26 01:05:45.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.cluster\u001b[0m:\u001b[36minit_or_connect_to_cluster\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mRay dashboard url: 127.0.0.1:8265\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m759\u001b[0m - \u001b[1mDetermining number of nvdecs/nvencs per gpu in this cluster.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m775\u001b[0m - \u001b[1mGpu with name NVIDIA H100 80GB HBM3 found. Looking up nvdecs and nvencs...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m777\u001b[0m - \u001b[1mFound the following gpu resources: GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mCreated/connected to cluster with resources: PoolOfResources(cpus=30.0, gpus=8.0, nvdecs=56.0, nvencs=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mSetting up fragmentation based autoscaler with problem: Problem(cluster_resources=ClusterResources(nodes={'ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71': NodeResources(cpus=30, gpus=[GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())], name='ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71')}), stages=[ProblemStage(name='Stage 00 - FilePartitioningStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=1, over_provision_factor=None), ProblemStage(name='Stage 01 - JsonlReaderStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 02 - Filter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 03 - JsonlWriter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None)])\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mStarting main loop\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mAutoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mSolving the following naiive allocation problem:\n",
            "{ 'cluster_resources': { 'cpus': 30.0,\n",
            "                         'gpus': 8.0,\n",
            "                         'nvdecs': 56.0,\n",
            "                         'nvencs': 0.0},\n",
            "  'stages': [ { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 00 - FilePartitioningStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': 1,\n",
            "                'resources_per_worker': { 'cpus': 0.5,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 01 - JsonlReaderStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 02 - Filter',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 03 - JsonlWriter',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1}]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mGot the following naiive allocation result:\n",
            "{ 'allocation_result': { 'cluster_resources': { 'cpus': 30.0,\n",
            "                                                'gpus': 8.0,\n",
            "                                                'nvdecs': 56.0,\n",
            "                                                'nvencs': 0.0},\n",
            "                         'stages': [ { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 1,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 00 - '\n",
            "                                                            'FilePartitioningStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': 1,\n",
            "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 9,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 01 - '\n",
            "                                                            'JsonlReaderStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 9,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 02 - Filter',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 9,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 03 - '\n",
            "                                                            'JsonlWriter',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}}],\n",
            "                         'throughput': 1.0},\n",
            "  'num_slots_per_state': [2, 2, 2, 2]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36mrun_fragmentation_autoscaler\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mRunning phase 4...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:48.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mDone calculating autoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:51.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 3.3227577209472656 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:51.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.011243581771850586 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:51.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.006824493408203125 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:51.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 3.343111515045166 to get stats.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:51.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
            "Pipeline duration: 0.05725359519322713 minutes\n",
            "Number of initial input samples: 1\n",
            "Number of input samples remaining: 1\n",
            "Streaming pipeline main loop rate: 0\n",
            "\n",
            "Cluster Resources:\n",
            "\n",
            " Resource                    Total    Available \n",
            "\n",
            " CPUs                        32           31    \n",
            "\n",
            " GPUs                         8            8    \n",
            "\n",
            " Memory (GB)               1751.72      1751.72 \n",
            "\n",
            " Object Store Memory (GB)   200          200    \n",
            "\n",
            "\n",
            "Resource Usage by Stage:\n",
            "\n",
            " Stage                               CPU %    Memory (GB)    Actor Count    CPU % per worker    Memory (GB) per worker \n",
            "\n",
            " Stage 00 - FilePartitioningStage        0              0              0                   0                         0 \n",
            "\n",
            " Stage 01 - JsonlReaderStage             0              0              0                   0                         0 \n",
            "\n",
            " Stage 02 - Filter                       0              0              0                   0                         0 \n",
            "\n",
            " Stage 03 - JsonlWriter                  0              0              0                   0                         0 \n",
            "\n",
            "\n",
            "Stage state:\n",
            "\n",
            " Stage                               Actors:    Actors:    Actors:    Actors:    Actors:       Tasks:           Tasks:        Queue:         Queue:      Slots:       Slots:  Speed:          \n",
            "                                      Target    Pending      Ready    Running       Idle    Completed    Returned None    Input Size    Output Size    Num Used    Num Empty  Tasks/actor/s   \n",
            "\n",
            " Stage 00 - FilePartitioningStage          0          1          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 01 - JsonlReaderStage               0         10          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 02 - Filter                         0         10          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 03 - JsonlWriter                    0          9          0          0          0            0                0             0              0           0            0                  \n",
            "\u001b[0m\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3209316)\u001b[0m 2026-02-26 01:05:52.263 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3209316)\u001b[0m 2026-02-26 01:05:52.263 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3209316)\u001b[0m 2026-02-26 01:05:52.269 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3209316)\u001b[0m 2026-02-26 01:05:52.269 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[32m2026-02-26 01:05:52.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 0\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 00 - FilePartitioningStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 1 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 0.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 0 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 00 - FilePartitioningStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3209322)\u001b[0m 2026-02-26 01:05:52.377 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3209322)\u001b[0m 2026-02-26 01:05:52.377 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3209317)\u001b[0m 2026-02-26 01:05:52.311 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3209317)\u001b[0m 2026-02-26 01:05:52.311 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3209316)\u001b[0m 2026-02-26 01:05:52.292 | DEBUG    | nemo_curator.stages.file_partitioning:_get_file_list:179 - Getting file list for ./wiki_categories_data\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3209316)\u001b[0m 2026-02-26 01:05:52.295 | INFO     | nemo_curator.stages.file_partitioning:process:106 - Found 2 files\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3209316)\u001b[0m 2026-02-26 01:05:52.296 | INFO     | nemo_curator.stages.file_partitioning:process:117 - No partitions specified, defaulting to one file per partition\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3209316)\u001b[0m 2026-02-26 01:05:52.296 | INFO     | nemo_curator.stages.file_partitioning:process:143 - Created 2 file groups from 2 files\n",
            "\u001b[32m2026-02-26 01:05:52.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 1\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 01 - JsonlReaderStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 10 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 10.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 10 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 7.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 7 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 28.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 28 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 19.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 19 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 22.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 22 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 16.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 16 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 25.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 25 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 13.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 13 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 4.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 4 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 1.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 1 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:52.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 01 - JsonlReaderStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209333)\u001b[0m 2026-02-26 01:05:52.501 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209333)\u001b[0m 2026-02-26 01:05:52.501 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209333)\u001b[0m 2026-02-26 01:05:52.503 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209333)\u001b[0m 2026-02-26 01:05:52.504 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[32m2026-02-26 01:05:55.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 2\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 02 - Filter. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 10 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 2.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 2 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 29.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 29 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 5.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 5 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 14.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 14 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 11.\u001b[0m\n",
            "\u001b[36m(Stage 02 - Filter pid=3209336)\u001b[0m 2026-02-26 01:05:55.899 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - Filter\n",
            "\u001b[36m(Stage 02 - Filter pid=3209336)\u001b[0m 2026-02-26 01:05:55.900 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - Filter\n",
            "\u001b[32m2026-02-26 01:05:55.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 11 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 8.\u001b[0m\n",
            "\u001b[36m(Stage 02 - Filter pid=3209320)\u001b[0m 2026-02-26 01:05:55.831 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 02 - Filter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - Filter pid=3209320)\u001b[0m 2026-02-26 01:05:55.831 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 02 - Filter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[32m2026-02-26 01:05:55.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 8 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 23.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 23 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 17.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 17 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 20.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 20 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 26.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 26 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 02 - Filter stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 3\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 03 - JsonlWriter. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 9 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 12.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 12 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 21.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 21 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 24.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 24 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 18.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 18 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 27.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 27 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 6.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 6 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 3.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 3 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 15.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 15 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 9.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 9 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 03 - JsonlWriter stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m543\u001b[0m - \u001b[1mAll stages are done. Finishing pipeline.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:55.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.01699376106262207 seconds to get node resource info.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209333)\u001b[0m 2026-02-26 01:05:55.916 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:90 - File /home/sanjay/ee194-a2/wiki_domain_data/02a5bb78f13e.jsonl already exists, overwriting it\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209333)\u001b[0m 2026-02-26 01:05:55.918 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 6 records to /home/sanjay/ee194-a2/wiki_domain_data/02a5bb78f13e.jsonl\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209333)\u001b[0m 2026-02-26 01:05:55.952 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:90 - File /home/sanjay/ee194-a2/wiki_domain_data/9d598ac18133.jsonl already exists, overwriting it\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209333)\u001b[0m 2026-02-26 01:05:55.953 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 1 records to /home/sanjay/ee194-a2/wiki_domain_data/9d598ac18133.jsonl\n",
            "\u001b[32m2026-02-26 01:05:56.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.029648303985595703 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:05:56.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.005532503128051758 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:06.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mPipeline completed successfully with 2 output tasks\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3209319)\u001b[0m 2026-02-26 01:05:52.364 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3209319)\u001b[0m 2026-02-26 01:05:52.364 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209343)\u001b[0m 2026-02-26 01:05:52.614 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3209343)\u001b[0m 2026-02-26 01:05:52.614 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - Filter pid=3209334)\u001b[0m 2026-02-26 01:05:55.905 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - Filter\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - Filter pid=3209334)\u001b[0m 2026-02-26 01:05:55.906 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - Filter\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Run the pipeline\n",
        "results = pipeline.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8614de38",
      "metadata": {},
      "source": [
        "You can use the following bash command to count the number documents within your `wiki_domain_dir`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7d2bed58",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    6 ./wiki_domain_data/02a5bb78f13e.jsonl\n",
            "    1 ./wiki_domain_data/9d598ac18133.jsonl\n",
            "    7 total\n"
          ]
        }
      ],
      "source": [
        "!wc -l ./wiki_domain_data/*.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1504b1",
      "metadata": {},
      "source": [
        "Feel free to do some exploratory analyses of the categories of data available. Include your explorations below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291995b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# exploratory analysis here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6ac5ed0",
      "metadata": {},
      "source": [
        "## Implement a Pipeline [30 points]\n",
        "\n",
        "Create and run a data curation pipeline. Explain your reasoning for each stage included and how you expect it to be relevant to your target domain and/or findings from your exploratory analysis.\n",
        "\n",
        "Some options include:\n",
        "- Heuristic filters: using `ScoreFilter` and/or `Filter` as the stage(s), with an existing or custom `DocumentFilter` as the parameter(s)\n",
        "- Modifiers: using `Modify` as the stage(s), with an existing or custom `DocumentModifier` as the parameter(s)\n",
        "- Deduplication: exact, fuzzy, and/or semantic deduplication workflow(s)\n",
        "- Quality classifiers: determining educational value using a FineWeb-Edu classifier, etc.\n",
        "\n",
        "Please note that since deduplication is not a map-style operation, you do **not** add it to a `Pipeline`. Instead, deduplication is initialized as a **workflow** (e.g., `workflow = TextSemanticDeduplicationWorkflow(...)`) and run with `workflow.run()`. See the existing [tutorials](https://github.com/NVIDIA-NeMo/Curator/tree/main/tutorials/text/deduplication) and/or NeMo Curator documentation for more help.\n",
        "\n",
        "You are encouraged to implement own own custom filters and/or stages in Curator! You are also encouraged to look at the number of dropped documents or other interesting statistics per stage.\n",
        "\n",
        "Save your final curated dataset in a directory called `wiki_curated_domain_data/`.\n",
        "\n",
        "### Scoring\n",
        "\n",
        "- A deduplication workflow is required [10 points]\n",
        "- Additional stages (not including read/write) are 5 points each (up to 15 points)\n",
        "- Justification for each stage is required [5 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "50ef5ce3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:06:23.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_reader' to pipeline 'wiki_curation_pipeline'\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(name='wiki_curation_pipeline', stages=[jsonl_reader(JsonlReader)])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the pipeline\n",
        "pipeline = Pipeline(\"wiki_curation_pipeline\")\n",
        "\n",
        "jsonl_reader = JsonlReader(wiki_domain_dir)\n",
        "pipeline.add_stage(jsonl_reader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "40e21529",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:06:25.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'UnicodeReformatter' to pipeline 'wiki_curation_pipeline'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:25.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'NewlineNormalizer' to pipeline 'wiki_curation_pipeline'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:25.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'word_count' to pipeline 'wiki_curation_pipeline'\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(name='wiki_curation_pipeline', stages=[jsonl_reader(JsonlReader), UnicodeReformatter(Modify), NewlineNormalizer(Modify), word_count(ScoreFilter)])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nemo_curator.stages.text.modules import ScoreFilter, Modify\n",
        "from nemo_curator.stages.text.modifiers.unicode_reformatter import UnicodeReformatter\n",
        "from nemo_curator.stages.text.modifiers.newline_normalizer import NewlineNormalizer\n",
        "from nemo_curator.stages.text.filters.heuristic_filter import (\n",
        "    WordCountFilter,\n",
        "    RepeatedParagraphsFilter,\n",
        "    MeanWordLengthFilter,\n",
        ")\n",
        "\n",
        "# Stage 1: Unicode normalization\n",
        "# Wikipedia dumps can contain mojibake (garbled Unicode) from encoding issues.\n",
        "# UnicodeReformatter uses ftfy to fix these artifacts, ensuring clean text\n",
        "# before any downstream filtering or analysis.\n",
        "pipeline.add_stage(Modify(modifier_fn=UnicodeReformatter(), input_fields=\"text\"))\n",
        "\n",
        "# Stage 2: Normalize excessive newlines\n",
        "# Articles may have inconsistent whitespace from the extraction process.\n",
        "# Collapsing 3+ consecutive newlines to 2 gives uniform paragraph separation.\n",
        "pipeline.add_stage(Modify(modifier_fn=NewlineNormalizer(), input_fields=\"text\"))\n",
        "\n",
        "# Stage 3: Filter out extremely short or long documents\n",
        "# Very short docs (< 50 words) are likely stubs with no real content.\n",
        "# Very long docs (> 10000 words) may be list-heavy disambiguation pages.\n",
        "# Keeping a reasonable range ensures substantive, focused articles.\n",
        "pipeline.add_stage(ScoreFilter(filter_obj=WordCountFilter(min_words=50, max_words=10000), text_field=\"text\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "30b1aed4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:06:28.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_writer' to pipeline 'wiki_curation_pipeline'\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(name='wiki_curation_pipeline', stages=[jsonl_reader(JsonlReader), UnicodeReformatter(Modify), NewlineNormalizer(Modify), word_count(ScoreFilter), jsonl_writer(JsonlWriter)])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "curated_pre_dedup_dir = \"./wiki_curated_pre_dedup\"\n",
        "jsonl_writer = JsonlWriter(curated_pre_dedup_dir, write_kwargs={\"force_ascii\": False})\n",
        "pipeline.add_stage(jsonl_writer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "49b44b42",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:06:29.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: wiki_curation_pipeline\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mDecomposing composite stage: jsonl_reader\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExpanded 'jsonl_reader' into 2 execution stages\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mExecution mode: STREAMING\u001b[0m\n",
            "2026-02-26 01:06:29,828\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:06:29,833\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:06:29,842\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\u001b[32m2026-02-26 01:06:29.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mPipelineSpec:\n",
            "  config: PipelineConfig(execution_mode=<ExecutionMode.STREAMING: 0>, num_setup_attempts_python=1, num_run_attempts_python=1, max_setup_failure_percentage=None, ignore_failures=False, reset_workers_on_failure=False, slots_per_actor=2, worker_max_lifetime_m=0, worker_restart_interval_m=1, logging_interval_s=60, failures_return_nones=False, return_last_stage_outputs=True, actor_pool_verbosity_level=<VerbosityLevel.INFO: 1>, monitoring_verbosity_level=<VerbosityLevel.INFO: 1>, mode_specific=StreamingSpecificSpec(autoscale_interval_s=180, autoscaler_verbosity_level=<VerbosityLevel.INFO: 1>, executor_verbosity_level=<VerbosityLevel.INFO: 1>), log_worker_allocation_layout=True, cpu_allocation_percentage=0.95, clear_cuda_visible_devices_on_cpu_actors=True)\n",
            "  job_info: None\n",
            "  Stage 0:\n",
            "   class_name: FilePartitioningStage\n",
            "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: 1\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 1:\n",
            "   class_name: JsonlReaderStage\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 2:\n",
            "   class_name: Modify\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 3:\n",
            "   class_name: Modify\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 4:\n",
            "   class_name: ScoreFilter\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 5:\n",
            "   class_name: JsonlWriter\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:29.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mInitialized Ray cluster.\u001b[0m\n",
            "2026-02-26 01:06:29,870\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:06:29,876\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:06:29,876\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
            "\u001b[32m2026-02-26 01:06:29.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.cluster\u001b[0m:\u001b[36minit_or_connect_to_cluster\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mRay dashboard url: 127.0.0.1:8265\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m759\u001b[0m - \u001b[1mDetermining number of nvdecs/nvencs per gpu in this cluster.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m775\u001b[0m - \u001b[1mGpu with name NVIDIA H100 80GB HBM3 found. Looking up nvdecs and nvencs...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m777\u001b[0m - \u001b[1mFound the following gpu resources: GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mCreated/connected to cluster with resources: PoolOfResources(cpus=30.0, gpus=8.0, nvdecs=56.0, nvencs=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mSetting up fragmentation based autoscaler with problem: Problem(cluster_resources=ClusterResources(nodes={'ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71': NodeResources(cpus=30, gpus=[GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())], name='ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71')}), stages=[ProblemStage(name='Stage 00 - FilePartitioningStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=1, over_provision_factor=None), ProblemStage(name='Stage 01 - JsonlReaderStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 02 - Modify', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 03 - Modify', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 04 - ScoreFilter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 05 - JsonlWriter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None)])\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mStarting main loop\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mAutoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mSolving the following naiive allocation problem:\n",
            "{ 'cluster_resources': { 'cpus': 30.0,\n",
            "                         'gpus': 8.0,\n",
            "                         'nvdecs': 56.0,\n",
            "                         'nvencs': 0.0},\n",
            "  'stages': [ { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 00 - FilePartitioningStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': 1,\n",
            "                'resources_per_worker': { 'cpus': 0.5,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 01 - JsonlReaderStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 02 - Modify',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 03 - Modify',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 04 - ScoreFilter',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 05 - JsonlWriter',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1}]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mGot the following naiive allocation result:\n",
            "{ 'allocation_result': { 'cluster_resources': { 'cpus': 30.0,\n",
            "                                                'gpus': 8.0,\n",
            "                                                'nvdecs': 56.0,\n",
            "                                                'nvencs': 0.0},\n",
            "                         'stages': [ { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 1,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 00 - '\n",
            "                                                            'FilePartitioningStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': 1,\n",
            "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 5,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 01 - '\n",
            "                                                            'JsonlReaderStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 5,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 02 - Modify',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 5,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 03 - Modify',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 5,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 04 - '\n",
            "                                                            'ScoreFilter',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 5,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 05 - '\n",
            "                                                            'JsonlWriter',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}}],\n",
            "                         'throughput': 1.0},\n",
            "  'num_slots_per_state': [2, 2, 2, 2, 2, 2]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36mrun_fragmentation_autoscaler\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mRunning phase 4...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:32.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mDone calculating autoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 3.323503017425537 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.00896310806274414 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.006453514099121094 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 3.342250347137451 to get stats.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
            "Pipeline duration: 0.0572166919708252 minutes\n",
            "Number of initial input samples: 1\n",
            "Number of input samples remaining: 1\n",
            "Streaming pipeline main loop rate: 0\n",
            "\n",
            "Cluster Resources:\n",
            "\n",
            " Resource                    Total    Available \n",
            "\n",
            " CPUs                        32           31    \n",
            "\n",
            " GPUs                         8            8    \n",
            "\n",
            " Memory (GB)               1751.72      1751.72 \n",
            "\n",
            " Object Store Memory (GB)   200          200    \n",
            "\n",
            "\n",
            "Resource Usage by Stage:\n",
            "\n",
            " Stage                               CPU %    Memory (GB)    Actor Count    CPU % per worker    Memory (GB) per worker \n",
            "\n",
            " Stage 00 - FilePartitioningStage        0              0              0                   0                         0 \n",
            "\n",
            " Stage 01 - JsonlReaderStage             0              0              0                   0                         0 \n",
            "\n",
            " Stage 02 - Modify                       0              0              0                   0                         0 \n",
            "\n",
            " Stage 03 - Modify                       0              0              0                   0                         0 \n",
            "\n",
            " Stage 04 - ScoreFilter                  0              0              0                   0                         0 \n",
            "\n",
            " Stage 05 - JsonlWriter                  0              0              0                   0                         0 \n",
            "\n",
            "\n",
            "Stage state:\n",
            "\n",
            " Stage                               Actors:    Actors:    Actors:    Actors:    Actors:       Tasks:           Tasks:        Queue:         Queue:      Slots:       Slots:  Speed:          \n",
            "                                      Target    Pending      Ready    Running       Idle    Completed    Returned None    Input Size    Output Size    Num Used    Num Empty  Tasks/actor/s   \n",
            "\n",
            " Stage 00 - FilePartitioningStage          0          1          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 01 - JsonlReaderStage               0          6          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 02 - Modify                         0          6          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 03 - Modify                         0          6          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 04 - ScoreFilter                    0          6          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 05 - JsonlWriter                    0          5          0          0          0            0                0             0              0           0            0                  \n",
            "\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3221067)\u001b[0m 2026-02-26 01:06:36.714 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3221067)\u001b[0m 2026-02-26 01:06:36.714 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3221067)\u001b[0m 2026-02-26 01:06:36.720 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3221067)\u001b[0m 2026-02-26 01:06:36.720 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3221068)\u001b[0m 2026-02-26 01:06:36.809 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3221068)\u001b[0m 2026-02-26 01:06:36.810 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[32m2026-02-26 01:06:36.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 0\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 00 - FilePartitioningStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 1 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 0.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 0 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 00 - FilePartitioningStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 1\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 01 - JsonlReaderStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 6 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 21.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 21 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 16.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 16 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 11.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 11 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 6.\u001b[0m\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3221068)\u001b[0m 2026-02-26 01:06:36.820 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3221068)\u001b[0m 2026-02-26 01:06:36.821 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3221068)\u001b[0m 2026-02-26 01:06:36.849 | DEBUG    | nemo_curator.stages.file_partitioning:_get_file_list:179 - Getting file list for ./wiki_domain_data\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3221068)\u001b[0m 2026-02-26 01:06:36.852 | INFO     | nemo_curator.stages.file_partitioning:process:106 - Found 2 files\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3221068)\u001b[0m 2026-02-26 01:06:36.852 | INFO     | nemo_curator.stages.file_partitioning:process:117 - No partitions specified, defaulting to one file per partition\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3221068)\u001b[0m 2026-02-26 01:06:36.852 | INFO     | nemo_curator.stages.file_partitioning:process:143 - Created 2 file groups from 2 files\n",
            "\u001b[32m2026-02-26 01:06:36.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 6 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 26.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 26 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 1.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 1 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:36.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 01 - JsonlReaderStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 05 - JsonlWriter pid=3221096)\u001b[0m 2026-02-26 01:06:37.148 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 05 - JsonlWriter\n",
            "\u001b[36m(Stage 05 - JsonlWriter pid=3221096)\u001b[0m 2026-02-26 01:06:37.148 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 05 - JsonlWriter\n",
            "\u001b[36m(Stage 05 - JsonlWriter pid=3221083)\u001b[0m 2026-02-26 01:06:37.136 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 05 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 05 - JsonlWriter pid=3221083)\u001b[0m 2026-02-26 01:06:37.137 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 05 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - Modify pid=3221080)\u001b[0m 2026-02-26 01:06:40.340 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - Modify\n",
            "\u001b[36m(Stage 02 - Modify pid=3221080)\u001b[0m 2026-02-26 01:06:40.341 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - Modify\n",
            "\u001b[36m(Stage 02 - Modify pid=3221081)\u001b[0m 2026-02-26 01:06:40.330 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 02 - Modify on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - Modify pid=3221081)\u001b[0m 2026-02-26 01:06:40.331 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 02 - Modify on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[32m2026-02-26 01:06:40.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 2\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 02 - Modify. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 6 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 2.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 2 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 12.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 12 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 7.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 7 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 22.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 22 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 27.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 27 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 17.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 17 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 02 - Modify stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 04 - ScoreFilter pid=3221088)\u001b[0m 2026-02-26 01:06:40.390 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 04 - ScoreFilter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 04 - ScoreFilter pid=3221088)\u001b[0m 2026-02-26 01:06:40.390 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 04 - ScoreFilter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 04 - ScoreFilter pid=3221088)\u001b[0m 2026-02-26 01:06:40.398 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 04 - ScoreFilter\n",
            "\u001b[36m(Stage 04 - ScoreFilter pid=3221088)\u001b[0m 2026-02-26 01:06:40.399 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 04 - ScoreFilter\n",
            "\u001b[32m2026-02-26 01:06:40.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 3\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 03 - Modify. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 6 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 28.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 28 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 8.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 8 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 18.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 18 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 23.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 23 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 13.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 13 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 3.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 3 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 03 - Modify stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 4\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 04 - ScoreFilter. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 6 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 24.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 24 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 29.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 29 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 19.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 19 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 14.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 14 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 4.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 4 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 9.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 9 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 04 - ScoreFilter stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 5\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 05 - JsonlWriter. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 5 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 10.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 10 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 5.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 5 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 25.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 25 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 15.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 15 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 20.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 20 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 05 - JsonlWriter stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m543\u001b[0m - \u001b[1mAll stages are done. Finishing pipeline.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.015366077423095703 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:40.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.014555215835571289 seconds to get cluster info.\u001b[0m\n",
            "\u001b[36m(Stage 05 - JsonlWriter pid=3221078)\u001b[0m 2026-02-26 01:06:40.757 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 1 records to /home/sanjay/ee194-a2/wiki_curated_pre_dedup/60bf0e342ad9.jsonl\n",
            "\u001b[32m2026-02-26 01:06:40.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.00786900520324707 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:06:50.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mPipeline completed successfully with 2 output tasks\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3221069)\u001b[0m 2026-02-26 01:06:36.846 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3221069)\u001b[0m 2026-02-26 01:06:36.847 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 05 - JsonlWriter pid=3221083)\u001b[0m 2026-02-26 01:06:37.144 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 05 - JsonlWriter\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 05 - JsonlWriter pid=3221083)\u001b[0m 2026-02-26 01:06:37.146 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 05 - JsonlWriter\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - Modify pid=3221082)\u001b[0m 2026-02-26 01:06:40.626 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - Modify\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - Modify pid=3221082)\u001b[0m 2026-02-26 01:06:40.626 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - Modify\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - Modify pid=3221084)\u001b[0m 2026-02-26 01:06:40.609 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 03 - Modify on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - Modify pid=3221084)\u001b[0m 2026-02-26 01:06:40.609 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 03 - Modify on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 04 - ScoreFilter pid=3221093)\u001b[0m 2026-02-26 01:06:40.683 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 04 - ScoreFilter\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 04 - ScoreFilter pid=3221093)\u001b[0m 2026-02-26 01:06:40.683 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 04 - ScoreFilter\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 05 - JsonlWriter pid=3221083)\u001b[0m 2026-02-26 01:06:40.758 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 5 records to /home/sanjay/ee194-a2/wiki_curated_pre_dedup/85b9d8b9752e.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Run the pipeline\n",
        "results = pipeline.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3f84e8c",
      "metadata": {},
      "source": [
        "### Deduplication\n",
        "\n",
        "Wikipedia dumps can contain duplicate articles (e.g. redirects, near-identical revisions across dump chunks). Exact deduplication hashes each document's text and removes entries with identical hashes, ensuring every article in the final dataset is unique. This is critical for preventing training data leakage and reducing dataset bias toward over-represented content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e6c86305",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:08:55.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: input_filegroups_pipeline\u001b[0m\n",
            "2026-02-26 01:08:55,227\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:08:55,231\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:08:55,232\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
            "\u001b[32m2026-02-26 01:08:55.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.utils\u001b[0m:\u001b[36mexecute_setup_on_node\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExecuting setup on node ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71 for 1 stages\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:55.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mSetup on node complete for all stages. Starting Ray Actor Pool pipeline with 1 stages\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:55.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1m\n",
            "Processing stage 1/1: FilePartitioningStage(file_paths='./wiki_curated_pre_dedup', files_per_partition=None, blocksize='2GiB', file_extensions=['.jsonl', '.json', '.parquet'], storage_options={}, limit=None, name='file_partitioning')\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:55.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1m  Input tasks: 1\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:55.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.utils\u001b[0m:\u001b[36mcalculate_optimal_actors_for_stage\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1m    Resource calculation: CPU limit=64, GPU limit=2147483647\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:55.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.utils\u001b[0m:\u001b[36mcalculate_optimal_actors_for_stage\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m    Available: 32.0 CPUs, 8.0 GPUs\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:55.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.utils\u001b[0m:\u001b[36mcalculate_optimal_actors_for_stage\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1m    Stage requirements: 0.5 CPUs, 0.0 GPUs\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:55.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1m FilePartitioningStage(file_paths='./wiki_curated_pre_dedup', files_per_partition=None, blocksize='2GiB', file_extensions=['.jsonl', '.json', '.parquet'], storage_options={}, limit=None, name='file_partitioning') - Creating 1 actors (CPUs: 0.5, GPUs: 0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:55.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mCreated actor pool for file_partitioning with 1 actors\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:56.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36m_process_stage_with_pool\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mBroke down 1 tasks into batches of 1 for a total of 1 batches for file_partitioning\u001b[0m\n",
            "Processing file_partitioning: 100%|| 1/1 [00:00<00:00, 478.69it/s]\n",
            "\u001b[32m2026-02-26 01:08:56.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m  Output tasks: 1\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:56.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\n",
            "Pipeline completed. Final results: 1 tasks\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:56.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mShutting down Ray to clean up all resources...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:56.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.stages.deduplication.exact.workflow\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mCreated input tasks from ./wiki_curated_pre_dedup in 1.02 seconds\u001b[0m\n",
            "\u001b[32m2026-02-26 01:08:56.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: exact_deduplication_pipeline\u001b[0m\n",
            "2026-02-26 01:08:56,241\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:08:56,246\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:08:56,257\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\u001b[32m2026-02-26 01:08:56.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.utils\u001b[0m:\u001b[36mexecute_setup_on_node\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExecuting setup on node ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71 for 1 stages\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mSetup on node complete for all stages. Starting Ray Actor Pool pipeline with 1 stages\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1m\n",
            "Processing stage 1/1: ExactDuplicateIdentification\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1m  Input tasks: 1\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.utils\u001b[0m:\u001b[36mcalculate_optimal_actors_for_stage\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1m    Resource calculation: CPU limit=32, GPU limit=8\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.utils\u001b[0m:\u001b[36mcalculate_optimal_actors_for_stage\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m    Available: 32.0 CPUs, 8.0 GPUs\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.utils\u001b[0m:\u001b[36mcalculate_optimal_actors_for_stage\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1m    Stage requirements: 1.0 CPUs, 1.0 GPUs\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1m ExactDuplicateIdentification - Creating 1 actors (CPUs: 1.0, GPUs: 1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1m  Creating Shuffle actors for stage: ExactDuplicateIds\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36m_create_rapidsmpf_actors\u001b[0m:\u001b[36m228\u001b[0m - \u001b[1m    Initializing RapidsMPFShuffling actor pool with 1 actors\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:00.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36m_create_rapidsmpf_actors\u001b[0m:\u001b[36m241\u001b[0m - \u001b[1m    Setting up UCXX communication...\u001b[0m\n",
            "\u001b[36m(ShuffleStageAdapter pid=3247935)\u001b[0m 2026-02-26 01:09:04.682 | DEBUG    | nemo_curator.backends.experimental.ray_actor_pool.shuffle_adapter:__init__:94 - Initialized ShuffleStageAdapter actor for rank 0/1\n",
            "\u001b[32m2026-02-26 01:09:05.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36m_create_rapidsmpf_actors\u001b[0m:\u001b[36m249\u001b[0m - \u001b[1m    UCXX setup complete\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:05.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mCreated actor pool for ExactDuplicateIds with 1 actors\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ShuffleStageAdapter pid=3247935)\u001b[0m [1772068145.601471] [instance-20260131-194227:3247935:0]          parser.c:2359 UCX  WARN  unused environment variable: UCX_MEMTYPE_CACHE (maybe: UCX_MEMTYPE_CACHE?)\n",
            "\u001b[36m(ShuffleStageAdapter pid=3247935)\u001b[0m [1772068145.601471] [instance-20260131-194227:3247935:0]          parser.c:2359 UCX  WARN  (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserting into shuffler: 100%|| 1/1 [00:00<00:00,  1.84it/s]\n",
            "\u001b[32m2026-02-26 01:09:06.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m  Output tasks: 1\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:06.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\n",
            "Pipeline completed. Final results: 1 tasks\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:06.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.experimental.ray_actor_pool.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mShutting down Ray to clean up all resources...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:06.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.stages.deduplication.exact.workflow\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mExact duplicate identification pipeline completed in 10.12 seconds\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:06.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.stages.deduplication.exact.workflow\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1mNo exact duplicates found in the dataset.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:06.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.stages.deduplication.exact.workflow\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m261\u001b[0m - \u001b[1mExact deduplication pipeline completed in 11.14 seconds\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicates found: 0\n"
          ]
        }
      ],
      "source": [
        "from nemo_curator.stages.deduplication.exact.workflow import ExactDeduplicationWorkflow\n",
        "\n",
        "dedup_cache_dir = \"./wiki_dedup_cache\"\n",
        "\n",
        "exact_dedup = ExactDeduplicationWorkflow(\n",
        "    input_path=curated_pre_dedup_dir,\n",
        "    output_path=dedup_cache_dir,\n",
        "    input_filetype=\"jsonl\",\n",
        "    text_field=\"text\",\n",
        "    assign_id=False,\n",
        "    id_field=\"id\",\n",
        ")\n",
        "dedup_result = exact_dedup.run()\n",
        "print(f\"Duplicates found: {dedup_result.metadata.get('num_duplicates', 0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "5ee00ade",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:09:17.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: text_duplicates_removal_workflow\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mExecution mode: STREAMING\u001b[0m\n",
            "2026-02-26 01:09:17,305\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:09:17,309\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:09:17,318\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\u001b[32m2026-02-26 01:09:17.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mPipelineSpec:\n",
            "  config: PipelineConfig(execution_mode=<ExecutionMode.STREAMING: 0>, num_setup_attempts_python=1, num_run_attempts_python=1, max_setup_failure_percentage=None, ignore_failures=False, reset_workers_on_failure=False, slots_per_actor=2, worker_max_lifetime_m=0, worker_restart_interval_m=1, logging_interval_s=60, failures_return_nones=False, return_last_stage_outputs=True, actor_pool_verbosity_level=<VerbosityLevel.INFO: 1>, monitoring_verbosity_level=<VerbosityLevel.INFO: 1>, mode_specific=StreamingSpecificSpec(autoscale_interval_s=180, autoscaler_verbosity_level=<VerbosityLevel.INFO: 1>, executor_verbosity_level=<VerbosityLevel.INFO: 1>), log_worker_allocation_layout=True, cpu_allocation_percentage=0.95, clear_cuda_visible_devices_on_cpu_actors=True)\n",
            "  job_info: None\n",
            "  Stage 0:\n",
            "   class_name: FilePartitioningStage\n",
            "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: 1\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 1:\n",
            "   class_name: JsonlReaderStage\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 2:\n",
            "   class_name: TextDuplicatesRemovalStage\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 3:\n",
            "   class_name: JsonlWriter\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:17.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mInitialized Ray cluster.\u001b[0m\n",
            "2026-02-26 01:09:17,342\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:09:17,347\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:09:17,348\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
            "\u001b[32m2026-02-26 01:09:17.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.cluster\u001b[0m:\u001b[36minit_or_connect_to_cluster\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mRay dashboard url: 127.0.0.1:8265\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m759\u001b[0m - \u001b[1mDetermining number of nvdecs/nvencs per gpu in this cluster.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m775\u001b[0m - \u001b[1mGpu with name NVIDIA H100 80GB HBM3 found. Looking up nvdecs and nvencs...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m777\u001b[0m - \u001b[1mFound the following gpu resources: GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mCreated/connected to cluster with resources: PoolOfResources(cpus=30.0, gpus=8.0, nvdecs=56.0, nvencs=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mSetting up fragmentation based autoscaler with problem: Problem(cluster_resources=ClusterResources(nodes={'ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71': NodeResources(cpus=30, gpus=[GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())], name='ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71')}), stages=[ProblemStage(name='Stage 00 - FilePartitioningStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=1, over_provision_factor=None), ProblemStage(name='Stage 01 - JsonlReaderStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 02 - TextDuplicatesRemovalStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 03 - JsonlWriter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None)])\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mStarting main loop\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mAutoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mSolving the following naiive allocation problem:\n",
            "{ 'cluster_resources': { 'cpus': 30.0,\n",
            "                         'gpus': 8.0,\n",
            "                         'nvdecs': 56.0,\n",
            "                         'nvencs': 0.0},\n",
            "  'stages': [ { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 00 - FilePartitioningStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': 1,\n",
            "                'resources_per_worker': { 'cpus': 0.5,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 01 - JsonlReaderStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 02 - TextDuplicatesRemovalStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 03 - JsonlWriter',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1}]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mGot the following naiive allocation result:\n",
            "{ 'allocation_result': { 'cluster_resources': { 'cpus': 30.0,\n",
            "                                                'gpus': 8.0,\n",
            "                                                'nvdecs': 56.0,\n",
            "                                                'nvencs': 0.0},\n",
            "                         'stages': [ { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 1,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 00 - '\n",
            "                                                            'FilePartitioningStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': 1,\n",
            "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 9,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 01 - '\n",
            "                                                            'JsonlReaderStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 9,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 02 - '\n",
            "                                                            'TextDuplicatesRemovalStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 9,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 03 - '\n",
            "                                                            'JsonlWriter',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}}],\n",
            "                         'throughput': 1.0},\n",
            "  'num_slots_per_state': [2, 2, 2, 2]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36mrun_fragmentation_autoscaler\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mRunning phase 4...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:20.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mDone calculating autoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 3.428405523300171 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.008025169372558594 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.005330324172973633 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 3.443939208984375 to get stats.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
            "Pipeline duration: 0.058716968695322676 minutes\n",
            "Number of initial input samples: 1\n",
            "Number of input samples remaining: 1\n",
            "Streaming pipeline main loop rate: 0\n",
            "\n",
            "Cluster Resources:\n",
            "\n",
            " Resource                    Total    Available \n",
            "\n",
            " CPUs                        32           31    \n",
            "\n",
            " GPUs                         8            8    \n",
            "\n",
            " Memory (GB)               1751.72      1751.72 \n",
            "\n",
            " Object Store Memory (GB)   200          200    \n",
            "\n",
            "\n",
            "Resource Usage by Stage:\n",
            "\n",
            " Stage                                    CPU %    Memory (GB)    Actor Count    CPU % per worker    Memory (GB) per worker \n",
            "\n",
            " Stage 00 - FilePartitioningStage             0              0              0                   0                         0 \n",
            "\n",
            " Stage 01 - JsonlReaderStage                  0              0              0                   0                         0 \n",
            "\n",
            " Stage 02 - TextDuplicatesRemovalStage        0              0              0                   0                         0 \n",
            "\n",
            " Stage 03 - JsonlWriter                       0              0              0                   0                         0 \n",
            "\n",
            "\n",
            "Stage state:\n",
            "\n",
            " Stage                                    Actors:    Actors:    Actors:    Actors:    Actors:       Tasks:           Tasks:        Queue:         Queue:      Slots:       Slots:  Speed:          \n",
            "                                           Target    Pending      Ready    Running       Idle    Completed    Returned None    Input Size    Output Size    Num Used    Num Empty  Tasks/actor/s   \n",
            "\n",
            " Stage 00 - FilePartitioningStage               0          1          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 01 - JsonlReaderStage                    0         10          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 02 - TextDuplicatesRemovalStage          0         10          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 03 - JsonlWriter                         0          9          0          0          0            0                0             0              0           0            0                  \n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 0\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 00 - FilePartitioningStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 1 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 0.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 0 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:23.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 00 - FilePartitioningStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3248841)\u001b[0m 2026-02-26 01:09:24.001 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3248841)\u001b[0m 2026-02-26 01:09:24.001 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3248839)\u001b[0m 2026-02-26 01:09:23.929 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3248839)\u001b[0m 2026-02-26 01:09:23.929 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3248839)\u001b[0m 2026-02-26 01:09:23.937 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3248839)\u001b[0m 2026-02-26 01:09:23.937 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3248839)\u001b[0m 2026-02-26 01:09:23.969 | DEBUG    | nemo_curator.stages.file_partitioning:_get_file_list:179 - Getting file list for ./wiki_curated_pre_dedup\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3248839)\u001b[0m 2026-02-26 01:09:23.972 | INFO     | nemo_curator.stages.file_partitioning:process:106 - Found 2 files\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3248839)\u001b[0m 2026-02-26 01:09:23.972 | INFO     | nemo_curator.stages.file_partitioning:process:117 - No partitions specified, defaulting to one file per partition\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3248839)\u001b[0m 2026-02-26 01:09:23.972 | INFO     | nemo_curator.stages.file_partitioning:process:143 - Created 2 file groups from 2 files\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3248836)\u001b[0m 2026-02-26 01:09:23.990 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3248836)\u001b[0m 2026-02-26 01:09:23.990 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[32m2026-02-26 01:09:24.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 1\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 01 - JsonlReaderStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 10 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 10.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 10 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 7.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 7 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 28.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 28 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 19.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 19 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 22.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 22 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 16.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 16 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 25.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 25 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 13.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 13 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 4.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 4 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 1.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 1 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 01 - JsonlReaderStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 02 - TextDuplicatesRemovalStage pid=3248848)\u001b[0m 2026-02-26 01:09:24.127 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - TextDuplicatesRemovalStage\n",
            "\u001b[36m(Stage 02 - TextDuplicatesRemovalStage pid=3248848)\u001b[0m 2026-02-26 01:09:24.127 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - TextDuplicatesRemovalStage\n",
            "\u001b[36m(Stage 02 - TextDuplicatesRemovalStage pid=3248842)\u001b[0m 2026-02-26 01:09:24.094 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 02 - TextDuplicatesRemovalStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - TextDuplicatesRemovalStage pid=3248842)\u001b[0m 2026-02-26 01:09:24.094 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 02 - TextDuplicatesRemovalStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3248853)\u001b[0m 2026-02-26 01:09:24.131 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3248853)\u001b[0m 2026-02-26 01:09:24.131 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3248853)\u001b[0m 2026-02-26 01:09:24.133 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3248853)\u001b[0m 2026-02-26 01:09:24.135 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[32m2026-02-26 01:09:24.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 2\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 02 - TextDuplicatesRemovalStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 10 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 2.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 2 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 29.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 29 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 5.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 5 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 14.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 14 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 11.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 11 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 8.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 8 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 23.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 23 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 17.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 17 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 20.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 20 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 26.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 26 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 02 - TextDuplicatesRemovalStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 3\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 03 - JsonlWriter. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 9 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 21.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 21 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 12.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 12 from allocator.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3248853)\u001b[0m 2026-02-26 01:09:24.216 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 1 records to /home/sanjay/ee194-a2/wiki_curated_domain_data/acef2699d502.jsonl\n",
            "\u001b[32m2026-02-26 01:09:24.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 24.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 24 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 18.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 18 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 27.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 27 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 6.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 6 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 3.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 3 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 15.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 15 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 9.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 9 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 03 - JsonlWriter stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m543\u001b[0m - \u001b[1mAll stages are done. Finishing pipeline.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.0016484260559082031 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.0082244873046875 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:09:24.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.005320072174072266 seconds to get actor info.\u001b[0m\n",
            "\u001b[36m(pid=gcs_server)\u001b[0m [2026-02-26 01:09:24,328 E 3085441 3085441] (gcs_server) gcs_actor_scheduler.cc:558: Failed to kill actor 42a8231ceeb3792d22d92fa210000000, return status: Invalid: KillActor RPC failed for actor 42a8231ceeb3792d22d92fa210000000: RpcError: RPC error: Socket closed rpc_code: 14\n",
            "\u001b[36m(pid=gcs_server)\u001b[0m [2026-02-26 01:09:24,330 E 3085441 3085441] (gcs_server) gcs_actor_scheduler.cc:558: Failed to kill actor 7ec06ab302d314f283d62bcd10000000, return status: Invalid: KillActor RPC failed for actor 7ec06ab302d314f283d62bcd10000000: RpcError: RPC error: Socket closed rpc_code: 14\n",
            "\u001b[32m2026-02-26 01:09:34.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mPipeline completed successfully with 2 output tasks\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicates removed: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3248838)\u001b[0m 2026-02-26 01:09:24.032 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3248849)\u001b[0m 2026-02-26 01:09:24.034 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - TextDuplicatesRemovalStage pid=3248857)\u001b[0m 2026-02-26 01:09:24.158 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - TextDuplicatesRemovalStage\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - TextDuplicatesRemovalStage pid=3248857)\u001b[0m 2026-02-26 01:09:24.158 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - TextDuplicatesRemovalStage\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3248854)\u001b[0m 2026-02-26 01:09:24.212 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3248854)\u001b[0m 2026-02-26 01:09:24.212 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3248858)\u001b[0m 2026-02-26 01:09:24.238 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 5 records to /home/sanjay/ee194-a2/wiki_curated_domain_data/8dff7abad519.jsonl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from nemo_curator.stages.text.deduplication import TextDuplicatesRemovalWorkflow\n",
        "\n",
        "curated_data_dir = \"./wiki_curated_domain_data\"\n",
        "ids_to_remove_path = os.path.join(dedup_cache_dir, \"ExactDuplicateIds\")\n",
        "\n",
        "removal_workflow = TextDuplicatesRemovalWorkflow(\n",
        "    input_path=curated_pre_dedup_dir,\n",
        "    ids_to_remove_path=ids_to_remove_path,\n",
        "    output_path=curated_data_dir,\n",
        "    input_filetype=\"jsonl\",\n",
        "    output_filetype=\"jsonl\",\n",
        "    output_kwargs={\"force_ascii\": False},\n",
        "    id_field=\"id\",\n",
        ")\n",
        "removal_result = removal_workflow.run()\n",
        "print(f\"Duplicates removed: {removal_result.metadata.get('num_duplicates_removed', 0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6fce921",
      "metadata": {},
      "source": [
        "## Evaluate the Data [15 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c437d60",
      "metadata": {},
      "source": [
        "In this section, we will compare the non-curated data within `wiki_domain_data/` with the curated data within `wiki_curated_domain_data/`.\n",
        "\n",
        "The best way to compare the effectiveness of curated versus non-curated data is to train separate models with each dataset and evaluate the resulting models themselves. However, in the interest of time, we will use **perplexity** as our evaluation metric.\n",
        "\n",
        "Perplexity is colloquially referred to how \"confusing\" a piece of text is to an LLM. A lower perplexity score indicates that the model is less \"perplexed,\" meaning it is more confident and accurate in predicting the next token in a sequence. This means that we would expect the perplexity of the curated data to be lower than the perplexity of the non-curated data, but maybe that will not be the case for your datasets. If this happens, it is okay. You should reason about the results with respect to your chosen domain.\n",
        "\n",
        "The cell below includes a basic function for calculating the perplexity of a text using the `gpt2` model. Calculate and plot the perplexities of the non-curated versus curated datasets.\n",
        "\n",
        "Consider the following:\n",
        "- The provided function is slow for computing the perplexities of hundreds or thousands of documents. Convert it into a Curator stage.\n",
        "- The `gpt2` model is a nice lightweight and generic model to use here. Evaluation using the `gpt2` model is required. Additionally, you are encouraged to try it out with different models depending on your chosen domain (e.g., if your domain is medicine, consider evaluating with a model specifically intended for medical and clinical text).\n",
        "\n",
        "### Scoring\n",
        "\n",
        "- Conversion to Curator stage [10 points]\n",
        "- Plots for the perplexities of the non-curated versus curated data [5 points]\n",
        "- Extension to domain-specific models and/or metrics, with a comprehensive analysis per method [5 bonus points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "302ee091",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c529a592f8d4417ea307d1b50b0efea8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bbb38cc32a44d14b04dd533986bd272",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2fcd244fe6f4a798b86bbf75ce84883",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9222aa47866f4a6e8d9483968034f371",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30716c742ca2448d84b55a5e400463e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "143746caebf6482facea1b4699886b7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a8fc855d0c34e09abe327157d5be96c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity: 71.11 | Text: This is a well-written coherent sentence.\n",
            "Perplexity: 93.84 | Text: Ths txt has typos and is hard to read.\n"
          ]
        }
      ],
      "source": [
        "# do not modify this cell\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# Load pretrained model and tokenizer\n",
        "model_name = \"gpt2\"  # small, fast for experiments\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "def compute_perplexity(texts):\n",
        "    \"\"\"\n",
        "    texts: list of strings\n",
        "    returns: list of perplexity scores\n",
        "    \"\"\"\n",
        "    perplexities = []\n",
        "\n",
        "    for text in texts:\n",
        "        # Tokenize\n",
        "        encodings = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
        "        input_ids = encodings.input_ids.to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, labels=input_ids)\n",
        "            # Cross-entropy loss per token\n",
        "            loss = outputs.loss\n",
        "        # Perplexity = exp(loss)\n",
        "        perplexity = math.exp(loss.item())\n",
        "        perplexities.append(perplexity)\n",
        "\n",
        "    return perplexities\n",
        "\n",
        "# Example usage\n",
        "texts = [\n",
        "    \"This is a well-written coherent sentence.\",\n",
        "    \"Ths txt has typos and is hard to read.\"\n",
        "]\n",
        "\n",
        "perplexities = compute_perplexity(texts)\n",
        "for t, p in zip(texts, perplexities):\n",
        "    print(f\"Perplexity: {p:.2f} | Text: {t}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9eab1fd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field\n",
        "from nemo_curator.stages.base import ProcessingStage\n",
        "from nemo_curator.stages.resources import Resources\n",
        "from nemo_curator.tasks import DocumentBatch\n",
        "\n",
        "@dataclass\n",
        "class PerplexityScorer(ProcessingStage[DocumentBatch, DocumentBatch]):\n",
        "    \"\"\"Computes per-document perplexity using a causal LM. Reuses the same\n",
        "    compute_perplexity logic from the cell above, but loads the model on the\n",
        "    Ray worker since workers are separate processes.\"\"\"\n",
        "\n",
        "    text_field: str = \"text\"\n",
        "    output_field: str = \"perplexity\"\n",
        "    name: str = \"perplexity_scorer\"\n",
        "    resources: Resources = field(default_factory=lambda: Resources(cpus=1.0, gpus=1.0))\n",
        "\n",
        "    def inputs(self):\n",
        "        return [\"data\"], [self.text_field]\n",
        "\n",
        "    def outputs(self):\n",
        "        return [\"data\"], [self.output_field]\n",
        "\n",
        "    def setup(self, _=None):\n",
        "        self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self._model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\")\n",
        "        self._model.eval()\n",
        "\n",
        "    def process(self, batch: DocumentBatch) -> DocumentBatch:\n",
        "        df = batch.to_pandas()\n",
        "        perplexities = []\n",
        "        for text in df[self.text_field]:\n",
        "            enc = self._tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
        "            input_ids = enc.input_ids.to(\"cuda\")\n",
        "            with torch.no_grad():\n",
        "                loss = self._model(input_ids, labels=input_ids).loss\n",
        "            perplexities.append(math.exp(loss.item()))\n",
        "        df[self.output_field] = perplexities\n",
        "        batch.data = df\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "216d0f67",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:15:52.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_reader' to pipeline 'non_curated_perplexity'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'perplexity_scorer' to pipeline 'non_curated_perplexity'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_writer' to pipeline 'non_curated_perplexity'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: non_curated_perplexity\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mDecomposing composite stage: jsonl_reader\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExpanded 'jsonl_reader' into 2 execution stages\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mExecution mode: STREAMING\u001b[0m\n",
            "2026-02-26 01:15:52,656\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:15:52,660\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:15:52,667\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\u001b[32m2026-02-26 01:15:52.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mPipelineSpec:\n",
            "  config: PipelineConfig(execution_mode=<ExecutionMode.STREAMING: 0>, num_setup_attempts_python=1, num_run_attempts_python=1, max_setup_failure_percentage=None, ignore_failures=False, reset_workers_on_failure=False, slots_per_actor=2, worker_max_lifetime_m=0, worker_restart_interval_m=1, logging_interval_s=60, failures_return_nones=False, return_last_stage_outputs=True, actor_pool_verbosity_level=<VerbosityLevel.INFO: 1>, monitoring_verbosity_level=<VerbosityLevel.INFO: 1>, mode_specific=StreamingSpecificSpec(autoscale_interval_s=180, autoscaler_verbosity_level=<VerbosityLevel.INFO: 1>, executor_verbosity_level=<VerbosityLevel.INFO: 1>), log_worker_allocation_layout=True, cpu_allocation_percentage=0.95, clear_cuda_visible_devices_on_cpu_actors=True)\n",
            "  job_info: None\n",
            "  Stage 0:\n",
            "   class_name: FilePartitioningStage\n",
            "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: 1\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 1:\n",
            "   class_name: JsonlReaderStage\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 2:\n",
            "   class_name: PerplexityScorer\n",
            "   required_resources: Resources(cpus=1.0, gpus=1.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.WHOLE_NUMBERED_GPU: 3>, data=WholeNumberedGpu(num_gpus=1, num_cpus=1.0, num_nvdecs_per_gpu=0, num_nvencs_per_gpu=0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 3:\n",
            "   class_name: JsonlWriter\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:52.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mInitialized Ray cluster.\u001b[0m\n",
            "2026-02-26 01:15:52,694\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:15:52,699\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:15:52,699\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
            "\u001b[32m2026-02-26 01:15:52.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.cluster\u001b[0m:\u001b[36minit_or_connect_to_cluster\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mRay dashboard url: 127.0.0.1:8265\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m759\u001b[0m - \u001b[1mDetermining number of nvdecs/nvencs per gpu in this cluster.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m775\u001b[0m - \u001b[1mGpu with name NVIDIA H100 80GB HBM3 found. Looking up nvdecs and nvencs...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m777\u001b[0m - \u001b[1mFound the following gpu resources: GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mCreated/connected to cluster with resources: PoolOfResources(cpus=30.0, gpus=8.0, nvdecs=56.0, nvencs=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mSetting up fragmentation based autoscaler with problem: Problem(cluster_resources=ClusterResources(nodes={'ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71': NodeResources(cpus=30, gpus=[GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())], name='ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71')}), stages=[ProblemStage(name='Stage 00 - FilePartitioningStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=1, over_provision_factor=None), ProblemStage(name='Stage 01 - JsonlReaderStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 02 - PerplexityScorer', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.WHOLE_NUMBERED_GPU: 3>, data=WholeNumberedGpu(num_gpus=1, num_cpus=1.0, num_nvdecs_per_gpu=0, num_nvencs_per_gpu=0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 03 - JsonlWriter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None)])\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mStarting main loop\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mAutoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mSolving the following naiive allocation problem:\n",
            "{ 'cluster_resources': { 'cpus': 30.0,\n",
            "                         'gpus': 8.0,\n",
            "                         'nvdecs': 56.0,\n",
            "                         'nvencs': 0.0},\n",
            "  'stages': [ { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 00 - FilePartitioningStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': 1,\n",
            "                'resources_per_worker': { 'cpus': 0.5,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 01 - JsonlReaderStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 02 - PerplexityScorer',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 1,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 03 - JsonlWriter',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1}]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mGot the following naiive allocation result:\n",
            "{ 'allocation_result': { 'cluster_resources': { 'cpus': 30.0,\n",
            "                                                'gpus': 8.0,\n",
            "                                                'nvdecs': 56.0,\n",
            "                                                'nvencs': 0.0},\n",
            "                         'stages': [ { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 1,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 00 - '\n",
            "                                                            'FilePartitioningStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': 1,\n",
            "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 8,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 01 - '\n",
            "                                                            'JsonlReaderStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 8,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 02 - '\n",
            "                                                            'PerplexityScorer',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 1,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 8,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 03 - '\n",
            "                                                            'JsonlWriter',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}}],\n",
            "                         'throughput': 1.0},\n",
            "  'num_slots_per_state': [2, 2, 2, 2]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36mrun_fragmentation_autoscaler\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mRunning phase 4...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:55.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mDone calculating autoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:58.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 3.3300893306732178 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:58.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.010119915008544922 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:58.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.006439924240112305 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:58.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 3.349708318710327 to get stats.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:58.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
            "Pipeline duration: 0.057457307974497475 minutes\n",
            "Number of initial input samples: 1\n",
            "Number of input samples remaining: 1\n",
            "Streaming pipeline main loop rate: 0\n",
            "\n",
            "Cluster Resources:\n",
            "\n",
            " Resource                    Total    Available \n",
            "\n",
            " CPUs                        32           31    \n",
            "\n",
            " GPUs                         8            8    \n",
            "\n",
            " Memory (GB)               1751.72      1751.72 \n",
            "\n",
            " Object Store Memory (GB)   200          200    \n",
            "\n",
            "\n",
            "Resource Usage by Stage:\n",
            "\n",
            " Stage                               CPU %    Memory (GB)    Actor Count    CPU % per worker    Memory (GB) per worker \n",
            "\n",
            " Stage 00 - FilePartitioningStage        0              0              0                   0                         0 \n",
            "\n",
            " Stage 01 - JsonlReaderStage             0              0              0                   0                         0 \n",
            "\n",
            " Stage 02 - PerplexityScorer             0              0              0                   0                         0 \n",
            "\n",
            " Stage 03 - JsonlWriter                  0              0              0                   0                         0 \n",
            "\n",
            "\n",
            "Stage state:\n",
            "\n",
            " Stage                               Actors:    Actors:    Actors:    Actors:    Actors:       Tasks:           Tasks:        Queue:         Queue:      Slots:       Slots:  Speed:          \n",
            "                                      Target    Pending      Ready    Running       Idle    Completed    Returned None    Input Size    Output Size    Num Used    Num Empty  Tasks/actor/s   \n",
            "\n",
            " Stage 00 - FilePartitioningStage          0          1          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 01 - JsonlReaderStage               0         11          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 02 - PerplexityScorer               0          8          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 03 - JsonlWriter                    0         10          0          0          0            0                0             0              0           0            0                  \n",
            "\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3279555)\u001b[0m 2026-02-26 01:15:59.310 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3279555)\u001b[0m 2026-02-26 01:15:59.311 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3279555)\u001b[0m 2026-02-26 01:15:59.314 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3279555)\u001b[0m 2026-02-26 01:15:59.314 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3279551)\u001b[0m 2026-02-26 01:15:59.333 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3279551)\u001b[0m 2026-02-26 01:15:59.333 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3279551)\u001b[0m 2026-02-26 01:15:59.344 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3279551)\u001b[0m 2026-02-26 01:15:59.344 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3279551)\u001b[0m 2026-02-26 01:15:59.376 | DEBUG    | nemo_curator.stages.file_partitioning:_get_file_list:179 - Getting file list for ./wiki_domain_data\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3279551)\u001b[0m 2026-02-26 01:15:59.379 | INFO     | nemo_curator.stages.file_partitioning:process:106 - Found 2 files\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3279551)\u001b[0m 2026-02-26 01:15:59.379 | INFO     | nemo_curator.stages.file_partitioning:process:117 - No partitions specified, defaulting to one file per partition\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3279551)\u001b[0m 2026-02-26 01:15:59.379 | INFO     | nemo_curator.stages.file_partitioning:process:143 - Created 2 file groups from 2 files\n",
            "\u001b[32m2026-02-26 01:15:59.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 0\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 00 - FilePartitioningStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 1 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 0.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 0 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 00 - FilePartitioningStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 1\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 01 - JsonlReaderStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 11 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 10.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 10 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 7.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 7 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 29.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 29 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 19.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 19 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 22.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 22 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 16.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 16 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 25.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 25 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 27.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 27 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 13.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 13 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 4.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 4 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 1.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 1 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:15:59.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 01 - JsonlReaderStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3279647)\u001b[0m 2026-02-26 01:15:59.568 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3279647)\u001b[0m 2026-02-26 01:15:59.568 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3279643)\u001b[0m 2026-02-26 01:15:59.557 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3279643)\u001b[0m 2026-02-26 01:15:59.557 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3279637)\u001b[0m 2026-02-26 01:16:02.729 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - PerplexityScorer\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3279633)\u001b[0m 2026-02-26 01:16:02.721 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 02 - PerplexityScorer on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3279633)\u001b[0m 2026-02-26 01:16:02.721 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 02 - PerplexityScorer on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3279639)\u001b[0m 2026-02-26 01:16:08.428 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - PerplexityScorer\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3279629)\u001b[0m 2026-02-26 01:15:59.409 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3279629)\u001b[0m 2026-02-26 01:15:59.410 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3279649)\u001b[0m 2026-02-26 01:15:59.567 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3279649)\u001b[0m 2026-02-26 01:15:59.567 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3279641)\u001b[0m 2026-02-26 01:16:02.806 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - PerplexityScorer\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3279639)\u001b[0m `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3279643)\u001b[0m 2026-02-26 01:16:09.106 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 1 records to /home/sanjay/ee194-a2/wiki_domain_perplexity/271cd48279b2.jsonl\n",
            "\u001b[32m2026-02-26 01:16:09.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 2\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 02 - PerplexityScorer. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 8 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 2.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 2 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 5.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 5 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 14.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 14 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 11.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 11 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 8.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 8 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 23.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 23 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 17.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 17 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 20.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 20 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 02 - PerplexityScorer stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 3\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 03 - JsonlWriter. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 10 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 21.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 21 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 12.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 12 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 24.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 24 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 28.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 28 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 18.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 18 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 6.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 6 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 3.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 3 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 15.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 15 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 9.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 9 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 26.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 26 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 03 - JsonlWriter stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m543\u001b[0m - \u001b[1mAll stages are done. Finishing pipeline.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.013595819473266602 seconds to get node resource info.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3279643)\u001b[0m 2026-02-26 01:16:09.219 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 6 records to /home/sanjay/ee194-a2/wiki_domain_perplexity/5ed1109a28ca.jsonl\n",
            "\u001b[32m2026-02-26 01:16:09.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.032839059829711914 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:09.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.00601649284362793 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mPipeline completed successfully with 2 output tasks\u001b[0m\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3279637)\u001b[0m 2026-02-26 01:16:09.164 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - PerplexityScorer\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_reader' to pipeline 'curated_perplexity'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'perplexity_scorer' to pipeline 'curated_perplexity'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_writer' to pipeline 'curated_perplexity'\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: curated_perplexity\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mDecomposing composite stage: jsonl_reader\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExpanded 'jsonl_reader' into 2 execution stages\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mExecution mode: STREAMING\u001b[0m\n",
            "2026-02-26 01:16:19,320\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:16:19,324\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:16:19,331\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\u001b[32m2026-02-26 01:16:19.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mPipelineSpec:\n",
            "  config: PipelineConfig(execution_mode=<ExecutionMode.STREAMING: 0>, num_setup_attempts_python=1, num_run_attempts_python=1, max_setup_failure_percentage=None, ignore_failures=False, reset_workers_on_failure=False, slots_per_actor=2, worker_max_lifetime_m=0, worker_restart_interval_m=1, logging_interval_s=60, failures_return_nones=False, return_last_stage_outputs=True, actor_pool_verbosity_level=<VerbosityLevel.INFO: 1>, monitoring_verbosity_level=<VerbosityLevel.INFO: 1>, mode_specific=StreamingSpecificSpec(autoscale_interval_s=180, autoscaler_verbosity_level=<VerbosityLevel.INFO: 1>, executor_verbosity_level=<VerbosityLevel.INFO: 1>), log_worker_allocation_layout=True, cpu_allocation_percentage=0.95, clear_cuda_visible_devices_on_cpu_actors=True)\n",
            "  job_info: None\n",
            "  Stage 0:\n",
            "   class_name: FilePartitioningStage\n",
            "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: 1\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 1:\n",
            "   class_name: JsonlReaderStage\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 2:\n",
            "   class_name: PerplexityScorer\n",
            "   required_resources: Resources(cpus=1.0, gpus=1.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.WHOLE_NUMBERED_GPU: 3>, data=WholeNumberedGpu(num_gpus=1, num_cpus=1.0, num_nvdecs_per_gpu=0, num_nvencs_per_gpu=0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "  Stage 3:\n",
            "   class_name: JsonlWriter\n",
            "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
            "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
            "      num_workers: None\n",
            "      num_workers_per_node: None\n",
            "      num_setup_attempts_python: 1\n",
            "      num_run_attempts_python: 1\n",
            "      ignore_failures: False\n",
            "      reset_workers_on_failure: False\n",
            "      slots_per_actor: 2\n",
            "      worker_max_lifetime_m: 0\n",
            "      worker_restart_interval_m: 1\n",
            "      max_setup_failure_percentage: None\n",
            "      over_provision_factor: None\n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:19.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mInitialized Ray cluster.\u001b[0m\n",
            "2026-02-26 01:16:19,355\tINFO worker.py:1696 -- Using address 10.128.0.20:6379 set in the environment variable RAY_ADDRESS\n",
            "2026-02-26 01:16:19,360\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 10.128.0.20:6379...\n",
            "2026-02-26 01:16:19,360\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
            "\u001b[32m2026-02-26 01:16:19.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.cluster\u001b[0m:\u001b[36minit_or_connect_to_cluster\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mRay dashboard url: 127.0.0.1:8265\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m759\u001b[0m - \u001b[1mDetermining number of nvdecs/nvencs per gpu in this cluster.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m775\u001b[0m - \u001b[1mGpu with name NVIDIA H100 80GB HBM3 found. Looking up nvdecs and nvencs...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m777\u001b[0m - \u001b[1mFound the following gpu resources: GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mCreated/connected to cluster with resources: PoolOfResources(cpus=30.0, gpus=8.0, nvdecs=56.0, nvencs=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=1.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mSetting up fragmentation based autoscaler with problem: Problem(cluster_resources=ClusterResources(nodes={'ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71': NodeResources(cpus=30, gpus=[GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set()), GpuResources(gpu_fraction=1, nvdecs={0, 1, 2, 3, 4, 5, 6}, nvencs=set())], name='ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71')}), stages=[ProblemStage(name='Stage 00 - FilePartitioningStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=1, over_provision_factor=None), ProblemStage(name='Stage 01 - JsonlReaderStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 02 - PerplexityScorer', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.WHOLE_NUMBERED_GPU: 3>, data=WholeNumberedGpu(num_gpus=1, num_cpus=1.0, num_nvdecs_per_gpu=0, num_nvencs_per_gpu=0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 03 - JsonlWriter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None)])\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mStarting main loop\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mAutoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mSolving the following naiive allocation problem:\n",
            "{ 'cluster_resources': { 'cpus': 30.0,\n",
            "                         'gpus': 8.0,\n",
            "                         'nvdecs': 56.0,\n",
            "                         'nvencs': 0.0},\n",
            "  'stages': [ { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 00 - FilePartitioningStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': 1,\n",
            "                'resources_per_worker': { 'cpus': 0.5,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 01 - JsonlReaderStage',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 02 - PerplexityScorer',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 1,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1},\n",
            "              { 'batches_per_second_per_worker': 1.0,\n",
            "                'name': 'Stage 03 - JsonlWriter',\n",
            "                'num_returns_per_batch': 1,\n",
            "                'requested_num_workers': None,\n",
            "                'resources_per_worker': { 'cpus': 1.0,\n",
            "                                          'gpus': 0,\n",
            "                                          'nvdecs': 0,\n",
            "                                          'nvencs': 0},\n",
            "                'stage_batch_size': 1}]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mGot the following naiive allocation result:\n",
            "{ 'allocation_result': { 'cluster_resources': { 'cpus': 30.0,\n",
            "                                                'gpus': 8.0,\n",
            "                                                'nvdecs': 56.0,\n",
            "                                                'nvencs': 0.0},\n",
            "                         'stages': [ { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 1,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 00 - '\n",
            "                                                            'FilePartitioningStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': 1,\n",
            "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 8,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 01 - '\n",
            "                                                            'JsonlReaderStage',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 8,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 02 - '\n",
            "                                                            'PerplexityScorer',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 1,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}},\n",
            "                                     { 'input_samples_per_sample': 1.0,\n",
            "                                       'num_workers': 8,\n",
            "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
            "                                                    'name': 'Stage 03 - '\n",
            "                                                            'JsonlWriter',\n",
            "                                                    'num_returns_per_batch': 1,\n",
            "                                                    'requested_num_workers': None,\n",
            "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
            "                                                                              'gpus': 0,\n",
            "                                                                              'nvdecs': 0,\n",
            "                                                                              'nvencs': 0},\n",
            "                                                    'stage_batch_size': 1}}],\n",
            "                         'throughput': 1.0},\n",
            "  'num_slots_per_state': [2, 2, 2, 2]}\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36mrun_fragmentation_autoscaler\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mRunning phase 4...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:22.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mDone calculating autoscaling...\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:25.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 3.380096197128296 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:25.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.008837699890136719 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:25.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.009507179260253906 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:25.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 3.400686264038086 to get stats.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:25.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
            "Pipeline duration: 0.05838054815928141 minutes\n",
            "Number of initial input samples: 1\n",
            "Number of input samples remaining: 1\n",
            "Streaming pipeline main loop rate: 0\n",
            "\n",
            "Cluster Resources:\n",
            "\n",
            " Resource                    Total    Available \n",
            "\n",
            " CPUs                        32           31    \n",
            "\n",
            " GPUs                         8            8    \n",
            "\n",
            " Memory (GB)               1751.72      1751.72 \n",
            "\n",
            " Object Store Memory (GB)   200          200    \n",
            "\n",
            "\n",
            "Resource Usage by Stage:\n",
            "\n",
            " Stage                               CPU %    Memory (GB)    Actor Count    CPU % per worker    Memory (GB) per worker \n",
            "\n",
            " Stage 00 - FilePartitioningStage        0              0              0                   0                         0 \n",
            "\n",
            " Stage 01 - JsonlReaderStage             0              0              0                   0                         0 \n",
            "\n",
            " Stage 02 - PerplexityScorer             0              0              0                   0                         0 \n",
            "\n",
            " Stage 03 - JsonlWriter                  0              0              0                   0                         0 \n",
            "\n",
            "\n",
            "Stage state:\n",
            "\n",
            " Stage                               Actors:    Actors:    Actors:    Actors:    Actors:       Tasks:           Tasks:        Queue:         Queue:      Slots:       Slots:  Speed:          \n",
            "                                      Target    Pending      Ready    Running       Idle    Completed    Returned None    Input Size    Output Size    Num Used    Num Empty  Tasks/actor/s   \n",
            "\n",
            " Stage 00 - FilePartitioningStage          0          1          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 01 - JsonlReaderStage               0         11          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 02 - PerplexityScorer               0          8          0          0          0            0                0             0              0           0            0                  \n",
            "\n",
            " Stage 03 - JsonlWriter                    0         10          0          0          0            0                0             0              0           0            0                  \n",
            "\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:25.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 0\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 00 - FilePartitioningStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 1 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 0.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 0 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 00 - FilePartitioningStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3291841)\u001b[0m 2026-02-26 01:16:25.953 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3291841)\u001b[0m 2026-02-26 01:16:25.953 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3291841)\u001b[0m 2026-02-26 01:16:25.959 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3291841)\u001b[0m 2026-02-26 01:16:25.960 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3291841)\u001b[0m 2026-02-26 01:16:25.982 | DEBUG    | nemo_curator.stages.file_partitioning:_get_file_list:179 - Getting file list for ./wiki_curated_domain_data\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3291841)\u001b[0m 2026-02-26 01:16:25.985 | INFO     | nemo_curator.stages.file_partitioning:process:106 - Found 2 files\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3291841)\u001b[0m 2026-02-26 01:16:25.986 | INFO     | nemo_curator.stages.file_partitioning:process:117 - No partitions specified, defaulting to one file per partition\n",
            "\u001b[36m(Stage 00 - FilePartitioningStage pid=3291841)\u001b[0m 2026-02-26 01:16:25.986 | INFO     | nemo_curator.stages.file_partitioning:process:143 - Created 2 file groups from 2 files\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3291839)\u001b[0m 2026-02-26 01:16:25.979 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3291839)\u001b[0m 2026-02-26 01:16:25.979 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3291839)\u001b[0m 2026-02-26 01:16:25.989 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3291839)\u001b[0m 2026-02-26 01:16:25.990 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\n",
            "\u001b[32m2026-02-26 01:16:26.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 1\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 01 - JsonlReaderStage. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 11 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 10.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 10 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 29.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 29 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 7.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 7 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 19.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 19 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 22.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 22 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 16.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 16 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 25.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 25 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 27.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 27 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 13.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 13 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 4.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 4 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 1.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 1 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:26.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 01 - JsonlReaderStage stopped. All states cleared.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3291853)\u001b[0m 2026-02-26 01:16:26.227 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3291853)\u001b[0m 2026-02-26 01:16:26.227 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3291863)\u001b[0m 2026-02-26 01:16:26.175 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3291863)\u001b[0m 2026-02-26 01:16:26.175 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 03 - JsonlWriter on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3291851)\u001b[0m 2026-02-26 01:16:29.339 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 02 - PerplexityScorer on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3291851)\u001b[0m 2026-02-26 01:16:29.339 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 02 - PerplexityScorer on node=ea03dc92d2a1e00fc84f26894a5665568c7e994851e36dce43118b71\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3291851)\u001b[0m 2026-02-26 01:16:29.345 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - PerplexityScorer\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3291851)\u001b[0m 2026-02-26 01:16:34.909 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - PerplexityScorer\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3291844)\u001b[0m 2026-02-26 01:16:26.042 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 01 - JsonlReaderStage pid=3291844)\u001b[0m 2026-02-26 01:16:26.042 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3291864)\u001b[0m 2026-02-26 01:16:26.310 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3291864)\u001b[0m 2026-02-26 01:16:26.310 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 03 - JsonlWriter\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3291856)\u001b[0m 2026-02-26 01:16:29.625 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 02 - PerplexityScorer\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3291851)\u001b[0m `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3291863)\u001b[0m 2026-02-26 01:16:35.625 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 1 records to /home/sanjay/ee194-a2/wiki_curated_perplexity/9bd7ee3cfb9b.jsonl\n",
            "\u001b[32m2026-02-26 01:16:35.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 2\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 02 - PerplexityScorer. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 8 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 2.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 2 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 5.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 5 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 14.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 14 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 11.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 11 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 8.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 8 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 23.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 23 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_pending_actor\u001b[0m:\u001b[36m920\u001b[0m - \u001b[1mKilling pending actor 17.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 17 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 20.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 20 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 02 - PerplexityScorer stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 3\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 03 - JsonlWriter. Terminating all actors.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 10 actor IDs across all states to terminate.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 12.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 12 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 21.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 21 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 24.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 24 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 28.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 28 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 18.\u001b[0m\n",
            "\u001b[36m(Stage 03 - JsonlWriter pid=3291863)\u001b[0m 2026-02-26 01:16:35.718 | DEBUG    | nemo_curator.stages.text.io.writer.base:process:93 - Written 5 records to /home/sanjay/ee194-a2/wiki_curated_perplexity/ad2e9e8c1423.jsonl\n",
            "\u001b[32m2026-02-26 01:16:35.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 18 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 6.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 6 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 3.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 3 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 15.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 15 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 9.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 9 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 26.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 26 from allocator.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 03 - JsonlWriter stopped. All states cleared.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m543\u001b[0m - \u001b[1mAll stages are done. Finishing pipeline.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.013623237609863281 seconds to get node resource info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.02828073501586914 seconds to get cluster info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:35.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.005853414535522461 seconds to get actor info.\u001b[0m\n",
            "\u001b[32m2026-02-26 01:16:45.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mPipeline completed successfully with 2 output tasks\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity computation complete for both datasets.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(Stage 02 - PerplexityScorer pid=3291860)\u001b[0m 2026-02-26 01:16:35.656 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 02 - PerplexityScorer\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "non_curated_perplexity_dir = \"./wiki_domain_perplexity\"\n",
        "curated_perplexity_dir = \"./wiki_curated_perplexity\"\n",
        "\n",
        "# Compute perplexity for non-curated data\n",
        "pipeline_nc = Pipeline(\"non_curated_perplexity\")\n",
        "pipeline_nc.add_stage(JsonlReader(wiki_domain_dir))\n",
        "pipeline_nc.add_stage(PerplexityScorer())\n",
        "pipeline_nc.add_stage(JsonlWriter(non_curated_perplexity_dir, write_kwargs={\"force_ascii\": False}))\n",
        "results_nc = pipeline_nc.run()\n",
        "\n",
        "# Compute perplexity for curated data\n",
        "pipeline_c = Pipeline(\"curated_perplexity\")\n",
        "pipeline_c.add_stage(JsonlReader(curated_data_dir))\n",
        "pipeline_c.add_stage(PerplexityScorer())\n",
        "pipeline_c.add_stage(JsonlWriter(curated_perplexity_dir, write_kwargs={\"force_ascii\": False}))\n",
        "results_c = pipeline_c.run()\n",
        "\n",
        "print(\"Perplexity computation complete for both datasets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "178b832f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-curated: n=7, mean=39.37, median=35.41\n",
            "Curated:     n=6, mean=36.77, median=33.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/tmp/ipykernel_3085081/709642808.py:28: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = axes[1].boxplot(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from nemo_curator.utils.file_utils import get_all_file_paths_under\n",
        "\n",
        "def load_perplexities(data_dir):\n",
        "    file_paths = get_all_file_paths_under(data_dir)\n",
        "    dfs = [pd.read_json(fp, lines=True) for fp in file_paths]\n",
        "    return pd.concat(dfs, ignore_index=True)[\"perplexity\"].values\n",
        "\n",
        "nc_perp = load_perplexities(non_curated_perplexity_dir)\n",
        "c_perp = load_perplexities(curated_perplexity_dir)\n",
        "\n",
        "print(f\"Non-curated: n={len(nc_perp)}, mean={np.mean(nc_perp):.2f}, median={np.median(nc_perp):.2f}\")\n",
        "print(f\"Curated:     n={len(c_perp)}, mean={np.mean(c_perp):.2f}, median={np.median(c_perp):.2f}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram comparison\n",
        "cap = np.percentile(np.concatenate([nc_perp, c_perp]), 95)\n",
        "axes[0].hist(nc_perp[nc_perp < cap], bins=50, alpha=0.6, label=\"Non-curated\", color=\"salmon\")\n",
        "axes[0].hist(c_perp[c_perp < cap], bins=50, alpha=0.6, label=\"Curated\", color=\"steelblue\")\n",
        "axes[0].set_xlabel(\"Perplexity\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "axes[0].set_title(\"Perplexity Distribution (< 95th percentile)\")\n",
        "axes[0].legend()\n",
        "\n",
        "# Box plot comparison\n",
        "bp = axes[1].boxplot(\n",
        "    [nc_perp[nc_perp < cap], c_perp[c_perp < cap]],\n",
        "    labels=[\"Non-curated\", \"Curated\"],\n",
        "    patch_artist=True,\n",
        ")\n",
        "bp[\"boxes\"][0].set_facecolor(\"salmon\")\n",
        "bp[\"boxes\"][1].set_facecolor(\"steelblue\")\n",
        "axes[1].set_ylabel(\"Perplexity\")\n",
        "axes[1].set_title(\"Perplexity Box Plot (< 95th percentile)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46c7a076",
      "metadata": {},
      "source": [
        "You are invited to experiment with other methods to evaluate the non-curated versus curated datasets. Include them below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d69827b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# additional explorations here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "009e4ed0",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Reason about the assignment and/or your findings here.\n",
        "\n",
        "Once you are done with any Curator-related pipelines, stop the Ray client with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "0d4fc498",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-02-26 01:21:37.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.core.client\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mNeMo Curator has stopped the Ray cluster it started by killing the Ray GCS process. It is advised to wait for a few seconds before running any Ray commands to ensure Ray can cleanup other processes.If you are seeing any Ray commands like `ray status` failing, please ensure /tmp/ray/ray_current_cluster has correct information.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "ray_client.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NeMo Curator (Curator/.venv)",
      "language": "python",
      "name": "curator-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
